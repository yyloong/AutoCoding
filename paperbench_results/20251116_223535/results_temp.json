{
  "metadata": {
    "timestamp": "2025-11-16T22:35:35.322286",
    "split": "mini",
    "eval_type": "code-dev",
    "total_papers": 10
  },
  "papers": [
    {
      "paper_id": "adaptive-pruning",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "40ff2859-e14d-46ba-af52-0ba4595e2bce",
          "requirements": "The paper \"APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference\" has been reproduced",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "acd25439-b70d-495e-badc-ffe39145687f",
              "requirements": "The required pre-trained models, datasets, and metrics are available",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "6de45a65-1ceb-4aeb-b5df-864c0d62802b",
                  "requirements": "The required pre-trained models are available",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9ad77547-04b6-4558-993b-f22d91203bf1",
                      "requirements": "Code has been implemented such that RoBERTa can be loaded into memory",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "fa5309a4-2d43-45ef-80f6-df26a5559be2",
                      "requirements": "Code has been implemented such that T5, specifically t5-lm-adapt, can be loaded into memory",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "b4dac465-a91c-4b19-bcb6-0ccf66a65931",
                  "requirements": "The required pre-trained datasets have been setup",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "c9daa9ee-7667-4795-9c83-3f5c9c88a65f",
                      "requirements": "Code for accessing the train and dev splits from the SST2 dataset from the GLUE benchmark has been implemented",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "5fef034a-5a8f-4ada-848c-336469238e68",
                      "requirements": "Code for accessing the train and dev splits from the MNLI dataset from the GLUE benchmark has been implemented",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Data Processing & Preparation"
                    },
                    {
                      "id": "8605df37-4a11-4c87-8eae-bfb10b6bf5b9",
                      "requirements": "Code for accessing the train and dev splits from the SQuAD 2.0 benchmark has been implemented",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "4e1da193-e3eb-4cc0-af44-74314ba83668",
                      "requirements": "Code for accessing the train and test sets from the CNN Dailymail (CNN/DM) dataset has been implemented",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "75338090-55d9-4e76-94bd-3a3939b95e02",
                  "requirements": "The required dataset-specific metrics have been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "1fdb66d7-04b9-479e-bcf4-32791841707f",
                      "requirements": "When evaluating models on SST2 and MNLI, the dev set accuracy is reported",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d43a1c9e-74f8-4725-91be-58a38063639a",
                      "requirements": "When evaluating models on SQuAD, the dev set F1 score is reported",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "698b1e1c-4947-4365-a49f-10c6ab66e263",
                      "requirements": "When evaluating models on CNN/DM, the ROUGE 1/2/L scores on the test set are reported",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6dcaf27c-daf9-4f67-b418-3aa0f352b461",
                  "requirements": "Training and evaluation metrics have been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3aeea066-bf35-4baa-a1e5-864de953d68f",
                      "requirements": "For each method trained on some dataset, the train time is measured as the time-to-accuracy of reaching 97% of the dev (/test) set performance of the finetuning baseline",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "79a20612-83df-424a-9355-068dc18032d7",
                      "requirements": "For each method, when being trained on some dataset, code has been implemented to record the max GPU memory utilization, using torch.cuda.max_memory_allocated() (or equivalent)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "240b99e2-f34e-4a0c-86c2-4454e31b6517",
                      "requirements": "For each method, when being evaluated on some dataset, the speed of inference is measured as the inference throughput (sampled processed per second)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1ff3dcb3-be14-4770-93a8-dcf721c4e3bd",
                      "requirements": "For each method, when performing inference with some dataset, code has been implemented to record the max GPU memory utilization, using torch.cuda.max_memory_allocated() (or equivalent)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "d1c67f43-2e5c-4e31-94c7-e5e970d13ee7",
              "requirements": "LoRA has correctly been setup",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "48e1cbcb-4226-4f00-a456-7a8d2025263c",
                  "requirements": "LoRA is available to be applied to modules within transformers",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "d5ec9b1a-d8cb-4196-8cfc-2923638b8483",
                  "requirements": "After training a method using LoRA adapters, before performing inference, the LoRA parameters are merged into the parameters of the model",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "589700b6-e18c-47fc-b38e-bf8d03015511",
              "requirements": "The baselines have been implemented",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "3ec70bbe-9d13-49f5-8145-1dc9682d27e6",
                  "requirements": "The fine-tuning baseline is implemented by finetuning a pre-trained model on a dataset",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "791e26f6-38ea-4e1a-89a9-b0bd251a48ea",
                  "requirements": "The Mask Tuning baseline is implemented, using the implementation at https://github.com/WoosukKwon/retraining-free-pruning",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "1cd21fca-c4db-4f55-b52e-f8b54b814401",
                  "requirements": "The LoRA+Prune baseline is implemented by first finetuning a model with LoRA adapters, then applying Mask Tuning",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "c4790fad-070e-401b-bb6b-a163971ba23a",
                      "requirements": "In LoRA+Prune, LoRA adapters are first added to modules of the given model",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "e2236b08-c76c-4236-b3d6-f4c2bcd3e9e5",
                      "requirements": "In LoRA+Prune, the model with the LoRA adapters added is finetuned",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "95d71d15-54a0-421b-b2af-9e6c65e5a004",
                      "requirements": "In LoRA+Prune, once the model with LoRA adapters has finished finetuning, Mask Tuning is applied to the model",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "1ad3cbb6-04ad-4947-88c9-f4461fa33596",
                  "requirements": "The CoFi baseline (also named \"Prune+Distill\" in Section 5.2) is implemented, using the implementation at https://github.com/princeton-nlp/CoFiPruning",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "8cb5586d-c650-48a5-8697-13c3e87d9beb",
                  "requirements": "The LoRA+Prune+Distill baseline is implemented",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "92a96898-e039-4a9e-98a1-0b8143bab0d5",
                      "requirements": "In LoRA+Prune+Distill, LoRA adapters are first added to modules of the given model",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "a7b5b5ae-5a7b-425c-b286-b753e36610d0",
                      "requirements": "In LoRA+Prune+Distill, CoFi pruning and distillation is used but with LoRA parameters only; only the $L_0$ modules (the non-negative stochastic gates in CoFi which collectively determine which weights to set to zero) and LoRA parameters are tuneable",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "1bf48b45-d2f9-492a-92b0-3bba1abbe809",
              "requirements": "APT has been implemented",
              "weight": 10,
              "sub_tasks": [
                {
                  "id": "64287b4f-18a0-47a1-bb7a-1a06204664ba",
                  "requirements": "The APT adapter architecture has been implemented, following Section 4.1",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "c388a6ce-0107-44bc-929d-188a452e04c3",
                      "requirements": "The masked input to the adapter is computed",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b16c44c6-58e1-4660-a60b-f66b21d43437",
                          "requirements": "The masked input to the APT adapter is computed as $X \\circ m_i$, where $X$ is the input to the adapter and is $m_i \\in \\mathbb{R}^d_i$ a learnable binary pruning mask",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "a1686474-6def-4ed5-8b88-7a6af0659cab",
                          "requirements": "When APT is applied to MHA layers, $m_i$ prunes the transformers' hidden dimension",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "169a5eb2-e201-49be-bf7f-f977933291f1",
                          "requirements": "When APT is applied to FFN layers, $m_i$ prunes the transformers' hidden dimension",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "d355596f-b5f3-4f47-a840-f33fbbd3d1f1",
                      "requirements": "The new weight matrix is computed, using the original weight matrix $W \\in \\mathbb{R}^{d_o \\times d_i}$",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "3a628b4e-ba0c-457f-ac35-fdf18c8fd356",
                          "requirements": "For the APT adapter implementation, a dynamic rank $r_{apt}$ is defined for each weight matrix, which can vary",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "18060c53-6871-4aa5-93d5-49f962f7187d",
                          "requirements": "For the APT adapter implementation, a new learnable weight matrix $W_A \\in \\mathbb{R}^{r_{apt} \\times d_i}$ is defined",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ee70fcc6-17cf-490f-ba08-3f2dba12b190",
                          "requirements": "For the APT adapter implementation, a new learnable weight matrix $W_B \\in \\mathbb{R}^{d_o \\times r_{apt}}$ is defined",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c99479b2-0e4e-435e-a574-53a7ae8d4c7f",
                          "requirements": "For the APT adapter implementation, the original weight matrix $W$ is kept frozen; it isn't updated during training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "bf86efe4-a3cb-4ee3-8c7b-19ab0a3cdf49",
                          "requirements": "For the APT adapter implementation, the new weight matrix is computed as $W + 2 \\cdot W_B W_A$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "bb7ec9df-02b9-43e0-92c9-dc1b5429ef23",
                      "requirements": "For the APT adapter implementation, the new weight matrix is multipled by the masked input",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "34cf5055-95ff-45aa-9406-eae383cb1814",
                      "requirements": "The output of the APT adapter is correctly computed",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5f68b482-6b70-43d8-973b-da59eab1f6ee",
                          "requirements": "For the APT adapter implementation, the output of the multiplication between the updated weights and masked input is masked by a learnable binary pruning mask $m_o \\mathbb{R}^d_o$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "9500d7e2-8f9a-446a-8da0-7f0e4621db39",
                          "requirements": "When the APT adapter is applied to MHA layers, $m_o$ prunes attention heads",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "472390c9-f791-4705-ab68-92c155f904d1",
                          "requirements": "When the APT adapter is applied to FFN layers, $m_o$ prunes internal neurons in the FFN layers",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "324e138f-5257-46d0-9e26-620a45b21fa6",
                  "requirements": "Outlier-aware salience score is implemented, following equations 3 and 9",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "56fadbbe-1aab-4a95-9fd6-08accc31726b",
                      "requirements": "For a parameter $W_{i,j}$ that is not in an APT adapter layer, the salience is computed as $S(W_{i,j}) = \\left| W_{i,j} \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W_{i,j}} \\right|$",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "67496368-0dd9-4422-b0f2-6fca77abe7a6",
                      "requirements": "For an APT adapter layer, the salience is computed following equation 9 as the sum of the block-wise frozen weight salience and the corresponding tuning weight",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7f8d2c8b-7078-4e1f-b6f2-7e2c92240b89",
                      "requirements": "Outlier-aware salience for a block is computed as $\\hat{S}(W_{:,j}) = \\tilde{S}(W_{:,j}) + \\left( \\text{Kurt}(O_{j,:}) \\right)^{\\frac{1}{2}}$, where $\\tilde{S}$ is the salience score, $O_{:,j} = W_{:,j} \\circ X_{j,:}^T$ represents the activation, and $\\text{Kurt}(\\cdot)$ stands for Kurtosis",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "6c5119f5-f5ff-43bd-a2ce-3965c4befe2c",
                      "requirements": "During training, the outlier-aware salience of each block is computed as an exponential moving-average $\\overline{S}^{(t)}(m) \\gets 0.85 \\overline{S}^{(t-1)}(m) + 0.15 \\hat{S}(m)$, where $\\overline{S}^{(t)}(m)$ is the moving-average of block $m$ at time step $t$, and $\\hat{S}(m)$ is the current outlier-aware salience score of block $m$",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c1f38081-5e08-4d70-8160-4c24546738d5",
                  "requirements": "Low-cost Adaptive LM Pruning is implemented, as described in Section 4.2 and Appendix B",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "4b240f46-6e6d-4245-9ebb-458cce9825ee",
                      "requirements": "APT Blocks are sorted in descending order by salience density",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "13736e68-c8a3-4b3d-a772-a4811896dc88",
                          "requirements": "Computing the parameter count for different blocks is implemented correctly following equations 10, 11, 12",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "293d6fac-aff3-4b99-b709-e803ff9d11a4",
                              "requirements": "Given a hidden dimensionality $d_m$ and number of attention heads $n_h$, the number of parameters of a MHA head is computed as $4 \\times d_m \\times d_m / n_h$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "4a6f0dfe-c9c0-43b6-b910-7b7257b56fe6",
                              "requirements": "Given a hidden dimensionality $d_m$, the number of parameters of a FFN neuron is computed as $2 \\times d_m$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "87383bb6-5e78-4acd-a7fb-ce8cdcef77d1",
                              "requirements": "Given a hidden dimensionality $d_m$, number of layers $n_L$, and number of neurons in the FFN layer $n_f$, the number of parameters associated with a transformers hidden dimension across all layers is computed as $n_L \\times (4 d_m + 2 n_f)$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "1d80f3a3-58f0-4419-976c-5786053c9b4c",
                          "requirements": "For a block with salience $S$ and number of parameters $\\mathcal{C}$, the salience density is computed as the salience divided by the parameter number $S / \\mathcal{C}$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "a3ae8772-f9aa-4f65-a8d2-7a1f94c9ae3c",
                          "requirements": "The salience density is only calculated for blocks that have an APT adapter applied to them",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8e4cb47d-9829-4357-b3c3-c44799d7f6f2",
                          "requirements": "The salience density of each block is re-computed everytime the number of parameters of the model changes",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4221dd78-0c29-416e-abd1-fa9b0a69d0ed",
                          "requirements": "The blocks are sorted by their salience density in descending order",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "50d7ad1a-8908-427c-9830-585bfd7086f4",
                      "requirements": "A function $f$ for identifying a block's category is implemented, following equation 13. $f$ returns 0 when block $b_i$ is a head, 1 if $b_i$ is a neuron, and 2 if $b_i$ is a dimension",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7e92857e-e842-4acb-abc4-ffa658b7d6c0",
                      "requirements": "Following equation 14, given any index $i$, the parameter number of the LM consisting of the top-$i$ blocks can be computed",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "c32d372a-826a-4bce-b9a0-5b5100afdd43",
                          "requirements": "Following equation 14, given any index $i$ and a sorted list of N blocks in descending order of salience density, the number of blocks in the top-$i$ blocks that are added to heads is computed as $n_h^\\prime = \\sum_{j=0}^{i-1} \\delta (0, f(b_j))$, where $\\delta (i, j)$ is the Kronecker delta function that returns 1 if $i=j$, and otherwise 0, and $f$ is the function that returns 0 when block $b_i$ is a head, 1 if $b_i$ is a neuron, and 2 if $b_i$ is a dimension",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "7de18cb9-893c-4faf-9fff-59347b183ec3",
                          "requirements": "Following equation 14, given any index $i$ and a sorted list of N blocks in descending order of salience density, the number of blocks in the top-$i$ blocks that are added to neurons is computed as $n_f^\\prime = \\sum_{j=0}^{i-1} \\delta (1, f(b_j))$, where $\\delta (i, j)$ is the Kronecker delta function that returns 1 if $i=j$, and otherwise 0, and $f$ is the function that returns 0 when block $b_i$ is a head, 1 if $b_i$ is a neuron, and 2 if $b_i$ is a dimension",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "256c6f16-a3d6-46ce-a5b4-edc6c2a96653",
                          "requirements": "Following equation 14, given any index $i$ and a sorted list of N blocks in descending order of salience density, the number of blocks in the top-$i$ blocks that are added to dimensions is computed as $d_m^\\prime = \\sum_{j=0}^{i-1} \\delta (2, f(b_j))$, where $\\delta (i, j)$ is the Kronecker delta function that returns 1 if $i=j$, and otherwise 0, and $f$ is the function that returns 0 when block $b_i$ is a head, 1 if $b_i$ is a neuron, and 2 if $b_i$ is a dimension",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "d3dcd793-2ff9-4ef2-89a2-0e38815a1637",
                          "requirements": "Following equation 14, given any index $i$ and a sorted list of N blocks in descending order of salience density, the parameter number is computed as $C_{\\text{top}-i} = (4d_h^\\prime \\cdot n_h^\\prime + 2n_f^\\prime) \\cdot d_m^\\prime$, where $d_h^\\prime$ is the number of heads in the model, $n_h^\\prime$ is the number of the top-$i$ blocks that are added to heads, $n_f^\\prime$ is the number of the top-$i$ blocks that are added to neurons, and $d_m^\\prime$ is the number of the top-$i$ blocks that are added to dimensions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "b424b0fc-5ca1-40d0-95c6-095dea897198",
                      "requirements": "In Low-cost Adaptive LM Pruning, binary search is used to get the top-$i$ salient blocks",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "215e9429-279e-4fb5-9bce-7cbf69c1f76e",
                      "requirements": "In Low-cost Adaptive LM Pruning, blocks that are marked to be pruned have their corresponding masks decreased by 0.01",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "3c85013f-a0c5-45e2-b32c-b418e247dfeb",
                  "requirements": "Adaptive and Efficient LM Tuning is implemented, as described in Section 4.3",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "664da958-cb9d-4efd-aec5-9c30d4e0c64f",
                      "requirements": "In Adaptive and Efficient LM Tuning, given an APT adapter $H_{apt}$, the importance score is computed as $\\mathcal{I}(H_{apt}) = \\sum_{i,j} S(W_{Bi,j})$, the summation of the parameter salience scores in $W_B$ (where $W_B \\in \\mathbb{R}^{d_o \\times r_{apt}}$ is an APT tuning parameter)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7fd4d11b-41d3-4036-b203-9bd71cc003b5",
                      "requirements": "In Adaptive and Efficient LM Tuning, APT adapters are sorted by their importance score",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "db7f1038-efbb-44a9-8407-e891c68c19ad",
                      "requirements": "The ranks of the top-half blocks (blocks with largest importance) is linearly increased",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0e3baed9-9122-4c55-9326-29edf8f0b4c4",
                          "requirements": "When increasing tuning parameter from $\\Delta t$ to $Delta t^{\\prime}$, the salient layer's rank is changed from $r_{apt}$ to $r_{apt}^\\prime=\\lfloor{r_{apt} \\cdot \\frac{\\Delta_t^\\prime}{\\Delta_t }\\rfloor$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "48d8285a-bcee-412a-995e-dea44e2fff2f",
                          "requirements": "When adding parameters, random Gaussian initialized parameters $\\mathcal{N}(0, \\sigma^2)$ are concatenated to $W_A$, and zeros are concatenated to $W_B$, where $W_A \\in \\mathbb{R}^{r_{apt} \\times d_i}$,  $W_B \\in \\mathbb{R}^{d_o \\times r_{apt}}$ are both APT tuning parameters",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "46f2680c-1aa2-44eb-8a74-b46ac73324f8",
                  "requirements": "Efficient Self-Knowledge Distillation is implemented, as described in Section 4.4",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "2b494437-89dd-4517-b9fb-634cbc20de15",
                      "requirements": "In Efficient Self-Knowledge Distillation, at each training epoch, intermediate layers from the teacher model are randomly selected for distillation; 4 teacher layers are randomly sampled in each quarter slice of the layers (e.g. for a 12-layer network the slices would be: 0-2, 3-5, 6-8, 9-11)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b06d3f22-5baf-43ef-9ffb-13c1bda9fcf7",
                      "requirements": "In Efficient Self-Knowledge Distillation, the teacher-student layer-mapping function $m(\\cdot)$ is implemented correctly",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "92744e38-5ae3-4873-8ed1-c0c431e77ad3",
                          "requirements": "In Efficient Self-Knowledge Distillation, the teacher-student layer-mapping function $m(\\cdot)$ is implemented to match 4 teacher layers with the closest, non-pruned student layers, using the same method introduced in CoFi (Xia et al., 2022). For each of the 4 teacher layers, the layer mapping function dynamically determines which of the student layers is closest; $\\mathop{\\arg \\min}\\limits_{j:\\mathbf{z}_{FFN}^{(j)}>0} \\text{MSE} (W_{\\text{layer}} H_s^j, H_t^i)$, where $H_s^j, H_t^i$ are hidden representations from the $j$-th student FFN layer and $i$-th teacher layer respectively, and $W_{\\text{layer}} \\in \\mathbb{R}^{d\\timesd}$ is a learnable linear transformation matrix, initialized as an identity matrix",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "39282784-429b-4b1f-97a1-729417989069",
                          "requirements": "In Efficient Self-Knowledge Distillation, the teacher-student layer-mapping function $m(\\cdot)$ is re-computed every training step",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "28658a50-5fa0-47d4-92c2-cdafb0d751aa",
                      "requirements": "In Efficient Self-Knowledge Distillation, the hidden layer distillation loss is defined as $\\mathcal{L}_{\\text{layer}} = \\sum_{i=1}^4 \\text{MSE}(\\text{Tr}(H_s^{\\phi(i)}), H_t^i)$, where $\\text{Tr}$ denotes the tunable LoRA layer for layer transformation, initialized as an identical matrix $\\mathcal{I}$, and $\\phi(\\cdot)$ is the teacher-student layer-mapping function",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "4b5df1a0-8ade-4ffa-a0b6-07fe15c74174",
                      "requirements": "In Efficient Self-Knowledge Distillation, $\\mu$ is a moving term that linearly scales from 0 to 1 during pruning",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "b1ced87a-d33c-4737-a3cb-1aa6f74a89ee",
                      "requirements": "The distillation loss $L_{\\text{distil}}$ is implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "8f4b756f-947a-4194-929a-06e791900ec7",
                          "requirements": "In Efficient Self-Knowledge Distillation, cross-entropy loss between the pruned student's and teacher's output probability distributions $\\mathbf{p}_s$ and $\\mathbf{p}_t$ is computed as $\\mathcal{L}_{\\text{pred}} = D_{\\text{KL}}(\\mathbf{p}_s \\,\\|\\, \\mathbf{p}_t)$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "1e6df51c-71c6-4712-95bd-c3ff8f9b8d69",
                          "requirements": "In Efficient Self-Knowledge Distillation, when training on GLUE tasks, the layer distillation is combined with the prediction-layer distillation: $\\mathcal{L}_{\\text{distill}} = \\mathcal{L}_{\\text{pred}} + 0.9 \\mathcal{L}_{\\text{layer}}$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "16f88c2e-9b4d-44b0-8417-44d14a96f729",
                          "requirements": "In Efficient Self-Knowledge Distillation, when training on SQuAD or CNN/DM, the layer distillation is combined with the prediction-layer distillation: $\\mathcal{L}_{\\text{distill}} = 0.1 \\mathcal{L}_{\\text{pred}} + 0.9 \\mathcal{L}_{\\text{layer}}$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "3f534396-e443-46f3-9ea8-a215dd653142",
                      "requirements": "Following equation 7, the distillation objective is defined as $\\mathcal{L} = \\mu \\mathcal{L}_{\\text{distill}} + (1 - \\mu) \\mathcal{L}_{\\text{ft}}$, where $\\mathcal{L}_{ft}$ is the supervised fine-tuning objective",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "43b7fa8c-b6d9-43fb-be02-91df6e3ac7ce",
                  "requirements": "When pruning LMs with APT, the LM is first pruned and trained with the self-distillation objective for some pre-defined number of epochs, then it is fine-tuned on the same dataset for some other pre-defined number of epochs",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "50acfee7-499d-4b68-8205-a346d6aa16e1",
                  "requirements": "When pruning LMs with APT, given a pre-determined target sparsity $\\gamma_T$ and total number of pruning training steps $T$, the target sparsity at timestep $t$ is computed by $\\gamma_t = \\gamma_T + (1 - \\gamma_T) \\left(1 - \\frac{t}{T}\\right)^3$",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "ca6ea57b-3ed0-40ee-96e8-123036828dfb",
                  "requirements": "After training a model using APT adapters, before performing inference, the APT parameters are merged into the parameters of the model",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "96fed172-bd64-4d1d-8582-a9ff78ed9fc2",
              "requirements": "The recorded metrics show that the results in section 5 have been reproduced",
              "weight": 10,
              "sub_tasks": [
                {
                  "id": "b8bc3c33-3772-461f-8e34-bcceb59f224c",
                  "requirements": "The hyperparameters have been configured",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "c5efd59d-aac5-4671-9eaf-c181267fb31e",
                      "requirements": "The dataset-specific hyperparameters are configured",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "32b34787-3ef1-430d-ac29-1f7b7476a6f9",
                          "requirements": "The GLUEhyperparameters are configured",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e193b120-5b15-442f-ad9c-8d817dea5c66",
                              "requirements": "All models trained on GLUEuse a learning rate of 2e-4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "83a476b8-e3d9-4ce5-b956-e3cac8d8a499",
                              "requirements": "All models trained on GLUEuse a batch size of 32",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d441dc31-a89e-483a-996f-4a62517c47e5",
                              "requirements": "For every method that isn't Finetune, models trained on GLUE use 40 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "fe34b5f1-93eb-4175-b53c-5b18b04b032d",
                              "requirements": "When training on the GLUE dataset using the Prune+Distill, LoRA+Prune+Distill, or APT methods, the first 20 epochs are used for distillation, and the remaining 20 are for training on the objective",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "df4efbf5-73f1-4101-8e0f-a9ac17690982",
                          "requirements": "The SQuAD hyperparameters are configured",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9662eaea-80a1-42d8-969f-c6d3b051806d",
                              "requirements": "All models trained on SQuAD use a learning rate of 2e-4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "89b01087-4722-4de3-8e4e-8d75f82f6904",
                              "requirements": "All models trained on SQuAD use a batch size of 32",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "c99c524a-17bd-4f7d-93c1-2f4b2b2753d1",
                              "requirements": "For every method that isn't Finetune, models trained on SQuAD use 40 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a5c6d56b-c273-40cf-9ded-82a9267d9c42",
                              "requirements": "When training on the SQuAD dataset using the Prune+Distill, LoRA+Prune+Distill, or APT methods, the first 20 epochs are used for distillation, and the remaining 20 are for training on the objective",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8c0ac791-e01b-48ae-abca-e6290bce216d",
                          "requirements": "The CNN/DM hyperparameters are configured",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e32c3c58-2be6-4435-a181-9c46588f4945",
                              "requirements": "All models trained on CNN/DM use a learning rate of 1e-4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "2fff2695-43e9-4392-ada2-77604e02babc",
                              "requirements": "All models trained on CNN/DM use a batch size of 16",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "f0f7160e-44ba-49de-89eb-d581aed006ee",
                              "requirements": "For every method that isn't Finetune, models trained on CNN/DM use 16 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "908deb8d-c35b-415f-9a18-0d086bab4a87",
                              "requirements": "When training on the CNN/DM dataset using the Prune+Distill, LoRA+Prune+Distill, or APT methods, the first 6 epochs are used for distillation, and the remaining 10 are for training on the objective",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "6287838a-d855-40c2-ba76-b3057ecfc68e",
                      "requirements": "The adapter ranks $r_{apt}$ in all APT modules are initialized to 8",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "452a6371-176b-4a01-b29b-e74f9278c08e",
                      "requirements": "The Finetune method is trained for 10 epochs",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "182530e5-82ff-4a09-8146-09a35255a2e0",
                  "requirements": "The LoRA and APT adapters are applied to the correct modules of RoBERTa and T5",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "dde4b5f2-f505-4592-a0ca-2fa8b50ddf12",
                      "requirements": "LoRA and APT adapters are added to queries and values of MHA layers in RoBERTa and T5",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "2a3669df-4e69-464a-b0c5-47b9001e2281",
                      "requirements": "LoRA and APT adapters are added to the up layer in FFN layers in RoBERTa and T5",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "0f68b07c-ac8b-48a6-a64a-d76d3544b1a2",
                  "requirements": "The recorded metrics show that Section 5.4 has been replicated",
                  "weight": 5,
                  "sub_tasks": [
                    {
                      "id": "be023cab-a19b-4a4f-9de8-220c66f5b66b",
                      "requirements": "The experiments required for Section 5.4 have been run",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2bc30ab0-356d-4433-9b84-3c7f718fab69",
                          "requirements": "RoBERTa is trained and evaluated using various pruning methods",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "01d90251-7fc3-4c86-9a5a-aab6ed12d987",
                              "requirements": "RoBERTa with the FT, LoRA, LoRA+Prune, and APT methods is trained and evaluated on MNLI, SST2, and SQuAD v2 separately with 60% sparsity",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "8e9dce7a-d32e-4636-9da7-df9918647823",
                              "requirements": "RoBERTa with the Prune+Distill and LoRA+Prune+Distill methods is trained and evaluated on MNLI and SST2 separately with 60% sparsity.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "dcc716d8-6f57-45be-b4d5-5c1b774b4b6b",
                          "requirements": "T5 with the FT, LoRA, LoRA+Prune, and APT methods is trained and evaluated on MNLI, SST2, and CNN/DM separately with 60% sparsity",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "831a290b-bb51-4254-b41a-536500671b44",
                      "requirements": "The results from Section 5.4 have been replicated",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "df922acd-6763-44a7-bb8d-73b1b01bd323",
                          "requirements": "The results comparing training time and efficiency of APT compared to LoRA+Prune have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d075f77c-9383-4f7c-8b35-dbb8ad9507a8",
                              "requirements": "The recorded metrics show that when pruning RoBERTa to 60% sparsity, APT converged about 8x faster than the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "be593611-3cdd-4a6c-89c6-726831a9382c",
                              "requirements": "The recorded metrics show that when pruning RoBERTa to 60% sparsity, APT used similar GPU memory during both training and inference compared to the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7fb47445-dde2-4b4a-957a-777aedae4eae",
                              "requirements": "The recorded metrics show that when pruning T5 to 60% sparsity, APT converged about 8x faster than the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c6179a9c-02b7-428b-b019-16d2d490b271",
                              "requirements": "The recorded metrics show that when pruning T5 to 60% sparsity, APT used similar GPU memory during both training and inference compared to the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "5b290859-b1d1-4219-89fe-15e6b3cee2e5",
                          "requirements": "The results comparing performance of APT compared to LoRA+Prune have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "cdcbff81-1647-42dd-85fa-851fc14037d7",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT achieves an equal or higher performance than LoRA+Prune across all evaluations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fbdc9a9e-6d1a-44a4-972d-995e33e35234",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, the inference efficiency reached by APT is about the same as the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "de57690a-d1e9-4606-b8d7-dc198bc976da",
                              "requirements": "The recorded metrics show that when pruning T5 under 60% sparsity, APT has roughly 5% better end-task performance on average than the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "737f8df7-95b8-42cb-9e59-8e05bae93052",
                              "requirements": "The recorded metrics show that when pruning T5 under 60% sparsity, the inference efficiency reached by APT is worse than the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8e7a9685-1cf0-42e1-b12c-b129d0872a66",
                          "requirements": "The results comparing performance of APT to Prune+Distill have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ec378300-5912-40de-a90e-d5d28f7bea31",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT has similar task accuracy to Prune+Distill across MNLI and SST2",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "37612400-aa24-4650-9402-9b9c536b86a5",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT costs roughly 40% of training memory compared to Prune+Distill",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9f477ec1-f090-482a-919d-c9050cac0802",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT converges 2.5x faster than Prune+Distill",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "e1fe1c33-bdce-4ee4-a5cb-7ec2b210f6a6",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT achieves better task performance than LoRA+Prune+Distill",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "dc200210-82d1-4f50-ae44-b30bd24cc22b",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT requires less training time than LoRA+Prune+Distill",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5a2b6715-3de9-4527-b9ae-86e28d4713b5",
                              "requirements": "The recorded metrics show that when pruning RoBERTa and T5 to 60% sparsity, APT requires less memory than LoRA+Prune+Distill",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "05b27156-45d5-40bf-89e9-bada7bbe4b05",
                  "requirements": "The recorded metrics show that Section 5.5 has been replicated",
                  "weight": 5,
                  "sub_tasks": [
                    {
                      "id": "7200cb94-104c-436c-9db7-716519188712",
                      "requirements": "The experiments required for Section 5.5 have been run",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0c47a836-4eec-478f-9be1-b7c9abd768f1",
                          "requirements": "For Section 5.5, the relative accuracy for some model is computed as the accuracy such model achieves when compared to the accuracy the finetuning baseline achieves",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d406c635-3506-4ed8-bf4f-ed80d54bc7b2",
                          "requirements": "RoBERTa with the LoRA+Prune, LoRA+Prune+Distill, and Prune+Distill methods is trained and evaluated on SST2 and MNLI separately, and the relative performance is computed using the average on SST2 and MNLI",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "24223a79-763d-4cb8-9f73-27fdd358d543",
                          "requirements": "T5 with the LoRA+Prune method is trained and evaluated on SST2 and MNLI separately, and the relative performance is computed using the average on SST2 and MNLI",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5a92263e-e824-4fe3-bc4f-661fc7ab5c1a",
                          "requirements": "RoBERTa with the APT method is trained and evaluated on SST2 and MNLI separately for sparsities 40%, 50%, 60%, 70%, 80%, 90%, 95%, and the relative is computed using the average on SST2 and MNLI",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8df3184f-06b6-4df1-8234-055b81384970",
                          "requirements": "T5 with the APT method is trained and evaluated on SST2 and MNLI separately for sparsities 40%, 50%, 60%, 70%, 80%, 90%, and the relative performance is computed using the average on SST2 and MNLI",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "48411c0d-c518-4be5-b9e3-94631d943f54",
                      "requirements": "The results from Section 5.5 have been replicated",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "939d1034-157f-460e-8cf6-fb589ea1f417",
                          "requirements": "The recorded metrics indicate that APT is about 20% faster in inference than the LoRA+Prune baseline for RoBERTa, when comparing the APT model that achieved the closest accuracy to the LoRA+Prune baseline",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "00ce14bb-60bc-461a-8958-897ca6c75a3d",
                          "requirements": "The recorded metrics indicate that APT is about 7% more memory efficient than the LoRA+Prune baseline for RoBERTa, when comparing the APT model that achieved the closest accuracy to the LoRA+Prune baseline",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "93cb26c7-4166-42c5-8718-8c27d892d682",
                          "requirements": "The recorded metrics indicate that APT is about 60% faster in inference than the LoRA+Prune baseline for T5, when comparing the APT model that achieved the closest accuracy to the LoRA+Prune baseline",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b7607af8-bc54-4840-9153-9a8b55409c84",
                          "requirements": "The recorded metrics indicate that APT is about 25% more memory efficient than the LoRA+Prune baseline for T5, when comparing the APT model that achieved the closest accuracy to the LoRA+Prune baseline",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a8de113b-d3cf-41aa-a5ff-2137c4587140",
                  "requirements": "The recorded metrics show that Section 5.6 has been replicated",
                  "weight": 5,
                  "sub_tasks": [
                    {
                      "id": "46a4b010-1790-404e-b3d2-de3587fe9718",
                      "requirements": "The experiments and results related to adaptive pruning in Section 5.6 have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e9fa1766-f3bd-447a-918d-e6696bf20ecf",
                          "requirements": "RoBERTa is trained and evaluated on SST2 and MNLI separately with 60% sparsity using a modified version of APT that doesn't use adaptive pruning (APT w/o $A_P$)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "b029f3f7-2957-4a7a-a53a-f05940ad055c",
                          "requirements": "The results related to adaptive pruning have been replicated",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "7525718b-1307-426a-9c08-1d1505a08ade",
                              "requirements": "The recorded metrics show that when pruning with APT w/o $A_P$, the task performance of RoBERTa reaches roughly 94 for SST2 and 87.5 for MNLI",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "16db85a1-c6ea-4e23-86f7-5d538f4f438a",
                              "requirements": "The recorded metrics show that when pruning with APT w/o $A_P$, the RoBERTA training speed with APT w/o $A_P$ is roughly 20% faster than full fine-tuning on the same datasets",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "66039c65-91df-4270-9216-1a31aab5756e",
                              "requirements": "The recorded metrics show that when pruning with APT w/o $A_P$, the RoBERTA training using APT w/o $A_P$ requires roughly 60% of the memory compared to full fine-tuning on the same datasets",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "95e0ba74-3019-48f1-a65a-01f65e0038be",
                      "requirements": "The experiments and results related to adaptive tuning in Section 5.6 have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "859bffed-bd82-43db-bed1-443bdf4b1ef0",
                          "requirements": "RoBERTa is trained using a modified version of APT that doesn't use adaptive tuning (APT w/o $A_T$) using 60% sparsity",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "03f507ad-6b1a-46d9-9318-d7794bb39540",
                          "requirements": "The results related to adaptive tuning have been replicated",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "011cf2f5-5a70-44ba-954c-0a3620075f08",
                              "requirements": "The recorded metrics show that when pruning RoBERTa with APT w/o $A_T$, it achieves roughly 93 on SST2",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "1a57a576-01a5-42e4-bb42-cdcdaa3f45e2",
                              "requirements": "The recorded metrics show that when pruning RoBERTa with APT w/o $A_T$, it achieves roughly 84 on MNLI",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "26fbd16f-a67f-4464-be72-818898a86f41",
                              "requirements": "The recorded metrics show that when pruning RoBERTa with APT w/o $A_T$, it has a similar performance as the LoRA+Prune baseline",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "70a1b6da-2a1f-475e-b61e-8dbbd1911766",
                              "requirements": "The recorded metrics show that when pruning RoBERTa with APT w/o $A_T$, it converged roughly 15% slower than full APT",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "dcec9c7d-8519-43a3-a582-b12869115591",
                      "requirements": "The experiments and results related to self-distillation in Section 5.6 have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e7ad0e1d-93d3-46c9-98c2-cff17945550d",
                          "requirements": "RoBERTa is trained using 60% sparsity and a modified version of APT that doesn't use self-distillation (APT w/o $D_S$)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "2a30eeb9-1943-47df-81a6-112e7030e9f9",
                          "requirements": "The results related to self-distillation have been replicated",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "10f451dd-7fac-4566-9e55-1d66c7beceb5",
                              "requirements": "The recorded metrics show that pruning RoBERTa with APT w/o $D_S$ has roughly 20% faster training time than full APT",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            },
                            {
                              "id": "9c90df0a-aa9f-4c71-be71-69f5cac2ccc0",
                              "requirements": "The recorded metrics show that pruning RoBERTa with APT w/o $D_S$ costs roughly 10% less training memory than full APT",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "all-in-one",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "6fb3259f-edad-4b55-85fb-0deb441df867",
          "requirements": "The paper \"All-in-one simulation-based inference\" has been reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "8c706efd-f14e-4756-a8e9-303d747db56a",
              "requirements": "Variance Exploding SDE (VESDE) is implemented, as described in A2.1",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "0ac16f05-bdb9-48c8-9103-764068f5301a",
                  "requirements": "The drift term for Variance Exploding SDE is defined as $f(x, t)=0$",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "1402caf0-ee17-48a4-b0f5-ee4523807747",
                  "requirements": "The diffusion term for Variance Exploding SDE is defined as $g(t)=\\sigma_{min} \\cdot (\\frac{\\sigma_{max}}{\\sigma_{min}})^t \\cdot \\sqrt{2 \\log \\frac{\\sigma_{max}}{\\sigma_{min}}}$",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "396c0b27-9d8c-49d4-a9e8-667b7c1a9e5c",
                  "requirements": "The perturbation kernel for the Variance Exploding SDE is defined as $p(x_t|x_0) = \\mathcal{N}(x_t, x_t, \\sigma(t)I)$ where $\\sigma(t) = \\sigma_{min}^2\\left( \\frac{\\sigma_{max}}{\\sigma_{min}} \\right)^{2t}$",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "07f7aac1-c623-46e0-b7cc-3991331cbd9c",
                  "requirements": "The constant $\\sigma_{max}$ for VESDE is set to 15",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "c6cd56ae-e565-4512-978e-80a8afaae037",
                  "requirements": "The constant $\\sigma_{min}$ for VESDE is set to 0.0001",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "ac3759f1-14f6-4859-a64f-84db470eb2db",
                  "requirements": "In VESDE, samples are drawn from the time interval [1e-5, 1]",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "a439cf9c-8942-4211-a74c-5bf1eae37b3b",
              "requirements": "The Simformer model, training process and inference process has been implemented",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "84ed0540-5940-4906-bc72-5d91da73dac5",
                  "requirements": "The Simformer architecture and tokenizer has been implemented",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "452f012f-547c-4330-abce-315c043e6594",
                      "requirements": "The tokenizer for the Simformer has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e94e3aee-6a46-40d1-84a8-df21110f104c",
                          "requirements": "The tokenizer correctly tokenizes and embeds the identifiers",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "437abe9f-4b33-4293-9c64-d9cf83fd2a55",
                              "requirements": "Each unique variable has an integer identifier. Multiple observations of the same variable share the same identifier",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "714bdd7e-b21c-4407-aa3d-f50307633bb4",
                              "requirements": "The tokenizer uses learnable vector embeddings to embed each identifier",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "af5cd308-83c7-4b2b-bc9f-b006183ea3ed",
                          "requirements": "The embedding for a single value is created by repeating the scalar value to match the desired dimensionality. For example, to embed the value 1 to desired dimensionality N, we would have a vector [1, 1, ...., 1] of length N",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2e46fc8d-2ecb-46f3-86b1-0c80fceec733",
                          "requirements": "The tokenizer correctly tokenizes and embeds the metadata (if required); the tokenizer applies a learnable linear mapping of a random Fourier embedding of the elements in the index set to the desired dimensionality.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2ff0a481-00b4-47e9-939a-4dd7f7a00361",
                          "requirements": "The tokenizer uses learnable vector embeddings to embed each value in a condition state - \"True\" values are mapped to a shared learnable vector embedding, whereas \"False\" values are mapped to zeros (of the desired dimensionality)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "407dcc3b-5f84-48b4-b5e5-730336b97fbe",
                          "requirements": "For each input, the tokenizer concatenates the embeddings of the identifier, value, metadata (if used), and condition state in that order",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c6eb15a5-65f9-4ac9-9927-f50f3118d8fe",
                          "requirements": "The tokenizer takes inputs: a sequence of scalar values, a sequence of integer variable identifiers, a condition mask $M_C$, and optional metadata if required. It embeds these inputs into a sequence of tokens, each of equal dimensionality",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "518fdd2a-c60f-4bbe-b12a-ae0fc80a98d4",
                      "requirements": "The Simformer architecture has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "09008e24-26e7-4aa9-8d9a-881feb20538f",
                          "requirements": "The Simformer model is a slightly modified vanilla encoder-only transformer following the implementation proposed by (Vaswani et al., 2017). The only modification is that the decoder is a single linear layer that produces a single scalar score for each variable token in the input sequence. The Simformer model is described in Section 3, Figure 2, and Appendix A.1",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "b1b80f04-e17c-49f6-831c-3cd3d15acf26",
                          "requirements": "Diffusion time is embedded as a random Gaussian Fourier embedding, and a linear projection of diffusion time is added to the output of each feed-forward block in the transformer",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "25eecc1a-cc2c-48e5-addc-082fdb7f638b",
                          "requirements": "The Simformer takes inputs: the diffusion time $t$, a sequence of tokens from the tokenizer, and an attention mask. These are projected to a sequence of scalar outputs, representing the marginal scores of the diffusion process at time $t$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "99653fba-a2b3-4f81-bf6a-41d49c939527",
                  "requirements": "The condition and attention masks are correctly computed for each sample passed to the Simformer",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "be65afa3-69f8-4f5a-8b0a-a2f7895b0b85",
                      "requirements": "During training, for each training sample, the condition mask $M_C$ is randomly sampled as either 1) the joint distribution, where $M_C=[0, 0, ..., 0]$, 2) the posterior distribution where data variables are observed and parameters are unobserved, 3) the likelihood function where data variables are unobserved and parameter variables are observed, 4) a Bernoulli distribution with p=0.3 (resampled for each element), 5) a Bernoulli distribution with p=0.7 (resampled for each element)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "dbb4968e-bfba-45c3-9c54-45879fefbd9c",
                      "requirements": "The attention mask $M_E$ is correctly computed for each sample passed to the Simformer",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "3e515973-3a59-46ca-b0b6-be1d8b4fea96",
                          "requirements": "$M_E$ is selected to be undirected, directed, or fully dense",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8e07cc4f-6176-4391-a8bb-578831aa3aa4",
                          "requirements": "If $M_E$ is selected to be fully dense, every token is allowed to attend to every other token",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "0cb084f8-8c30-4111-8822-b6f8aa7967b2",
                          "requirements": "The attention mask $M_E$ is correctly computed for the undirected and directed cases",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "08a90ef1-cf86-4bfa-b17a-9269e223a57e",
                              "requirements": "For both undirected and directed cases, the attention mask $M_E$ is computed to capture the known dependencies of the current task. Specifically, each task provides $M_E$ as given by the adjacency matrix of a directed/undirected graphical model with the diagonal set to True.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6f05f0cf-c61a-4ad9-b2b0-a353b7cab492",
                              "requirements": "If $M_E$ is directed it must be updated for a given $M_C$. The algorithm proposed by Webb at al. (2018) is used to add the minimal number of edges required to represent additional dependencies from conditioning as specified in $M_C$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "2c102351-18e1-4eb5-9812-9eea70a83e88",
                  "requirements": "The code for training the Simformer model has been implemented",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "34b6fc70-d083-4bef-986e-336b09845a3c",
                      "requirements": "When training the Simformer, for each training sample $\\hat{x}_0$, the noise level $t$ is sampled in the range [1e-5, 1] to generate a (partially) noisy sample $\\hat{\\mathbf{x}}_t^{M_C} = (1 - M_C) \\cdot \\hat{\\mathbf{x}}_t + M_C \\cdot \\hat{\\mathbf{x}}_0$ i.e. variables that we want to condition on remain clean.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "284fd942-573c-4da6-81bd-2f92cdc4f2b7",
                      "requirements": "The loss function for the Simformer is correctly defined",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0e335268-1035-4b34-b99c-97054665db5c",
                          "requirements": "A diffusion model loss is used that targets (un)conditional marginal score $\\nabla_{\\mathbf{x}_t^{\\text{unobserved}}}\\,\\log p_t(\\mathbf{x}_t^{\\text{unobserved}} \\mid \\mathbf{x}^{\\text{observed}})$ as defined by the condition mask $M_C$ and p(x).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "b3e915ef-1f57-4b70-b3da-546947d6c1b5",
                          "requirements": "As defined in Section 3.3, for each (partially) noisy training sample $\\hat{x}_t^{M_c}$, the Simformer loss is defined as: $\\ell(\\phi, M_C, t, \\hat{\\mathbf{x}}_0, \\hat{\\mathbf{x}}_t) = (1-M_C)\\cdot \\left(s_\\phi^{M_E}(\\hat{\\mathbf{x}}_t^{M_C}, t) - \\nabla_{\\hat{\\mathbf{x}}_t} \\log p_t(\\hat{\\mathbf{x}}_t|\\hat{\\mathbf{x}}_0)\\right)$, where $s_\\phi^{M_E}$ denotes the score model equipped with a specific attention mask $M_E$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "e3cd228e-467b-4c47-a23d-6e212249115e",
                          "requirements": "The Simformer loss is only computed over samples that are unobserved, i.e., they have a value of 0 in $M_C$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2cb4d86f-19c4-438f-b6f1-52c588ba9d09",
                          "requirements": "The total Simformer loss per mini-match is given by a weighted sum, as given by a positive weighting function $\\lambda(t)$ e.g. $\\lambda(t)=g(t)^2$ where $g(t)$ is the diffusion coefficient of the VESDE.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "2165e285-6f2c-4257-bb16-802ffb1c30a4",
                  "requirements": "Code for sampling arbitrary conditionals from a trained Simformer model has been implemented",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "79df6718-c5e7-4967-92b0-4a66d1e8998e",
                      "requirements": "When performing inference using Simformer, the reverse diffusion process is run on all unobserved variables. Observed variables are kept constant at their initial values",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "f7905b54-4c68-46c1-a359-282166d871fd",
                      "requirements": "Euler-Maruyama discretization has been implemented to run the diffusion process backward",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "7c953e3a-a3ec-4c91-a897-c6691ed60a80",
                          "requirements": "Euler-Maruyama discretization has been implemented to run the diffusion process backward for Simformer",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "23d6d4c9-f750-4f5d-8965-b9c2277d5c6a",
                          "requirements": "500 steps are used in the Euler-Maruyama discretization process for Simformer",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "225db93c-4bf3-4b1c-b1fa-13ea37cb7513",
                  "requirements": "The Simformer supports conditioning on intervals.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "32a938b0-0c5c-4e86-a1c0-966aa43d77a4",
                      "requirements": "Algorithm 1 has been implemented such that conditioning on intervals can optionally be selected",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "386472cc-f299-4e46-89c9-95e9b9a4addf",
                          "requirements": "For conditioning on intervals, the self-recurrence is implemented such that a mutable hyperparameter $r$ specifies how many times future points undergo a forward diffusion step followed by a reverse step, incrementally refining each sample.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "39362fd2-1f41-4f81-97ec-ce3c1e893502",
                          "requirements": "For conditioning on intervals, the constraint function is defined as $c(\\hat{x}) = \\hat{x} - u$, where $u$ is a mutable hyperparameter",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "091fd46a-e09e-4989-986b-2a14ba8b6e25",
                          "requirements": "For conditioning on intervals, the scaling function $s(t)$ is defined as $s(t)=\\frac{1}{\\sigma(t)^2)|$, i.e., inversely proportional to the variance",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "58d5bd8c-e8c0-41d7-aa31-684e0e0ddc61",
                          "requirements": "Algorithm 1 has been fully implemented to sample from conditions specified by the constraint function.",
                          "weight": 3,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f5b9aa3e-f51e-4071-ad3c-fa381e0c060b",
                      "requirements": "Conditioning on intervals can optionally be used when sampling",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "7a83a930-4571-4f37-a14f-ccd065832d07",
              "requirements": "Baseline methods Neural Posterior Estimation (NPE), Neural Ratio Estimation (NRE), and Neural Likelihood Estimation (NLE) are implemented",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "ad5f1aac-30cc-425c-bc8a-409a58a71447",
                  "requirements": "The sbi library (Tejero-Cantero et al., 2020) is used to implement NPE, NRE, and NLE. Default parameters from the library are used, aside from using a more expressive neural spine flow for NPE and NLE",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "ee41ea7c-8c0f-4f87-95cc-a1f2258596a6",
                  "requirements": "Each method NPE, NRE, and NLE is trained using the provided training loop (e.g. sbi.SNPE().train())",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "31ed240f-4e9c-489b-89ae-6ed46a85e8d8",
                  "requirements": "Each method NPE, NRE and NLE uses a batch size of 1000",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "6a1ddafa-29df-4e46-bc3e-71236a0b7d76",
                  "requirements": "Each method NPE, NRE and NLE uses the Adam optimizer",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "56dcd071-8f39-4131-97cd-f6d011e99cf5",
                  "requirements": "Early stopping is used to stop training early depending on validation loss",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "0ad49ef2-9746-4c76-b208-8c384f91b6fb",
              "requirements": "The benchmark tasks are prepared",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "3f527fcf-07ec-42f1-8079-9fba3eadfb62",
                  "requirements": "The benchmark tasks are prepared as specified in Section A.2.2",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "a357f51e-61be-4e6c-83d6-45ce645bcf46",
                      "requirements": "The four benchmark tasks in (Lueckmann et al., 2021) are prepared, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "23688299-d3fa-43ed-be9f-2fa2b2c40fa4",
                          "requirements": "The tasks Gaussian Linear, Gaussian Mixture, Two Moons, and SLCP are available such that synthetic data can be sampled from each task",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "c4c06ba2-a749-432b-a92f-5770bd95e974",
                          "requirements": "For Two Moons, the method to obtain N reference samples for a possible conditional can be computed",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9fa888e9-7fb0-4a65-8322-e26c7a021143",
                              "requirements": "N Markov chains with samples are initialized from the joint distribuiton",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "ed3ab4fa-52b1-4328-8d90-988292d02e8f",
                              "requirements": "1000 steps of a random direction slice sampling algorithm are run",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "e4d0c4d5-593a-432a-b5f7-6216655ab5f5",
                              "requirements": "An additional 3000 steps of Metropolis-Hastings Markov Chain Monte Carlo (MHMCMC) are run with step size of 0.01",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "92486973-e7a9-4da9-8a38-556e3bae3dd9",
                              "requirements": "Only the last samples of each chain are considered, yielding N reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "0cf2dd7e-ae82-4367-a4b5-319bf002944b",
                          "requirements": "For SLCP, the method to obtain N reference samples for a possible conditional can be computed",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "af3a4299-578a-4cdd-abb6-021e5c1f5c7d",
                              "requirements": "N Markov chains with samples are initialized from the joint distribuiton",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "028a6cbe-387e-456d-941c-0c4a4b970dd5",
                              "requirements": "600 steps of a random direction slice sampling algorithm are run",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "1e941abb-e1d9-4f91-958c-db60dad4c82e",
                              "requirements": "An additional 2000 steps of Metropolis-Hastings Markov Chain Monte Carlo (MHMCMC) are run with step size of 0.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "0051bf87-8706-4531-9b1d-00bbb499d8e4",
                              "requirements": "Only the last samples of each chain are considered, yielding N reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c09ac29b-6e1f-492a-bb28-0fd1e0921ee8",
                          "requirements": "For each of the tasks Gaussian Linear, Gaussian Mixture, Two Moons, and SLCP, N >= 1000 reference samples are generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "7b6ba22b-2426-4c42-87f3-ca873ea83403",
                      "requirements": "The Tree task is prepared, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "1f652a29-c4c5-4d71-a7e5-9071b6a7da18",
                          "requirements": "The Tree task is available such that synthetic data can be sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "a336830e-9ea1-4c01-911b-5ef6ab18f5a3",
                          "requirements": "For Tree, the method to obtain N reference samples for a possible conditional can be computed",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "acc664bc-89fb-4b2d-8813-330dc6a109b7",
                              "requirements": "N Markov chains with samples are initialized from the joint distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "35e0a7bf-ddf7-429e-a1e3-a298bffcc301",
                              "requirements": "5000 steps of a HMC sampler is run",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "462ad866-65cb-4e08-bbd4-83dd471d9358",
                              "requirements": "Only the last samples of each chain are considered, yielding N reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "36605b43-ee09-4877-a74e-c5250de7a110",
                          "requirements": "For the Tree task, N >= 1000 reference samples are generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "640b9d2b-b40f-4d22-b9ed-a383e0b995c3",
                      "requirements": "The HMM task is prepared, as described in A2.2, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "6fc3436c-8304-4955-801b-0e35528e425d",
                          "requirements": "The HMM task is available such that synthetic data can be sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "8556e276-9c22-410f-a4b1-ab9789f87a9d",
                          "requirements": "For HMM, the method to obtain N reference samples for a possible conditional can be computed",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "52f952b5-752a-4f30-9b53-edd0a3543361",
                              "requirements": "N Markov chains with samples are initialized from the joint distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "293a5a7e-aa99-420c-9af6-9c47e07bedb3",
                              "requirements": "5000 steps of a HMC sampler is run",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "bc5f359e-8302-4a9d-a617-6e3312aea9cc",
                              "requirements": "Only the last samples of each chain are considered, yielding N reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "321d7fd3-71de-4092-907f-c6197f0a7f69",
                          "requirements": "For the HMM task, N >= 1000 reference samples are generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "2eccea68-c454-44df-ad98-22640297231a",
                      "requirements": "The Lotka Volterra task is prepared, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "9f70a4e5-0896-4778-814a-1a3dee705854",
                          "requirements": "The Lotka Volterra task is available such that synthetic data can be sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "bcf546a2-f0a7-42e5-9956-3bc18b67483a",
                          "requirements": "For Lotka-Volterra, inference is performed for the full time-series and the implementation doesn't rely on summary statistics.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "efe8edda-ebfa-4363-b13a-28bcb3d95ae3",
                          "requirements": "In the Lotka Volterra task, to each simulation, Gaussian observation noise is added with $\\sigma=0.1$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "460565d1-b20d-449e-abfe-cd786d94f21a",
                      "requirements": "The SIRD task is prepared, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b96b17cd-fe54-4a06-9c95-5883018d631e",
                          "requirements": "The SIRD task is available such that synthetic data can be sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "6c80714a-4f4e-4cae-9792-9fff064e4e5f",
                          "requirements": "In the SIRD task, a uniform prior is imposed on the global variables $\\gamma, \\delta$ denoted as $\\gamma, \\delta \\sim \\text{Unif}(0, 0.5)$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "22bc638a-ddbe-40f5-9de2-4436b28f62bf",
                          "requirements": "In the SIRD task, for the time-dependent contact rate, $\\hat{\\beta} \\sim \\mathcal{G}(0, k)$ is first sampled from a gaussian prior with $k$ representing an RBF kernel defined as $k(t_1, t_2) = 2.5^2 \\exp\\left(-\\frac{1}{2} \\frac{\\|t_1 - t_2\\|^2}{7^2}\\right)$, then is transformed via a sigmoid function",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "4332dc3c-76d7-4b84-b317-35e82990b266",
                          "requirements": "In the SIRD task, the contact rate is implemented to vary over time, whereas the recovery and death rate are constant in time.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "19f4319f-3056-4264-8fe4-3b4d13fe7a27",
                          "requirements": "In the SIRD task, observational data is modeled with log-normal noise with a mean of $S(t)$ and a standard deviation of $\\sigma=0.05$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "a3cb2ba7-578e-4589-9a32-ddcd65b94f01",
                      "requirements": "The Hodgkin-Huxley task is prepared, as described in A2.2",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "64541d71-1b37-49be-9a3a-69bf786b3427",
                          "requirements": "The Hodgkin-Huxley task is available such that synthetic data can be sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "4884d911-0bd8-4a99-a4a5-2721b7185072",
                          "requirements": "In the Hodgkin-Huxley task, the initial membrane voltage is established at $V_0=-65.0mV$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "548511a5-0bfe-451b-8c1d-3b2ecc5693bd",
                          "requirements": "In the Hodgkin-Huxley task, simulations are conducted over a duration of 200ms",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "688df55a-5c45-4a79-8f1f-0aff770d4167",
                          "requirements": "In the Hodgkin-Huxley task, an input current of 4mA is applied in the interval between 50ms and 150ms",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "57d03e3d-386c-4163-9945-428714362bfd",
                          "requirements": "In the Hodgkin-Huxley task, the rate functions as defined following the equations in A2.2",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "5b2d5ce9-207a-47a0-8304-81c6bad86a69",
                          "requirements": "In the Hodgkin-Huxley task, energy consumption is computed based on sodium charge, converted into $\\mu J/s$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e2719676-7dc5-4fdd-a38a-eeadc6f81b27",
                          "requirements": "In the Hodgkin-Huxley task, for observational data, the summary features are: spike count, resting potential mean, resting potential std, spiking window mean, and centered and standardizes moments up to 4th order",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "0b14bb53-e680-4ca6-a662-819ecd08cb16",
                          "requirements": "In the Hodgkin-Huxley task, the simulator-generated noisy time series is reduced to the correct summary statistics",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "d342c64a-005d-44f8-88af-5d650c363011",
                          "requirements": "In the Hodgkin-Huxley task, the metabolic cost consumed by the circuit is recorded and and added as an additional statistic",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d0a2a0d9-e828-4a2a-bccc-377b8eff3fe1",
                  "requirements": "The C2ST metric has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3957cfb9-2e44-4026-be71-7d87d2c91583",
                      "requirements": "Given inputs X and Y, the classifier-based two-sample test accuracy between X and Y is measured as the 5-fold cross-validation score",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "982f7456-e34d-40be-a4a9-76c32826d301",
                      "requirements": "The classifier is a random forest classifier with 100 trees",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "973db5a3-21f4-48d0-8853-a5047626a637",
                      "requirements": "A score of 0.5 signifies perfect alignment with the ground truth posterior, and 1.0 indicates that a classifier can completely distinguish between the approximation and the ground truth",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "fe277dc1-7433-4bfe-bee3-9169ce93ad4c",
              "requirements": "The recorded metrics show that the results from section 4 are replicated",
              "weight": 6,
              "sub_tasks": [
                {
                  "id": "5287b6eb-3425-48a8-87e1-66db607097ac",
                  "requirements": "The hyperparameters for Simformer stated in Section A.2.1 are used in all experiments, unless otherwise stated",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "cdf1bfdd-53dd-420a-83f6-0a110ba9d765",
                      "requirements": "All Simformers have a token dimension of 50",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "e9edc2a0-3809-4e69-b9b6-1686b2955aa9",
                      "requirements": "All Simformers have 4 heads",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "32e4ef3f-9fdc-4845-a2ac-7c988141c039",
                      "requirements": "In all Simformers, the dimensionality of the key, query and value is 10",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "da87d682-3f30-443c-b318-8bb158048285",
                      "requirements": "In all Simformers, the random Gaussian Fourier embedding used in the tokenizer to embed metadata objects has 128 dimensions (if required)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "5963d717-2765-4535-80d8-8a92a9052a21",
                      "requirements": "In all Simformers, the random Gaussian Fourier embedding used for diffusion time has 256 dimensions",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "85db9bf8-1b9c-4d82-8b53-1813b1d31b3a",
                      "requirements": "In all Simformers, the feed-forward block expands to a hidden dimension of 150.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b18e9e5a-0079-420f-9222-4380004418ef",
                      "requirements": "In all Simformers, a batch size of 1000 is used",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "831ca2ca-49a9-46c0-a63a-a39c877050a5",
                      "requirements": "The Adam optimizer is used to train all Simformers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "7ec03b27-0737-4e4a-9581-bc4720744a1a",
                  "requirements": "Variance Exploding SDE (VESDE) is used to train the Simformer in all experiments",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "6dcabf24-d932-42d7-969e-027952e673e7",
                  "requirements": "The recorded metrics show that the results in section 4.1 have been replicated",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "237efc4f-17f7-4078-b987-802bebdefa43",
                      "requirements": "Simformers used for all experiments in Section 4.1 have 6 layers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "dbb88487-ba68-4776-8f94-127e2a0c0a2e",
                      "requirements": "The experiments in 4.1 related to approximating the posterior distribution have been replicated",
                      "weight": 3,
                      "sub_tasks": [
                        {
                          "id": "89b6ac69-3bb1-414b-a77b-c134bae12d71",
                          "requirements": "For each task Linear Gaussian, Mixture Gaussian, Two Moons, SLCP, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) NPE, 2) Simformer (with a dense attention mask), 3) Simformer with an undirected graph for it's attention mask, 4) Simformer with a directed graph for it's attention mask",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f71d87cb-8775-4078-b570-53d1db40dbd1",
                              "requirements": "For the Linear Gaussian task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) NPE, 2) Simformer, 3) Simformer with an undirected graph for it's attention mask, 4) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "bc21d6d1-49a5-45d0-93cc-cb42241275b4",
                                  "requirements": "For the Linear Gaussian task, NPE has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "71d1e184-3e0e-46da-883c-c8a55244c3b5",
                                  "requirements": "For the Linear Gaussian task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "3628b28c-b00b-458e-8e1d-1ac6f5e47411",
                                  "requirements": "For the Linear Gaussian task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8f4524fc-48f5-4615-bd33-aedc2aa58d3a",
                                  "requirements": "For the Linear Gaussian task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6aeb57d8-a135-4f03-ac45-a7927da55369",
                              "requirements": "For the Mixture Gaussian task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) NPE, 2) Simformer (with a dense attention mask), 3) Simformer with an undirected graph for it's attention mask, 4) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "174cb2a9-b358-4ca7-86e0-ea85ac02cc93",
                                  "requirements": "For the Mixture Gaussian task, NPE has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "20c740b8-19b8-416e-b35b-e4d98db613d1",
                                  "requirements": "For the Mixture Gaussian task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "152f3333-1368-4e19-a14f-f68c1cc26eb7",
                                  "requirements": "For the Mixture Gaussian task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "fabc5fd9-a064-48d0-8da2-17bd643b8136",
                                  "requirements": "For the Mixture Gaussian task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7365fc07-bb4c-4744-8770-9bf04bd03916",
                              "requirements": "For the Two Moons task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) NPE, 2) Simformer (with a dense attention mask), 3) Simformer with an undirected graph for it's attention mask, 4) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a5d7b1c2-bf1e-4b84-a3ad-995892f597b8",
                                  "requirements": "For the Two Moons task, NPE has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "d47f5e4e-23ec-41f9-96c5-18a471eba572",
                                  "requirements": "For the Two Moons task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "629c1323-a808-4f83-9cfd-cdbe4d93cf46",
                                  "requirements": "For the Two Moons task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ec9c4b69-613a-42c3-8224-cef629f103ce",
                                  "requirements": "For the Two Moons task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ed25b914-62f6-4056-a678-f1ba819892f4",
                              "requirements": "For the SLCP task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) NPE, 2) Simformer (with a dense attention mask), 3) Simformer with an undirected graph for it's attention mask, 4) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f2ad95c5-369c-4c20-859e-2f4931957879",
                                  "requirements": "For the SLCP task, NPE has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "3859bb58-dad4-4fe6-9c15-1b802e35ac9e",
                                  "requirements": "For the SLCP task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "fe86ca91-12bb-4ceb-bc1b-254a7aa9aa42",
                                  "requirements": "For the SLCP task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5bbb52eb-424e-4711-9fad-48011f6af612",
                                  "requirements": "For the SLCP task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3fca5db9-2b7b-42dd-bbb8-709de985d349",
                          "requirements": "For each task Linear Gaussian, Mixture Gaussian, Two Moons, SLCP, samples for ten ground-truth posteriors are obtained",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a4ad0e3d-c2ff-417d-a9b4-6b8bbcd00669",
                              "requirements": "For the Linear Gaussian task, samples for ten ground-truth posteriors are obtained",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2ac19789-276a-4951-9d90-ba7a357511fb",
                              "requirements": "For the Mixture Gaussian task, samples for ten ground-truth posteriors are obtained",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fd64cfd0-746e-4441-bdc5-2b9bbef4e680",
                              "requirements": "For the Two Moons task, samples for ten ground-truth posteriors are obtained",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "8f6a3486-8f4c-4c48-ab4f-9e0e8f16bf13",
                              "requirements": "For the SLCP task, samples for ten ground-truth posteriors are obtained",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "86946725-2c72-4cbe-8829-f26723dedd03",
                          "requirements": "For each task Linear Gaussian, Mixture Gaussian, Two Moons, SLCP, for each model trained for 10^3, 10^4, and 10^5 simulations, N posterior samples are generated from the 10 different reference observations, where N is the number of reference samples",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3a9eb157-8938-4dcc-be3d-a3a8bd128a6b",
                              "requirements": "For the Linear Gaussian task, for each model trained for 10^3, 10^4, and 10^5 simulations, N posterior samples are generated from the 10 different reference observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "157423ff-ee2b-437e-b2ca-bcec8d433b3b",
                              "requirements": "For the Mixture Gaussian task, for each model trained for 10^3, 10^4, and 10^5 simulations, N posterior samples are generated from the 10 different reference observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "56cf845a-2871-4367-ab5f-de7eeca6ad8a",
                              "requirements": "For the Two Moons task, for each model trained for 10^3, 10^4, and 10^5 simulations, N posterior samples are generated from the 10 different reference observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "2270f417-52ab-4467-89ab-abbd8f8bc4ea",
                              "requirements": "For the SLCP task, for each model trained for 10^3, 10^4, and 10^5 simulations, N posterior samples are generated from the 10 different reference observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8ef89a76-6998-4e08-8980-cfed46328456",
                          "requirements": "For each task Linear Gaussian, Mixture Gaussian, Two Moons, SLCP, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors and ground-truth posteriors have been calculated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "183cc3f0-b19b-4a34-a217-5b912f33b69c",
                              "requirements": "For the Linear Gaussian task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "59965170-0553-49cb-9c56-10f156301c77",
                              "requirements": "For the Mixture Gaussian task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "1149eae8-db2d-45ae-ac54-77551d12013d",
                              "requirements": "For the Two Moons task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "6a97b353-6945-48ab-96cf-63640b596fbb",
                              "requirements": "For the SLCP task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "7cb21bb8-ed7b-4509-87e2-235d613c4637",
                          "requirements": "Results Analysis",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "a7604584-412e-4c92-9b49-7063bf40af90",
                              "requirements": "Across all four benchmark tasks (Linear Gaussian, Mixture Gaussian. Two Moons, SLCP) when approximating the posterior distribution, all Simformer variants almost always outperform neural posterior estimation (NPE) wrt. C2ST accuracy",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "1755440f-b437-4700-b2c0-5740d5188fa4",
                              "requirements": "When approximating the posterior distribution, both the Simformer with undirected graph and Simformer with directed graph significantly outperform the regular Simformer on the Linear Gaussian and SLCP tasks wrt. C2ST accuracy",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "86499107-3abb-4381-9c83-359efa66286a",
                              "requirements": "When approximating the posterior distribution, averaged across all benchmark tasks (Linear Gaussian, Mixture Gaussian. Two Moons, SLCP) and number of simulations used in training, the Simformer required about 10 times fewer simulations than NPE to achieve similar performance wrt. C2ST accuracy",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4b06966e-21fb-4c41-ba8b-06a73d07c850",
                      "requirements": "The experiments in 4.1 related to evaluating arbitrary conditionals have been replicated",
                      "weight": 3,
                      "sub_tasks": [
                        {
                          "id": "d5f01a00-bde6-42fb-93bd-14dc3304e738",
                          "requirements": "For the Tree and HMM tasks, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) Simformer (with a dense attention mask), 2) Simformer with an undirected graph for it's attention mask, 3) Simformer with a directed graph for it's attention mask",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "670708ce-eb6a-41bd-b4d7-9d5b2a34f17a",
                              "requirements": "For the Tree task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) Simformer (with a dense attention mask), 2) Simformer with an undirected graph for it's attention mask, 3) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4a7698c5-edcd-4b67-a17b-a0f1230856a7",
                                  "requirements": "For the Tree task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5fdb707e-4c2d-4a5d-96d6-d798c260dd79",
                                  "requirements": "For the Tree task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5730c287-4b2c-43de-8b46-c60219839c1d",
                                  "requirements": "For the Tree task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "36e9c98e-ff38-4cce-9570-3516722f74cc",
                              "requirements": "For the HMM task, each of the following models have been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs): 1) Simformer (with a dense attention mask), 2) Simformer with an undirected graph for it's attention mask, 3) Simformer with a directed graph for it's attention mask",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ee48f977-2f31-4cb6-a34f-589699af5fa3",
                                  "requirements": "For the HMM task, Simformer (with a dense attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "dbb902c0-3beb-475e-b1e4-e93ba3d9a3d9",
                                  "requirements": "For the HMM task, Simformer (with an undirected graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "0ec528ea-7dc7-4420-ae51-359d30bacd47",
                                  "requirements": "For the HMM task, Simformer (with a directed graph for it's attention mask) has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ed3d37e3-fe23-4b1e-bade-445f4803604a",
                          "requirements": "For each task Tree, HMM, Two Moons, and SLCP, ground truth posterior samples with Markov-Chain Monte-Carlo are generated on 100 randomly sampled selected conditional or full joint distributions",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "dd3a0c20-a060-420d-ab30-2d2f306e1592",
                              "requirements": "For the Tree task, ground truth posterior samples with Markov-Chain Monte-Carlo are generated on 100 randomly sampled selected conditional or full joint distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "82cb5063-8d65-4270-bbf2-263bed38d932",
                              "requirements": "For the HMM task, ground truth posterior samples with Markov-Chain Monte-Carlo are generated on 100 randomly sampled selected conditional or full joint distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "409deb4c-dab8-4430-ac6d-9ca3026707e3",
                              "requirements": "For the Two Moons task, ground truth posterior samples with Markov-Chain Monte-Carlo are generated on 100 randomly sampled selected conditional or full joint distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c2239ebc-0b8c-4651-9561-353cc0db8ce2",
                              "requirements": "For the SLCP task, ground truth posterior samples with Markov-Chain Monte-Carlo are generated on 100 randomly sampled selected conditional or full joint distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f7583837-d547-432c-bc01-4fc1789c8ad3",
                          "requirements": "For each task Tree, HMM, Two Moons, and SLCP, for each model trained for 10^3, 10^4, and 10^5 simulations, for each of the ground truth posterior samples, N model-generated posteriors are created by conditioning on the observations, where N is the number of reference samples",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "77fa71bf-bb82-4bfc-b03b-428b37278f91",
                              "requirements": "For the Tree task, for each model trained for 10^3, 10^4, and 10^5 simulations, for each of the ground truth posterior samples, N model-generated posteriors are created by conditioning on the observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "913b099a-e731-4a8a-8a91-ccfb4ef5e650",
                              "requirements": "For the HMM task, for each model trained for 10^3, 10^4, and 10^5 simulations, for each of the ground truth posterior samples, N model-generated posteriors are created by conditioning on the observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7413d98d-aa4b-4dd4-90b7-acf047652b39",
                              "requirements": "For the Two Moons task, for each model trained for 10^3, 10^4, and 10^5 simulations, for each of the ground truth posterior samples, N model-generated posteriors are created by conditioning on the observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a2fe39cd-7147-490e-ad88-49b391d9b2a0",
                              "requirements": "For the SLCP task, for each model trained for 10^3, 10^4, and 10^5 simulations, for each of the ground truth posterior samples, N model-generated posteriors are created by conditioning on the observations, where N is the number of reference samples",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "9bab456c-e8f2-48d6-9de1-50419853f1d3",
                          "requirements": "For each task Tree, HMM, Two Moons, and SLCP, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors (trained on 10^3, 10^4 and 10^5 simulations and conditioned on observations) and ground-truth posteriors have been calculated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "c1fdd141-a393-4471-abc9-02347a235cbb",
                              "requirements": "For the Tree task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors (trained on 10^3, 10^4 and 10^5 simulations and conditioned on observations) and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "0ece9e6e-a75c-4aa1-aad8-bf5fead43be6",
                              "requirements": "For the HMM task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors (trained on 10^3, 10^4 and 10^5 simulations and conditioned on observations) and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2a4fd54c-7609-4bca-be6e-821a1b941bd9",
                              "requirements": "For the Two Moons task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors (trained on 10^3, 10^4 and 10^5 simulations and conditioned on observations) and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "99bb3116-25c7-4b6f-9f09-e97f8b0339eb",
                              "requirements": "For the SLCP task, for each model trained for 10^3, 10^4, and 10^5 simulations, Classifier Two-Sample Test accuracy between the model-generated posteriors (trained on 10^3, 10^4 and 10^5 simulations and conditioned on observations) and ground-truth posteriors have been calculated",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "b858fec6-3c95-4e5e-89e1-02d441f30cab",
                          "requirements": "When evaluating arbitrary conditionals on tasks Tree, HMM, Two Moons, and SLCP, when trained with 10^5 simulations, all Simformer models on all tasks achieve low C2ST (below 0.7)",
                          "weight": 3,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5a4f4027-4a4a-4079-913d-2714b8fa054d",
                  "requirements": "The recorded metrics show that the results in section 4.2 have been replicated",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "aa888ef9-bcd4-429d-801b-c0ec0b989e57",
                      "requirements": "The Simformer used for all experiments in Section 4.2 has 8 layers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7ec881a6-1960-450d-a466-12f0ba03d52d",
                      "requirements": "The Simformer in section 4.2 has been trained for 10^3, 10^4, and 10^5 simulations (in separate training runs)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "4a41cf69-dfce-4b8a-9992-882edc610757",
                      "requirements": "Samples from the Simformer have been generated, conditioning on four synthetic prey observations",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "f4bb304f-5350-49e4-ba0a-c57b664c42ba",
                          "requirements": "Four synthetic prey observations are sampled at random times",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "1f9a15cb-263a-4fb9-957f-2eab2212ffb0",
                          "requirements": "The Simformer trained on 10^5 simulations of Lotka-Volterra is used with a dense attention mask to infer the posterior distribution on a uniform grid between t=0 and t=15, given the four synthetic observations and posterior predictive samples for unobserved predator and prey variables.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2da3fc50-59bb-466c-b167-7cf44c86e029",
                          "requirements": "The ground truth parameter is usually within regions of high posterior probability, using the Simformer with a dense attention mask trained on 10^5 simulations of Lotka-Volterra",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9701fea0-3f18-4789-9003-81f4e348fcc3",
                      "requirements": "Results have been computed after sampling an additional nine synthetic predator observations",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "6cae1579-72c2-4f69-8c5f-47a6a3941aa9",
                          "requirements": "Nine additional synthetic observations of the predator population are sampled from Lotka-Volterra at random times",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "c31c4bfa-12c2-4326-adb4-7cf06384a800",
                          "requirements": "The Simformer (trained on 10^5 simulations of Lotka-Volterra) with a dense attention mask is used to infer the posterior distribution given the four prey synthetic observations and nine predator synthetic observations",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0f4a0b23-a0d9-4f11-bc99-9af8c899ad7b",
                          "requirements": "Including the nine predator synthetic observations reduces the uncertainty in the posterior predictive of both prey and predator populations, when using the Simformer trained on 10^5 simulations of Lotka-Volterra",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "df75afbb-c140-4a59-acb6-df5986ef1780",
                          "requirements": "Including the nine predator measurements reduces the uncertainty in both the posterior, when using the Simformer trained on 10^5 simulations of Lotka-Volterra",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "0e5d1602-6d99-4eb4-abe2-1e3924a98083",
                      "requirements": "The recorded metrics show that results in section 4.2 have been replicated.",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "2551546a-de57-439f-8a62-0090e278638b",
                          "requirements": "All Simformers trained on 10^3, 10^4, 10^5 simulations of Lotka-Volterra are separately used to sample from arbitrary conditional distributions to simultaneously generate posterior and posterior predictive samples",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "173a3eec-8d27-4b7f-8960-678a592e926d",
                          "requirements": "Using the Simformer trained for 10^5 simulations of Lotka-Volterra, the C2ST performance (posterior distribution) is below 0.65",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e87233c0-481d-4b86-bae8-bd37448a9231",
                          "requirements": "Using the Simformer trained for 10^5 simulations of Lotka-Volterra, the C2ST performance (arbitrary conditionals) is below 0.75",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9480ddc4-8a8c-4acc-a8e3-b398cb962672",
                  "requirements": "The recorded metrics show that the results in section 4.3 have been replicated",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "a0b66551-0aea-443f-8936-bc8db21c949b",
                      "requirements": "The Simformer used for all experiments in Section 4.3 has 8 layers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "e0c85d33-977f-4839-b149-312cdfcd5b34",
                      "requirements": "The Simformer used in Section 4.3 uses the dense attention mask",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "62344010-ba29-4d85-a8ce-a92f90387cb9",
                      "requirements": "Results for the Simformer when sampling 5 synthetic observations have been replicated",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "a0864d9d-71ad-4650-aa62-150dd52c2b05",
                          "requirements": "Five synthetic observations are generated from infected, recovered, and deceased individuals at random times",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "78909e7b-adc2-430f-8d2c-698f870ae046",
                          "requirements": "Given the five synthetic observations, the Simformer is applied to obtain samples from the posterior distribution of parameters as well as posterior predictive samples for unobserved  infected, recovered, and deceased values on a regular time grid from 0 to 40",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "81423255-fefa-410a-869f-5fba0a9ce93c",
                          "requirements": "The mean of the death, recovery and contact rate parameters is somewhat close to the true parameter that generated the observations, using the Simformer given the five synthetic observations",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "eeb98ce1-14b2-47f2-af99-c0f06c1ee5f3",
                          "requirements": "The mean of the infected, recovered and death population densities accurately model the sampled observations, using the Simformer given the five synthetic observations",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "231cf3a5-4f4a-4c23-8558-8c87fd31bd5d",
                      "requirements": "Results for the Simformer accurately sampling parameter-conditioned posterior distributions have been replicated",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "a4c1f3af-b890-4414-947c-83ce4ce49ef4",
                          "requirements": "Synthetic observations consisting of four measurements of the time-dependent contact rate parameter is generated and a single synthetic observation of death population is generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "aa314a14-d24f-4371-9738-ea3f62cb9a6c",
                          "requirements": "The Simformer estimated realistic death and recovery rates, using the Simformer given the five synthetic observations",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6e727597-f426-43da-9dd2-481dbc2c2b4b",
                          "requirements": "The predicted mean intercepts all four measurements of the time-dependent contact rate parameter, using the Simformer given the five synthetic observations",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "296dadfa-105d-4e23-aedd-9ce6cde8836b",
                          "requirements": "The predicted mean of the death population intercepts the synthetic observation, using the Simformer given the five synthetic observations",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "11977643-0daa-4866-b388-7c63253bb844",
                  "requirements": "The recorded metrics show that the results in section 4.4 have been replicated",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "4dce6753-f211-4e45-9f86-152ab3367ccb",
                      "requirements": "The Simformer used for all experiments in Section 4.4 has 8 layers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "c9544022-72fb-4e87-977f-84731c412783",
                      "requirements": "The Simformer used in Section 4.4 uses the dense attention mask",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1f1f0d03-49b5-4ca9-89a3-85624c717226",
                      "requirements": "Results when inferring the posterior distribution given only the summary statistics have been replicated",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "2b3aaed1-0d47-4fe4-96df-73b1b8c34c8a",
                          "requirements": "The Simformer infers the posterior distribution given only the summary statistics of the voltage (not the energy)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "17113941-b42f-4662-9b19-d5676fa0e3f9",
                          "requirements": "The posterior distribution has wide marginals for parameters $g_{Na}, g_K$ and narrow marginals for parameters $C_m, g_L$",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "31d0cc76-b73b-4fad-9656-2dda0419e095",
                          "requirements": "Posterior predictive samples are generated from this new posterior (via Simformer and by running the simulation), where this \"new posterior\" is generated given voltage summary statistics",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "edae46eb-6449-451f-8f5d-4936be7bf7bb",
                          "requirements": "The predicted posterior is almost equivalent to the simulated posterior",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2c03b450-acbe-437f-a079-ee5560abf51d",
                          "requirements": "The posterior predictive trace of Simformer closely matched the posterior predictive trace obtained by running the simulator",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "d23997b6-49f6-48ff-b578-5e31505f065f",
                      "requirements": "Results when applying an observation interval have been replicated",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "fa934dce-6547-475e-b231-8206c35d596d",
                          "requirements": "An observation interval is defined for the energy consumption within the lowsest 10% quantile of posterior predictives",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "0a2964da-9bad-44c6-8a6d-b107b6522463",
                          "requirements": "Simformer with guided diffusion is used to infer the posterior given voltage summary statistics and the constraint on energy consumption",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "540ce42f-c72d-491a-87d6-7aa69373fbab",
                          "requirements": "The additional constraint on energy consumption significantly constrained the parameters posterior, in particular the maximal sodium and potassium conductances",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "3c812e66-c1b1-4298-a078-797fd5516d68",
                          "requirements": "Posterior predictive samples are generated from this new posterior (via Simformer and by running the simulation), where this \"new posterior\" is generated given voltage summary statistics and the constraint on energy consumption",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "d01c197f-aece-4023-af49-d1dfb8fc149b",
                          "requirements": "The predicted energy consumption lies below the desired threshold",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4444e56a-ac1a-43b5-8b53-005190291454",
                          "requirements": "The posterior predictive trace of Simformer closely matched the posterior predictive trace obtained by running the simulator",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "bam",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "d84bfb09-98cd-4628-883e-71a454321834",
          "requirements": "The core contributions of the paper \"Batch and match: black-box variational inference with a score-based divergence\" have been reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "e959a383-dfd5-4b2d-ac24-a768900f6265",
              "requirements": "The core variational inference algorithms studied in the paper have been implemented",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "bam-implementation",
                  "requirements": "The Batch and Match (BaM) algorithm for Variational Inference (VI) has been implemented as outlined in Section 3 and Algorithm 1.",
                  "weight": 4,
                  "sub_tasks": [
                    {
                      "id": "bam-interface-output",
                      "requirements": "BaM has been implemented such that, at minimum, it takes batch size, inverse regularization (learning rate), the target score function, the initial mean and the initial covariance as input and outputs the estimated variational parameters.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "bam-batch-step",
                      "requirements": "The 'batch' step from BaM has been correctly implemented as outlined in Section 3 and Algorithm 1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bam-batch-sampling",
                          "requirements": "The 'batch' step in BaM has been implemented such that at each iteration the current estimated mean and covariance matrix are used to sample $z_b$ from a Gaussian for $b = 1, \\dots, B$, where B is the batch size.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "bam-batch-score-computation",
                          "requirements": "The 'batch' step in BaM has been implemented such that at each iteration the \"score\" ($\\nabla \\log (p)$, where $p$ is the density of the target distribution)) can be and is computed for each sampled $z_b$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "bam-batch-statistics",
                          "requirements": "The 'batch' step in BaM has been implemented such that the sample statistics are accumulated following equations (6) and (7), as shown in step 5 of Algorithm 1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "bam-match-step",
                      "requirements": "The 'match' step from BaM has been correctly implemented as outlined in Section 3 and Algorithm 1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bam-qm-equation",
                          "requirements": "The 'match' step in BaM has been implemented such that at each iteration, the U and V matrices have been implemented using the accumulated statistics from the 'batch' step, as outlined in equations (10) and (11) and in step 6 of Algorithm 1.",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "bam-updated-mean",
                          "requirements": "The 'match' step in BaM has been implemented such that at each iteration, the U and V matrices are used along with the accumulated statistics and the inverse regularization (learning rate) to update the estimated mean and covariance using equations (12) and (13) as shown in step 7 of algorithm 1.",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "bam-low-rank-solver-optional",
                          "requirements": "The BaM 'match' step has been implemented such that it optionally supports updating covariance using the update in Lemma B.3, asserting that B<D",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "6320b786-5d6a-40bd-ac47-deb3c3cff4e4",
                      "requirements": "BaM has been implemented such that it generally follows the steps in Algorithm 1.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "advi-implementation",
                  "requirements": "Automatic Differentiation Variational Inference (ADVI) has been implemented as outlined in the provided Algorithm 2 code snippet, supporting a Gaussian variational approximation with full covariance.",
                  "weight": 4,
                  "sub_tasks": [
                    {
                      "id": "advi-setup",
                      "requirements": "ADVI is implemented such that, at minimum, it takes batch size, a learning rate or learning rate schedule, the unnormalized target log density, the initial mean and the initial covariance as input and outputs the estimated variational parameters.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "advi-sampling-step",
                      "requirements": "ADVI has been implemented such that at each iteration, a mini-batch of samples is drawn from the current approximate distribution $q_{t}$, a Gaussian with some mean $\\mu_{t}$ and covariance $\\Sigma_{t}$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "advi-elbo-estimation",
                      "requirements": "ADVI has been implemented such that at each iteration, a stochastic estimate of the (negative) Evidence Lower Bound (ELBO) is computed using the reparameterization trick or an equivalent approach for samples \\(z_b\\sim q_{t}\\). Specifically, the code forms \\(-\\sum_b [\\log p(z_b) - \\log q_t(z_b)]\\).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "advi-update-step",
                      "requirements": "ADVI has been implemented such that the gradient of the negative ELBO (with respect to the variational parameters) is used to update the variational parameters (e.g. via the Adam optimizer) as shown in step 5 of Algorithm 2",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "advi-has-followed-algo2",
                      "requirements": "Overall, the implemented ADVI procedure follows the logic of Algorithm 2",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "28288cd0-0d49-4215-aaff-a59eb10f50a5",
                  "requirements": "Automatic Differentiation Variational Inference (ADVI) \"Score\" variant has been implemented, such that it is identical to the ADVI implementation but rather than using ELBO loss, it uses score-based divergence.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "2b23a5ca-0606-463c-838e-b95f1e69253c",
                  "requirements": "Automatic Differentiation Variational Inference (ADVI) \"Fisher\" variant has been implemented, such that it is identical to the ADVI implementation but rather than using ELBO loss, it uses Fisher divergence",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "gsm-implementation",
                  "requirements": "The Gaussian Score Matching (GSM) approach for Variational Inference (VI) has been implemented as described in Algorithm 3, supporting a Gaussian variational approximation with full covariance.",
                  "weight": 4,
                  "sub_tasks": [
                    {
                      "id": "gsm-interface-output",
                      "requirements": "GSM has been implemented such that it takes, at minimum, a batch size, the unnormalized target density, the initial mean and the initial covariance as input and outputs the estimated variational parameters.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "gsm-iteration-loop",
                      "requirements": "GSM has been implemented such that at each iteration, a mini-batch of samples is drawn from the current approximate distribution $q_{t}$, a Gaussian with some mean $\\mu_{t}$ and covariance $\\Sigma_{t}$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "gsm-score-computation",
                      "requirements": "GSM has been implemented such that at each iteration, for each sampled $z_b$ the target distribution's score \\$s_b = \\nabla \\log \\tilde{p}(z_b)$ is computed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "c8d8bf97-af2f-46be-b070-e5e128586a3a",
                      "requirements": "GSM has been implemented such that at each iteration, for each sampled $z_b$, the updated for mean and covariance are estimated following steps 6 and 7 of Algorithm 3.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "gsm-partial-updates",
                      "requirements": "GSM has been implemented such that each iteration, the variational mean and covariance are updated following step 9 of Algorithm 3.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "gsm-has-followed-algo3",
                      "requirements": "Overall, the GSM procedure has been implemented so that it follows the main steps of Algorithm 3.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "ffe9ade4-968a-484c-8bd4-c8d07430f076",
              "requirements": "The results of section 5.1 have been replicated",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "337c5085-020c-41ec-b709-ad49ad7dd776",
                  "requirements": "Code has been implemented for measuring the forward and reverse empirical KL divergences between two distributions",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "aea0c082-1b85-4a49-9de5-5dbb1bb9efd5",
                  "requirements": "The results of Figure 5.1 and Figure E.3 have been replicated",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "fbed7d83-986d-4a94-97d6-a6b54f0a70b4",
                      "requirements": "BaM, ADVI, ADVI (Score), ADVI (Fisher) and GSM have been run to estimate the posterior of Gaussian distributions with increasing number of dimensions",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d09bc369-1eb5-4ad1-9873-79c8bba1dbf2",
                          "requirements": "Code has been implemented such that Gaussian distributions of dimension $D \\in \\{4, 16, 64, 256\\}$ can be used as target distributions",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "50edd5b6-1d84-4a50-9e2f-9825a51b4c6a",
                              "requirements": "Code has been implemented such that 4-dimensional Gaussian distributions can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "92c9368d-79c0-4811-bac5-4f5c013433a3",
                              "requirements": "Code has been implemented such that 16-dimensional Gaussian distributions can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c970ece1-fb92-4203-aa5d-8e65b145f417",
                              "requirements": "Code has been implemented such that 64-dimensional Gaussian distributions can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "63a772a0-d934-49b8-bb2c-56c2cc3d18cc",
                              "requirements": "Code has been implemented such that 256-dimensional Gaussian distributions can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "9d0ba9cb-6809-48ef-b90a-2e90306fbafd",
                          "requirements": "Code has been implemented such that the score function for a Gaussian distributions of dimension $D \\in \\{4, 16, 64, 256\\}$ can be computed (either analytically or with an autodiff solution)",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d6b2f005-796b-4dc9-9b8e-4b3aeb195ae4",
                              "requirements": "Code has been implemented such that the score function for a 4-dimensional Gaussian distribution can be computed (either analytically or with an autodiff solution)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c7b901f3-450e-41c3-b843-ab635890be05",
                              "requirements": "Code has been implemented such that the score function for a 16-dimensional Gaussian distribution can be computed (either analytically or with an autodiff solution)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "b2ae9111-5996-4b93-8dca-e80a015adf53",
                              "requirements": "Code has been implemented such that the score function for a 64-dimensional Gaussian distribution can be computed (either analytically or with an autodiff solution)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c293cbce-662c-4723-9141-3aa045dbe42e",
                              "requirements": "Code has been implemented such that the score function for a 256-dimensional Gaussian distribution can be computed (either analytically or with an autodiff solution)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "729be366-001c-43aa-93ec-aed0d2250ddd",
                          "requirements": "BaM, ADVI, ADVI (Score), ADVI (Fisher) and GSM have been run to estimate the posterior of Gaussian distributions with increasing number of dimensions",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a391bece-5431-4569-a9a0-7366e402cd63",
                              "requirements": "BaM has been run to estimate the posterior of Gaussian distributions of increasing number of dimensions",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "62a0b2d7-6925-465d-8a76-f56a15dbb1a4",
                                  "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a D-dimensional Gaussian distribution, the learning rate can be set to DB, where B is the batch size",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6f26a16e-0c90-46f2-89bc-74bd0a1c5874",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a D-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "39daebb5-af71-4d2e-a031-5379296040f0",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a D-dimensional Gaussian distribution",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "71097d28-3052-4d89-8810-3d88cde79c5a",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a D-dimensional Gaussian distribution",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3e177584-01ab-47bf-80c3-ee4c2d54091b",
                                  "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a D-dimensional Gaussian distribution, BaM VI can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "40da5875-e968-42dd-86bc-eed6c375b427",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of BaM VI for estimating the posterior of a D-dimensional Gaussian distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4894c77a-3bb7-49f6-ad15-4906c79364fd",
                                  "requirements": "BaM has been run to estimate the posterior of a 4-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2b2f49ba-4aae-49ab-9b5a-9e37674d1e45",
                                      "requirements": "BaM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c5574df9-467c-4e54-916e-3b5a7796d089",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "1876119e-93f1-4ec8-a2bf-efa33f9ecb14",
                                          "requirements": "BaM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "0056fb57-e234-4234-8c1b-3a28ab17112a",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "116b2cae-d3f9-4f0a-a378-ef8e58ebce13",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "b3f2b99a-6930-4274-bfa7-5366da33e733",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "4c09eede-b39e-4176-9447-c97837d19d0e",
                                              "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "8f83d494-95a9-4ad0-af53-ab20deed1801",
                                              "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "db63a034-717a-4b21-8b9b-5fdaec6af548",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "9c0ad632-1c56-4da0-a495-70960c94d4e4",
                                      "requirements": "BaM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "fbdb544e-f50f-470a-8119-2db6b615bf83",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "09e0158e-3be8-43be-8f47-789b7fa5b524",
                                          "requirements": "BaM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "24854988-2cbe-421f-9e40-396440c52923",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "7e41d3f2-2c68-460f-bbfb-da5ee396dac2",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "bdb0681d-a74a-4b30-a9cb-04b43c19d636",
                                          "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "723c33ff-c364-4a99-8a72-2ecf33ff0fc3",
                                              "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "927f15c3-23a9-4b8a-b609-c09ecca3b943",
                                              "requirements": "When using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "c9e6dd41-bbb8-40db-9ba7-52a5246d2af8",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9523f7c4-f76a-4ff7-a1bd-385db42bae02",
                                  "requirements": "BaM has been run to estimate the posterior of a 16-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d08f4a46-2273-4e9d-a5c3-15bc8286e1fd",
                                      "requirements": "BaM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "ee04129e-d7a7-43f3-ac48-f0a483d8e110",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "44e4875f-420e-43aa-b399-a8cb531f2e80",
                                          "requirements": "BaM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "15fcd6ee-7f48-4b38-af7f-10cf71ee4a04",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "37efb491-ab72-46ff-ac01-be182e669cf9",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "ab84912a-4ff2-40ed-a9c8-b18dccf6db56",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "039d5a5b-c720-4bf7-87af-d3ee4c6e5384",
                                              "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "e753e316-198c-4b34-bfd6-c7d6a9a070ad",
                                              "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "7b934673-9cd7-489d-a0b9-07a5634dd6a8",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "10f4375e-6777-41ac-84ac-e1cca9dad1b6",
                                      "requirements": "BaM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "b35f2cfb-a024-4f04-8455-9901825390f4",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "1db9cd8d-b056-4cdf-bfee-a9eb852d9cf1",
                                          "requirements": "BaM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "27fcf00d-f195-42c9-9a17-c383d656c24f",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "4c9ff8c5-b168-4c51-8703-07a92a58adfa",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "a1e6aa6a-9aca-4b0f-b24e-126c0b2e5225",
                                          "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "6aec384e-ea26-4299-8a0c-72d5ed13c7e8",
                                              "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "a002e9a2-c102-4568-bb4d-e1074d7613bf",
                                              "requirements": "When using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "c72f3d40-e998-466a-a89f-e7f503fe1ab8",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 15 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "38e7e205-fead-48be-b6fd-835857dee712",
                                  "requirements": "BaM has been run to estimate the posterior of a 64-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b50a05c9-3ae6-47b9-8351-6163846991dc",
                                      "requirements": "BaM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c2e800f3-4cd4-453a-9352-37cf844759e5",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "60cc1054-45fc-4cb8-955e-41d6da1541f1",
                                          "requirements": "BaM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "377271e7-fb3a-495f-995c-6fe875ffcbd8",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "667cffc6-13a3-4fd1-9ac2-ac8412089d9a",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "d5353c26-db26-4257-bd5d-5d0fcb44f0ac",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "45133900-476a-4761-bd13-d305ab5cec73",
                                              "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "e0b6bfdd-c621-49ba-8d60-acf649b4b0c0",
                                              "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "212933eb-607c-409c-ae38-b5e839252b71",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "b49d98ca-ae72-4e53-95b5-b73db0bf76bf",
                                      "requirements": "BaM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d3765100-6550-4508-8b98-d98114ef0040",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "194a41c4-2505-446b-bc8f-3dbe6a62e21c",
                                          "requirements": "BaM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "f2a43b87-896f-43ea-99ff-ec29cb4b8e5f",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "f8b76c87-6e7c-4657-9df8-53953550f729",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "b8f31e81-5f2f-4039-be45-67f346243a43",
                                          "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "f8305d21-f8b3-4e32-8659-e5b2f0bfbf97",
                                              "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "c223b970-8c42-46e5-94b8-d2bff394e4fe",
                                              "requirements": "When using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "705c39a5-6a5a-4e0f-9c24-ab2d79b914c5",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 40 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ba36d907-9ea5-4757-be2d-8d2401be5204",
                                  "requirements": "BaM has been run to estimate the posterior of a 256-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c3db5013-4d0d-4f81-968e-3461bafb9271",
                                      "requirements": "BaM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "39e40367-ba29-4826-bcd3-fb6e1dc7963e",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "0542821d-25db-4819-aa43-79f889e294c6",
                                          "requirements": "BaM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "db61caee-7c7d-4bae-9c7b-b26ef18e69e6",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "ba9893da-59e7-45b0-b0dd-399883daaee0",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "dbf7b8d8-99c9-4df1-a8aa-b79341d35b2f",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "86d49309-597f-4d98-8f66-165226007954",
                                              "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "bea69362-bf5e-4080-8934-6ea319224005",
                                              "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "349bd088-ece1-4e07-a7a8-384b85077878",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "b68d2ab4-0679-4c38-8cfb-fcff581d3d64",
                                      "requirements": "BaM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "a21ce6b6-2b35-4227-878f-d1635b2c9493",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "ac7d8b06-3bce-47a7-b6b4-8ac2c8c494b3",
                                          "requirements": "BaM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "dd94edbd-a41d-445e-8a2b-59172489d0df",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "61c521c9-8cf9-436a-a141-e124dc8acb41",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150, the learning rate was set to BD",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "c499b98a-6103-4789-a78c-b284ea5aef48",
                                          "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "18b6b769-b2a1-4ff4-b92a-585a997adf20",
                                              "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "1893167f-e0d2-42dc-b64e-af5ac0b0d355",
                                              "requirements": "When using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "bb4d0731-fa2b-4d7e-8977-e3abdccbc566",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 150 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "abc88ea9-b5d3-4990-af50-fa386440755b",
                              "requirements": "GSM has been run to estimate the posterior of Gaussian distributions of increasing number of dimensions",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "67253f08-1f31-4efe-b7d9-90f95a0de792",
                                  "requirements": "Code has been implemented such that when using GSM to estimate the posterior of a D-dimensional Gaussian distribution, GSM can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "e80199a9-f837-4938-9e58-528b9708dcd8",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using GSM to estimate the posterior of a D-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b4146816-ff82-4eda-8456-7d042446eb19",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of GSM for estimating the posterior of a D-dimensional Gaussian distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8f4bda07-4c7d-489c-a1d3-4f6da52b4dd3",
                                  "requirements": "GSM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f6d52f40-cd4c-40d9-a230-be509486b0eb",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "851ebe43-5aec-425a-8a17-ffe296556183",
                                      "requirements": "GSM has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "282b6593-9eed-469d-b27d-846238dee3b0",
                                      "requirements": "When using GSM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a32ab529-4f80-4e7b-97c4-5849d2dda725",
                                      "requirements": "When using GSM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2a37ca79-3836-4de1-ae0d-e6e3d96df615",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b46b5451-70d4-4b61-9b8c-4a92b3954837",
                                  "requirements": "GSM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7421b712-966c-4476-8aff-e0d6247ceb09",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "68a9da7a-bdf0-4bc7-969b-e6e0bc22afd5",
                                      "requirements": "GSM has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "86d80488-be67-489e-ae4b-62ad848c5946",
                                      "requirements": "When using GSM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9cbd1b65-7be1-411c-8748-2fb8cc1eb3cc",
                                      "requirements": "When using GSM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e5281d19-9195-46f1-a380-81c1dbe3961f",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "cc705d52-35fa-4e0e-b3f5-0b2d67bebe00",
                                  "requirements": "GSM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "dd0d8498-77c9-419c-b042-c7befeb3696a",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "8ba2f8bb-a6b9-4a86-b900-e4e5991eff59",
                                      "requirements": "GSM has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6259f215-2b2b-4a8d-ac52-f9d19109ae71",
                                      "requirements": "When using GSM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7fab2d25-d8fc-4f6d-8008-196ebbac7bbb",
                                      "requirements": "When using GSM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b659a37c-65af-4d58-9020-c85e6d3c979d",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8a7025bc-e1b0-4258-835a-f1f7126923be",
                                  "requirements": "GSM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "bcc28907-bf05-4e9f-bba6-490e2516697b",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "215b71b4-e27d-4a60-906d-f7a9a7bc9c79",
                                      "requirements": "GSM has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "85284cb4-5aae-479a-ae72-ffc46f08d866",
                                      "requirements": "When using GSM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ec099917-3d20-4f05-b8f7-4b20083cbe1b",
                                      "requirements": "When using GSM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a0ea8b20-06e5-4728-bfed-a3078bde3d94",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e409348c-6b51-49e9-a7b1-b9cfe127584c",
                              "requirements": "ADVI has been run to estimate the posterior of Gaussian distributions of increasing number of dimensions",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e7325915-a008-4954-be0e-5901babcf792",
                                  "requirements": "Code has been implemented such that when using ADVI to estimate the posterior of a D-dimensional Gaussian distribution, ADVI can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a6f9be76-1337-4d55-be38-09686b2fe584",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI to estimate the posterior of a D-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f032d17c-4130-4ec1-8c53-84352d28a0d0",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI for estimating the posterior of a D-dimensional Gaussian distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "cb864a5e-d686-42a7-85b8-5abea114310b",
                                  "requirements": "ADVI has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e7397fe9-b5fb-4473-beb9-6104e66f8d5a",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "61156dc6-1267-4e9e-b920-d98b26a9fbc7",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 4-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a315b608-8665-46b8-a89f-92f9d3c1dd0d",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "379a38a5-13eb-4712-b7a2-c83bef621dc9",
                                      "requirements": "ADVI has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "18333b3b-4513-46ae-a937-474d08ec0dad",
                                      "requirements": "When using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "24ec6ae5-963d-4eba-876f-c2bc84fc70b9",
                                      "requirements": "When using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ef371648-4dfb-42fa-99fd-e488c79464ea",
                                      "requirements": "When using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b1ce0df4-588b-4ff9-8f37-e8cd8256e8fd",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c3c4f60b-690c-426e-8616-f5d0c8eaacff",
                                  "requirements": "ADVI has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "77c5e4f4-3e37-4d88-9b5f-c1ffb6901a1f",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "3e0ca9f4-b0d4-4003-88fe-7ec12a8875fa",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 16-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "efa7c7ad-da14-4ad0-9487-5085fe0244c8",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "412b5e23-12e9-4f02-94fc-fb31b2220c56",
                                      "requirements": "ADVI has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "64573f8c-e4e0-439f-8318-06b39dd2cafb",
                                      "requirements": "When using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ff35e6b8-d222-45ec-8737-3acad734d39b",
                                      "requirements": "When using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9c292bcb-fb54-43f6-8996-d9d98e306c12",
                                      "requirements": "When using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5316ac87-ca9a-44c1-a83c-44b0172ce7de",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2c4aff27-197d-4d33-8ebf-35a85f3f4f51",
                                  "requirements": "ADVI has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "019702c4-52c7-4988-baf0-51a951707d80",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "ff651be2-f063-4e2b-a0a5-03bdb3b396dc",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 64-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5d231988-06a7-4ba7-b05e-2930586cb8f8",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fa1f6c32-5350-4063-a9a7-5f4a5a3e5d5a",
                                      "requirements": "ADVI has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "989ad570-aee8-4d57-b5fd-73483a537697",
                                      "requirements": "When using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ca477c48-3805-40bf-a826-5675fde38f7b",
                                      "requirements": "When using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "66d03db4-4c97-4d2a-bc8f-4a239709f23f",
                                      "requirements": "When using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "56de9fef-d4fc-4e82-b8cb-55bcb3b01230",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "55f1e1ac-16fc-4b51-8b8e-92156333a44a",
                                  "requirements": "ADVI has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4d4f636e-6121-460e-98c1-090b51342277",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "46ffe5e8-1cfb-4d74-851d-6304a8063fd3",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 256-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7f47c6c1-f0d8-4ffd-9b9d-48c1f16ee772",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fbcd9e0c-f027-4243-aa0c-b5ce3c506294",
                                      "requirements": "ADVI has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "594de7ea-9e09-4dea-b8d1-91d22fe940ff",
                                      "requirements": "When using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "aa6b4efb-58d7-4b78-ad2b-b7509e717a24",
                                      "requirements": "When using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4d3228a0-b083-472a-bb91-a5f4b37494f7",
                                      "requirements": "When using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "01645de4-5857-43b7-94a9-41a6557b87d1",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a5ef5f30-0eff-45e0-ac9b-f5de868edcb6",
                              "requirements": "ADVI (Score) has been run to estimate the posterior of Gaussian distributions of increasing number of dimensions",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0769c811-66e6-45e5-94aa-59575d21db68",
                                  "requirements": "Code has been implemented such that when using ADVI (Score) to estimate the posterior of a D-dimensional Gaussian distribution, ADVI (Score) can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b98057f9-dfc7-48a8-8cf7-c1c15e91bb2e",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Score) to estimate the posterior of a D-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "19c30243-6859-41b1-a85c-bec6a3535bec",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI (Score) for estimating the posterior of a D-dimensional Gaussian distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "977d0326-9cbe-4f4f-8bcb-ea99793a95e7",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7d14bb0-373a-47e1-ac5c-dd91eca1695d",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "172fbeea-8142-445b-b94d-8349006f4659",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c2a2a3d9-7c7f-4124-8803-22cbdf74367e",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9f2fbcd5-bf36-42b9-ad3e-78e273be3363",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "85d734eb-f263-4170-abb3-a29972dd800d",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "eb676011-32a0-43e4-984f-64681709c5a5",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a26df670-5f91-48fe-9b3e-369465202b14",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5b1e168f-5cbd-49f2-b286-fdacb2930c36",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "85683cac-9db3-43f4-aaef-3e2564b798f9",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f5437611-5a59-42b7-9646-0730ee6667b7",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "84ce8524-3641-45ad-ae93-fe86a2794769",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6b84acf9-9d40-4de4-a6fd-4e104107cbb2",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "73118b23-158f-4406-90b7-fbd91b4507aa",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0e43c57d-ccac-486c-a4cc-9723e35cfe76",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9be67ab7-bada-4325-89c2-c241e7c67700",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "85b88c94-1fec-44ca-abfc-05e72f295f24",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2d1b1085-2914-467c-9877-c774adb02f36",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dc0401af-e2d1-4a5f-b1db-0662dc14287f",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "44fd1ea8-3944-4695-918c-9772a867aa73",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "8041942c-0edc-4736-a9ba-d62b6e51a547",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a9dd06c0-2773-4639-a9ad-c0329dc12eaa",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fdc00a0a-08ef-4d77-93cc-609d084a5867",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "07e5a293-cf9b-4210-a4b7-dd9516f089fa",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c580b1c5-edc0-4a8d-9e40-b7a81642532c",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "088bc8dd-e3b4-4266-be9a-3e399301aaf1",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0828d604-6f55-4ebb-bf43-49a2b275877e",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "711397d9-cdeb-4812-a070-f98c5f12e501",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5775d45e-e528-4c0d-b553-82e5b005c089",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "939854ba-18eb-43aa-b498-afb29d6f3e7a",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e307747d-f3a9-4d30-a051-264e819324e5",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ac80844b-3a00-4e2f-98f6-4098b808bc8f",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "897af513-f413-48e0-b1c5-b458a17e3d5b",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "507ddc64-8014-4d36-b83f-62d3d81bedb3",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "09649bc7-b949-4e3c-b899-6c402c3893b3",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "15fd4d08-50b9-438d-8001-38014b42c00f",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "2d8dba46-fdb1-4687-ab35-082fb3bbfef8",
                              "requirements": "ADVI (Fisher) has been run to estimate the posterior of Gaussian distributions of increasing number of dimensions",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "61d2a7ac-d780-45ed-8a66-641d136f208c",
                                  "requirements": "Code has been implemented such that when using ADVI (Fisher) to estimate the posterior of a D-dimensional Gaussian distribution, ADVI (Fisher) can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b9955d65-6a91-45cd-ba42-223b663f3917",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Fisher) to estimate the posterior of a D-dimensional Gaussian distribution",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9e1d9e27-a62f-4135-aeec-ef3ebc8fcc62",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI (Fisher) for estimating the posterior of a D-dimensional Gaussian distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8fa054bb-189c-4c24-9879-f33c32fefad5",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "dc5a24f1-f2b4-4351-87f5-30a1f7585388",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "c4f07ed3-ec49-4ef7-9525-3bde733d1392",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4d1e3198-2915-4ace-a63b-1afc505dbb29",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "962e743b-6ff0-47c0-8bb4-35f08d70dfa2",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "d6dc1999-d11d-42f2-92a5-9cf0db8d61d4",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e1b227a5-1560-4096-9502-c3502c9a1f65",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5105a35f-39ff-4c47-a793-adf8b3b84ccd",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f2ae8ce6-1680-4a35-8e49-dd3b1e07ff2a",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 4-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d5ab4e88-df24-451c-9fc2-d5c9df2d74a5",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f1a39120-2827-4348-8400-c79c79213769",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "a25779c4-d2c7-41ed-af59-44e5971c2f54",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7803ff73-c5c0-4d4f-87bc-0cdaf29ba3fb",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a5e160a8-fc4c-417c-afe6-cd5dbff6f038",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fec68668-f94b-4f71-991a-9cdf8bfba989",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1c692b2f-0e3f-4f4d-8d3d-0d0327ad0526",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8cf46d16-94fa-47b2-bcd8-8cc823783bf5",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "93dd4fb8-6840-438b-ba9e-7d9b1bcc5a73",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 16-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6b07004b-cafd-4d00-a462-d2cc39dcd434",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "86e8e06c-f129-4d2e-b7d2-e313537abdaa",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "bb986eed-e15a-49b3-a549-7478c9939fda",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "26001ddb-6ea7-40e2-9a81-50047fa6fd0a",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8fe279f8-7c00-46a4-9f1b-1dec662d7673",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "01337593-9d01-4b42-88ca-dbeff84a5d35",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b757e1cd-d9f1-46e3-9624-c1fc5987bc44",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "381b1a65-1aaa-4645-9335-a65fa7810448",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "991e718e-1a51-41fa-b7de-e4a7cf41ed66",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 64-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "73c2774a-266d-4ecb-8f73-6aac9d1dcbfc",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "68163181-2c7e-474b-a8d4-b2b1d7f20276",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "91e7d1da-8692-4dcd-abf3-d5d84c693da9",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distributionwith batch size 2.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ea31481d-5fb2-4452-a631-6877f34cf9c4",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9fd46c47-2113-464a-8195-78dbc3cb5dd5",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8ae76871-e954-4aa1-a669-fc254def82d0",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3d432389-30b2-49ea-a068-b1c50feaa665",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "83a87c65-d622-4c47-bc92-8122d00a4fd9",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2e7ef85d-b0d6-404b-b4c8-aaef7ad844c5",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 256-dimensional Gaussian distribution with batch size 2 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "eedfd70e-12b9-44d3-9dd3-e7a19677670d",
                      "requirements": "The results of Figure 5.1 and Figure E.3 have been replicated",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "afaa90e8-f1f1-46b9-a4d6-0dc0352a4179",
                          "requirements": "The forward and reverse KL divergence between target and estimated Gaussian distributions measured over VI iterations for BaM and ADVI show that BaM converges orders of magnitude earlier (in terms of number of iterations) than ADVI.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1fcbbb32-a117-4781-986a-275bda1b82bc",
                          "requirements": "The forward and reverse KL divergence between target and estimated Gaussian distributions measured over VI iterations for BaM and GSM show the two methods perform similarly for B=2, while BaM at larger batch sizes tends to converge more quickly than GSM at B=2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bc5749df-9522-406a-af84-a15956e07e74",
                          "requirements": "The forward and reverse KL divergence measured between target and estimated Gaussian distributions over VI iterations for the gradient based methods (ADVI, ADVI (Score) and ADVI (Fisher)) show that the three methods perform similarly",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ae52b35c-e390-452e-9377-204deac393c1",
                  "requirements": "The results of Figure 5.2 and of Figure E.4 have been replicated",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "188481bf-75cd-4f99-b5fa-59c8419fdf9e",
                      "requirements": "BaM, ADVI, ADVI (Score), ADVI (Fisher) and GSM have been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "60178528-4580-4681-8e47-700b7e224b6d",
                          "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations can be used as target distributions",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ff269cb7-a37d-4a14-8960-ccd93e603f80",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with a normal tail ($t=1$) and skew $s=0.2$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "d8170870-2836-4d2e-beab-9f291b2ce36d",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with a normal tail ($t=1$) and skew $s=1$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "82a1992c-1068-4323-a51b-b770b583b878",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with a normal tail ($t=1$) and skew $s=1.8$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "207e29f4-75d4-4007-9441-e2b5d8ac8702",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with no skew ($s=0$) and tail $t=0.1$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "09019bbd-437c-4f73-97e3-00ecfda7472b",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with no skew ($s=0$) and tail $t=0.9$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "070becc1-57ff-4e55-8055-561d38bb3cce",
                              "requirements": "Code has been implemented such that 10-dimensional sinh-arcsinh normal distributions with no skew ($s=0$) and tail $t=1.7$ can be used as target distributions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "fa6d1b81-9ba8-4c0c-8ab5-a2afe132fbf4",
                          "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with different skew and tail configurations",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5b909bab-d557-4f11-9d59-1ba13436b0d0",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with a normal tail ($t=1$) and skew $s=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "92a1d7d3-d19f-4754-b3dc-2f732c62e6b4",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with a normal tail ($t=1$) and skew $s=1$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a1e6e69f-5c8c-4c2c-a647-d0b82de248e8",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with a normal tail ($t=1$) and skew $s=1.8$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7bab19a2-310f-481f-9afd-57923298ef72",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with no skew ($s=0$) and tail $t=0.1$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "d35ebeb4-c5c5-436a-af5d-b21d48db66ec",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with no skew ($s=0$) and tail $t=0.9$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "fd81315c-b70e-471a-a634-f1ce3a04b328",
                              "requirements": "Code has been implemented such that the score function for a 10-dimensional sinh-arcsinh normal distribution can be computed (either analytically or with an autodiff solution) with no skew ($s=0$) and tail $t=1.7$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c3085df2-aa0b-46dc-9d37-3cc521b53203",
                          "requirements": "BaM, ADVI, ADVI (Score), ADVI (Fisher) and GSM have been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "292d63d7-8830-48ba-90f2-1933a2a13c12",
                              "requirements": "BaM has been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9dad0b0e-0c6b-40c5-835d-dd2ab6bafb51",
                                  "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, the learning rate can be set to $10B/(t+1)$, where B is the batch size and t is the iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "25c0ebf7-38fe-4623-9166-6e23d54fae08",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c32b5a87-6ee1-46ac-8dd2-6e0754ced64d",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "97d94811-06df-4099-9354-e5174ec8d24a",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "18ac0834-f755-44cd-a0c5-6fb1a1b23aa2",
                                  "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, BaM VI can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "6c1197c7-b2fa-488b-aeda-ec8adf3005cb",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of BaM VI for estimating the posterior of a given 10-dimensional sinh-arcsinh normal distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "fca66135-4d93-4fb0-9c0c-1d7a9504b6a5",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "12ba99bb-d789-4b04-aeb0-410b84bac7f0",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "28d977ff-e0dc-42bf-a9ff-e6494f3345ec",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "f4f43f48-a6bd-4ee7-a332-5a69f2ac85ab",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "4f376ba6-3614-4bb2-8922-61e3535b95ab",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "d4a0e069-0784-4b46-8fd2-63443ad231d5",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "01c054e9-25de-4c98-908c-e82e621bfd10",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "dc0d4cec-272c-4b32-be12-1e924693bb82",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "f8cd84bd-cc60-4088-bdc3-a38cde84ce64",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "47bfc7bf-c5ee-4d76-991f-315508529cbe",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "477150d1-d9b5-446a-8b40-82faf2832964",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "ca596add-6928-4936-b59b-25b3f822c020",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "eb74865f-b922-4889-a903-fdbefc6e18ba",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "7e5101a0-0082-4e82-8367-75e0f83ebf16",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "b41fe229-8ade-43c2-ba5c-f81a2fd48c5e",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "86e78bac-f004-4518-bb83-d1617d49f250",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "1b3a9ebf-1ff6-400f-b1a5-189aa27c7745",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "33be260a-d620-4675-811a-4af45406b48b",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "18ddc804-4de1-42ef-8bc6-43294e1c1311",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ffafdf4b-d9b1-4904-96e3-85fa18c38c48",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "31d92a5d-4a1d-4d9e-9a09-8e84646d0077",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "34cdb209-0c54-498c-b77c-4e423e9fadb9",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "e5d9582b-095d-41aa-ada7-224e2fd7d8ff",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "498d2346-28da-45ed-ba3d-51a361e051f9",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "e44f2d22-825c-4919-b5f4-b91e1b7bfb67",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "c97ae071-0e26-45b9-8f97-4f8af2f4caa9",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "e387403d-a8dd-43e7-a9d5-c3c316048b0d",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "8950a31a-fe23-4a31-8539-25aa8c4b3420",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "c1afb007-3a74-4427-9e4c-89697cbf680e",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "e1f1812b-166e-4e8f-a073-e7b317a9e8b6",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c8390171-a91e-4106-9af1-778bf2e05fad",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "09bf5fc1-0250-49af-b5a1-db72df7acd0c",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "6871bc50-9d3c-4fe7-9ce4-42659f017a40",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "45088ef3-4343-4b6a-be23-1a81470f2983",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "e2d356de-06b9-4e25-800b-b17c53f37efb",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "b59e00e1-a992-4270-8c44-845d47488800",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "83d034f9-7098-413e-96c0-8f05e5e4c2e4",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "5f9ef61e-465b-49e1-8c0c-f5f76e0b081a",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3bd767ac-8f6c-48b2-b7d4-c572aa7c44ef",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9d1ba8a3-e3a6-4fee-bb60-f652430684d5",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d8e5e825-3ff9-4d46-a4a6-4186741e372c",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "99eb13b1-01c5-44c8-bfb5-442331d2996e",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "9cd74282-ad08-4d05-96c8-233af32246a9",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "cdced646-7bfd-4b04-a05c-762b757836f6",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "68854be9-1355-4108-8b76-1668da32fb35",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "19af0edd-51bf-408a-b44b-05d2b27cc475",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "608d2dc3-755d-4109-b356-068c829de421",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "c4c35868-4073-4be0-a26d-3a4a08eb09fc",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "88d12ca0-eee8-411f-8c17-fe8227b1909a",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "be0ef39a-0aa7-4417-b5f8-f922061a5314",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "ae70dc14-becc-45d1-99e0-02e645a8e452",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "9e360075-b9f3-497f-bfb5-677e956ab4e8",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "f2a93e5f-fe5f-4d27-aa32-f6cf4fcc4745",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "35cbd191-708f-45fc-93dd-6b58a8b2d02f",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "b9fd0920-bd92-4380-865d-fb12246afed5",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "ac696ae0-3912-4b2c-a1df-4ac4340b6cd7",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "ec069e17-1a0e-4099-8df5-cef3a703dbce",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dd9f3124-9fe1-4b02-b0f1-616d615e58a0",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "92ab92b1-4ec9-43ba-9745-e777782920ee",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "6c660cf4-52f7-4a98-bbbb-15ebf344bfee",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "1c24cf2d-8c7a-4320-91b7-c5fe59cffd81",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "9e436be5-3f70-461d-9dc8-84edc22e6041",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "ef531090-1b64-4947-93da-264147dc41d6",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "301ccf20-57f4-4905-90c4-2eb4b1a97cad",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "cf03d711-6b0a-44eb-8735-f823a61c4c9e",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "597d878e-e359-4d95-a461-7e1329a665b8",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "eb01b5f5-8c85-4b91-bb50-b14e29f07cbf",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "ce904ed7-2418-46bf-b634-30890bd72a54",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "dd07dda1-9b02-43c7-b0ee-66afedde04e6",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "a93772cc-bd01-4453-a6d0-1de89926a9c5",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "2d372887-5959-4eb3-9b44-58fccdb4a1f4",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "b113b88e-031e-4b4c-83f9-981dad188663",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "9b8868a0-492c-42b0-a0c5-0a30ecdba4a3",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "b54f0e5e-85a9-4b85-a14c-602e761d2234",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "df794af1-8a08-41c2-a7ee-3ebae63c6f9e",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "21f1c1bf-530f-49d6-b315-b25585ae8168",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "af003457-b274-43bc-8a27-f6bd90dc443c",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "38138586-5971-435b-9737-0f33d4d0a397",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "3105a9d3-ae36-4127-9f05-3aa254cb975f",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "059ead17-f4a3-4f21-9986-3a43d91dcfad",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "12b21af6-e802-4ab2-9c31-abed1c0dcb01",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "0171bc4d-cfd7-4f56-82f3-9754abb48194",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "937f0570-da35-4066-971c-34e5744ed472",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "3382bd2b-59d3-4654-b5ea-87605e1205f4",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "8af7132c-5395-4997-97a0-ace8a2aa605a",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "faf72c5b-ad10-4e60-90df-a905771691d5",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "1f1a8179-12e2-4417-9cfd-ea5ac2fd76c5",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "26b2e529-f297-420c-a9e5-cd395d63c6ce",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "f7bf8721-e952-4b4e-a5db-21f259900695",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "8c6b48ce-5f2e-4461-bba9-7a12cc4e5a1e",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "9946d9e0-f4e1-46f5-8627-1e2cef005725",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "3f0c6eac-1da8-4cc5-acff-c6025626bffc",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "18d74aeb-b932-4d4c-b932-d695bfc7973c",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "32400d56-455b-4947-bf96-d540619a254e",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "63057eb0-4d7e-4464-8ff9-b6fc7c123187",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1c7eb2ef-7bdf-43ff-98d5-142ea1d738cf",
                                  "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f507a29f-5d1f-4edc-a923-0e334c2a58bc",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "6534a8e5-36bc-4327-a008-a7757bdd758a",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "46b3a74e-1887-48b9-b03b-5650760bc91b",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "11118af4-1352-43bb-899e-6cba4a40f1de",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "0851596e-4168-4bf1-9af5-a8aa750da367",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "d9948e27-a594-4df5-9101-a9a3241e2907",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "1d325a4d-6a99-4f7c-b00d-faa4cc28bd3b",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "35fb2726-52d6-4108-ae2b-254177bb1cf0",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "f3cb72b7-da6b-41b3-afb8-6d1b759c0694",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "5724c784-e3c7-4eb0-bea4-f763da11e8b8",
                                      "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "fa254875-4f75-4ac8-98a2-d7148f8f567e",
                                          "requirements": "Code has been implemented for using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Development",
                                          "finegrained_task_category": "Method Implementation"
                                        },
                                        {
                                          "id": "69e6f97f-8ff8-448a-8f2a-0405ea023bce",
                                          "requirements": "BaM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "c28337af-0f9b-4e48-beb0-0c11c920fe93",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10, at least at least 10E4 iterations of BaM VI have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "884af9f6-37e5-46bc-ad03-127b9890bdb3",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10, the learning rate was set to $BD/(t+1)$",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        },
                                        {
                                          "id": "ebef5168-a384-4834-954a-1368d93d21a8",
                                          "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [
                                            {
                                              "id": "ca568913-9d6f-4dcb-82ea-5b6cd7e40ad9",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10, the forward empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            },
                                            {
                                              "id": "1c642871-ea7b-42a2-afa9-8b0be504d863",
                                              "requirements": "When using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10, the reverse empirical KL divergence has been measured at each iteration.",
                                              "weight": 1,
                                              "sub_tasks": [],
                                              "task_category": "Code Execution",
                                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                            }
                                          ],
                                          "task_category": null,
                                          "finegrained_task_category": null
                                        },
                                        {
                                          "id": "5d0326c5-eae4-480a-9cf7-c80c9c834872",
                                          "requirements": "10 seeded runs using BaM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 10 have been run.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Experimental Setup"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "316b904a-620e-4c10-9433-9c7bcde5b72e",
                              "requirements": "GSM has been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "12083429-a077-419d-b13b-8a1d94dd0dc9",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using GSM to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "98d97674-932f-4271-be5e-d436fceebb2d",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5bfa1a7d-5ce7-4e96-b14e-1ee9791e5fe1",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d712e1e2-19c1-4c18-a578-87e8c0251fa5",
                                  "requirements": "Code has been implemented such that when using GSM to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, GSM VI can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "744581d5-a97d-4383-b7cf-69cac8983134",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of GSM VI for estimating the posterior of a given 10-dimensional sinh-arcsinh normal distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "01da3a86-bca7-4400-b3c0-4f9965c78ce1",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5911c6c6-8360-4a6c-8f79-ae88a452e709",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "391e09ee-fad5-4fb7-a91a-41778fc39bdb",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "10d06c80-8846-4230-ae44-61849795680e",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "29d201cc-72d3-40be-8100-a463a83ed6b8",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c30beb18-febd-40a3-9d66-de146b17d7a4",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "3c669aad-ef59-4626-aba0-e3eee4c00e18",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "76aa7fad-f537-4973-9afa-3b1af9d796fe",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4b9729ee-5046-4814-83c0-fe791f244c8f",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "757e115e-7858-4b19-b82a-6dab796125ec",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "88b80548-27f7-4039-ba7e-d9338e804eea",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c32d9ae7-90b5-45db-ac88-fd742c2cb31b",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "05f7462a-41c7-4fab-9684-214478ef0ed3",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "45df03dd-0004-4666-935b-c6d4dd2ce158",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "1b38f57b-8611-44ef-81ab-ca3f05376f5c",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "eb8281d1-3b00-48ab-957e-c2a2079e9693",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4e8dea33-7367-43db-be3e-4f44181c023a",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "12437269-d581-4bf0-b7a3-d5dc97d1b39e",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "a98484f2-0c87-4ca1-b229-be8faba6cd8d",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0f5315a6-07f7-4949-9595-db791452a0a8",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b07f3b64-8514-4218-86f8-12a7752aff1d",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "fa911b45-5cb2-4029-9aa4-2e52ef3909d8",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "4299c0e1-1c75-4acc-b007-9e039946bab6",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "773b436c-49b8-46ed-a113-31c235976a4c",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "bcdcd256-fcc7-439a-b5e1-0ca09c290d19",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c13010f1-acdb-41a3-b93a-244c0a010c7c",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "f21bf1b6-cc7d-46b5-833c-ad976a7beef1",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "d61f280d-cd4c-4afc-8d1e-f631e171d03d",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "217969c4-2042-41d7-b2a6-82fb4d3d8ee5",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "7cf84274-03dc-44a8-8dea-1186c08fa537",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "ed96f466-5758-4cde-bf73-6f6b86901ea5",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "badd58a6-886d-4fcf-a43c-eb146b6555d1",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3cc04364-49ce-4940-9429-1b575421dfee",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "692a185b-7c0b-4b47-a66b-57ab09a21be4",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "541d7b68-13f7-4717-b3f9-b7bc0bed14be",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c7c32ea0-d1f2-421e-8062-67ef37c1f156",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "faf88046-896b-4c55-a0e7-50806d2db9c0",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "65b83b7b-92d2-423a-aea3-6f5741ffa0da",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "ca52c67e-73d6-4270-9f5e-88c2798f564c",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "ed1a5670-7c00-4e9a-8216-dcbd4a71ec2f",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8ff935c0-4ee2-42a5-81a4-8f0c4800119f",
                                  "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b3960a65-9de3-4e1c-8b8e-84df01b6f525",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "91b80ba0-edb1-4b3b-8e19-4ca927d750e6",
                                      "requirements": "GSM has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "cac3207d-1428-4366-a1f4-cb722f2357a8",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of GSM VI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5d57d7b9-cc24-478d-88d3-9c2b9b114dfd",
                                      "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "8a7a1ce1-c309-421e-ad03-576c26c382c5",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "787af806-0e72-4ad0-a5d1-0a2fa5dc4bf5",
                                          "requirements": "When using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "e80c7b4a-288d-49c4-8d4e-5ed1eea148c7",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "49009201-8b62-4428-99a1-e523a92a7f47",
                              "requirements": "ADVI has been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "433794fa-99a9-4a27-8ac6-565308ab48c3",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a7cc727d-358e-48f8-b95d-b5cbbf3cb1e1",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e2f0b6d2-5706-4e29-8b96-6ae2bcee1e32",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b9339ea4-d945-4a13-889e-8e7e253b73f1",
                                  "requirements": "Code has been implemented such that when using ADVI to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, ADVI can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "345dd995-ef53-4c4c-85d1-07e57c6ae488",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI for estimating the posterior of a given 10-dimensional sinh-arcsinh normal distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "533d7f50-181d-47d5-acd6-8109daff576e",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "575b0fcc-2b32-48a2-9787-65b00c2c5937",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "151d6cf2-a85a-4c1c-b23a-791ac01fb763",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9c42c539-6d17-45c9-bee6-554311b8232d",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8fadf64b-97be-48f5-b343-ea5c8cd6e507",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ee9fdd7b-920c-4301-a7e3-067f543cfc83",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c0dd7770-fc48-4ef0-b698-ab310ec5ce7a",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ecbef58a-a12d-4dca-8bda-4dabe08cf0db",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d5251688-7eb0-49a0-b1bd-ad350c56231b",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "8bdbc3d7-f477-4a57-831c-916a46912a25",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "c4209adb-20e8-44d9-816e-a25c6c4235df",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a8fe4da6-eea6-426f-9a62-4d8830e132ce",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "82ff24a9-8690-4761-9649-665b13de052e",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "99555c45-00b7-4afb-a985-b6e6c2a41ed2",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ab275e2b-bea3-4774-83d8-e7ed92a6d903",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7a40a22a-09ea-4564-8625-70f0758586df",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fa87a2ce-59bf-4664-ab05-b4328caa2bbe",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "17bd6e5e-7cb3-49c1-bf41-44dcaa7a7677",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "534a3cf6-c0ee-48ec-b69f-87ba393e24c9",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "60f213cb-90cc-4de6-8121-cc25c3b82fc5",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "ca7a17c3-115d-47a4-a27f-3d16b6b78583",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "995a6c19-1c2a-42f9-9670-ae02f4bb9564",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a092056f-97ba-4df2-9650-2cbc5fd89490",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "81f81047-3fd7-49b6-b3c3-f5901be9ecf2",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "78d157ac-fdde-4959-aa3f-440cdb052670",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "aa2adfc0-b415-423e-a454-b41b85f7fa44",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "82227b50-2294-4ba4-becf-0aa69893137f",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "620de40f-72ff-4f08-9a16-847bdfca5414",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8428beb2-d8cb-4ea6-ac2d-b15cb02d9685",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ddda2c46-1640-4032-a488-382b6c2abaf9",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "dae93d49-b089-4861-b924-00a5fc491c98",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "92ac75f8-7fba-4278-9e4c-f458135ad5a9",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "479187ca-2b66-44ec-a47c-0f68951cc8ed",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9861a2df-b76f-4c66-827f-86238b013439",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a86a18eb-e8fe-4bd2-8b07-14d587e952ce",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "8c63d9a0-c069-47a8-a3b7-0cb083625beb",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "10b6a04c-f4f1-4dce-9c9e-dc6afbc2914c",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "55fbb62d-7a39-41aa-89c4-ef139586e6e8",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3198c989-66cd-4a62-b619-b1a13b0edb56",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8ca49c8f-fe52-4e89-9293-4f03677fb360",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "920faf78-7744-4fe7-afa2-68f9f29f95d1",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "01dab2bb-d769-46fd-a771-474fed6b3dab",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "15341615-56ea-4234-b16d-522cb9d0289e",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "9e8b7c88-5bfd-4c50-a133-b56885f297d5",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "fb48bced-421e-4bbd-a89e-c2144e3fe77a",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d0d7f5f5-16de-4649-ad52-88182c79356a",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "581aeb9c-e314-4c6c-a7fd-8e9b8b3b95f9",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "786b3d65-1854-495e-8eea-1435ef8506f8",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b9498352-f7a7-460e-84a0-300155594f95",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f16e3ab3-0b75-4ff0-a4a2-3d319d0eb724",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5de2f6fd-7d14-4d1b-ad74-21ce94f90799",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "393704b3-0acf-4f00-91bb-b5608a40661e",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "0ebd659c-dcb5-4e14-abe9-f86f302b665f",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "8e1b4fe8-72a0-4858-9839-0c1e60517486",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "8c91d635-40ce-4788-be54-70c0d33c0493",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "504a8afe-3400-4190-b8de-c0b7103c74e4",
                                  "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0739e81e-c949-447e-9d79-b396f3fcf9c7",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "43a93dcb-54d0-4b76-b720-0c96a293d2ef",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7ac7b7be-bcde-46a7-a110-e05c4e0be65d",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f2be3969-10db-44a6-95d4-7e5d0846b340",
                                      "requirements": "ADVI has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a77d5683-e2e1-4bd2-b2d7-db9bba29fa5f",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "76eff4b4-fc23-4878-9cf0-37b987a7324e",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "268715e7-2163-4081-ab04-179828781de8",
                                      "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "44ba6bbe-0486-4a0e-ae82-39fa155e907e",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "6b15e080-712a-4daa-8cb0-336210ca1c3b",
                                          "requirements": "When using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "e90a6b24-9e3f-4b8b-99ba-5fb01f7880ac",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cde7e294-1538-4603-99bc-46202284db55",
                              "requirements": "ADVI (Score) has been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "697e91e6-027b-45dd-8938-85f6fb939408",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Score) to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4aa82457-3a6e-42bf-8475-a7a8e6630a9c",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "505ef52e-2a68-4a7f-91b0-72c054e6afac",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "104d165c-6498-4083-9f39-c00307a4d24d",
                                  "requirements": "Code has been implemented such that when using ADVI (Score) to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, ADVI (Score) can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b7cbd6a7-e4cb-4343-b584-45c8b590b754",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI (Score) for estimating the posterior of a given 10-dimensional sinh-arcsinh normal distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "1f61670c-4890-4634-a77e-cd7030be38e7",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "47484f32-9338-4ff4-be18-6e0c25023ba0",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "c28c357e-51c7-4c82-9011-aedd051e2e62",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2c89a14c-85cd-48b6-ada4-f37a9696fb2d",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e105dac4-cea6-4a3f-a466-b46bedc66870",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ba0e9c27-c94e-4d25-952d-07acc87d09eb",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7d6fec08-a014-4dfe-b1be-b2ecbb02c8d6",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7cd02a6a-b383-4611-80bb-6b5d5414d1f4",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "90b4fc01-4bcc-429f-8c41-539f38aee7a0",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "4b889f83-2fb8-4372-90ad-89486204e40c",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "3640f230-829c-4507-9bc2-caa0f9165911",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9f15095b-58e8-419e-b156-53c18a87ac5b",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "09d74f73-bfdf-4e05-b0e3-8680f3a416be",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "e1ecd6ff-25a2-4d3f-8cf6-6d50728e25b8",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7023c16b-4e75-4170-873e-badcc17b90bd",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "710cd4de-fdff-4a58-9dda-d515e1a009b2",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c8400f7b-e4e3-4bbc-9949-9ad409f81f52",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f51f2f96-0d49-404b-9407-69ac5813c5ba",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3f3cea4f-23b9-4aa0-bced-5103e56699a2",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "985ef3ed-763b-4f99-9b6b-d1df1c88bb17",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "a5ff7730-3115-4a2f-8f46-1f3c901a7500",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "5682594b-5225-43c4-aa14-a89ac5f62ee8",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f780c010-2861-48e7-9140-f5de7874a641",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b60ec56e-dada-42b2-bf26-dffa3dfeb430",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "a9c3cf98-0dd9-43e0-881c-36ecc33a31d3",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e2985594-8291-4570-adfe-68f27a0c0210",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "85fc83b7-ddec-442c-ae8b-ad407e4875af",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e02c2119-ad2c-4ab6-9f4d-8d9a0a76066d",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "185d2868-050a-4af1-8b1a-c66c7100c4af",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "38c0a46e-22db-45f7-b05f-e6167d07de9d",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "05bb0a28-c2ac-441b-89c0-56a0dc60c15a",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "da75920e-9fbe-4f19-80dc-bfcf888d5395",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "40843141-48bc-46fb-b71b-431cf03f752e",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "53e3bf04-a943-4647-805f-70c2e0701bf1",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4f1c6ab7-7de3-4196-98f7-8fe0c8c72ed2",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "9ff3a320-5fbd-429e-b64f-71ad91d63241",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c94040db-d8ad-4a9b-89fd-1a764779497c",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "afe5de64-88c9-4675-b2ce-6fa02f973758",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "bd4aeb0d-4654-4bf5-8c25-098103a6f11f",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "fa99ff23-fbb4-4f18-bfee-fe46ad1cca1b",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4de98819-d0f3-4c53-849a-640ec45e7036",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "69f480e4-0e4c-45f6-9291-fac652ba68b3",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "799684df-a31a-4d2c-9882-806c1b7e3c90",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "abd3ae40-6a82-4e5e-ad95-2c7137380abf",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a6d47da7-10b9-4a86-b9a4-f940ab1ad35b",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7182ff89-b52d-47c5-88c4-1daa0f14db2d",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "f16ba270-2409-478a-a96b-c46c8c58b69a",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "58dfa0e0-fb1f-4ab3-b383-d1998a22e1e4",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "117aa215-e381-4514-a9da-9844f4e803d1",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6e80278b-3669-46f1-a833-3e6b2e2d6b97",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6cf5b95b-9399-4c87-a05a-678e1a553023",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6ac6df88-8bfd-4b21-bedc-a4cc9446532b",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "2ac2b72f-21c5-4ee1-a5e8-5f0f6cade681",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "729fdcea-587c-42ed-a49d-80409cdac9e5",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "1bd3dded-deb4-437c-8578-361775e79028",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4c6b3d03-4fb5-433e-80af-dd904e8d5760",
                                  "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "364dab3a-85e6-4d19-b497-97e4d95b7176",
                                      "requirements": "Code has been implemented for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "50150783-5232-47c4-9ec8-142221692edb",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1450a497-5db6-479a-a9b3-affb7fb07b0f",
                                      "requirements": "The optimal learning rate for using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9ebacb36-0c73-448f-bcdf-386a97ea1cca",
                                      "requirements": "ADVI (Score) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8f3f1f62-ead4-48b2-b190-ac0c16dc4f0f",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Score) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5b9b81bc-aad3-4706-b9bb-6cc2259493d0",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "50c83765-f36d-45f8-bffb-5a4d1700880a",
                                      "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c2c82662-c683-43dc-a8e1-5aa536ad1c57",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "2c3111ab-0562-4103-8a11-3319b03df61e",
                                          "requirements": "When using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "6c442710-6aac-4598-817e-a318b7e4ceb9",
                                      "requirements": "10 seeded runs using ADVI (Score) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "835c190e-50a3-4322-b32a-f85099af29b9",
                              "requirements": "ADVI (Fisher) has been run to estimate the posterior of 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "dc564a76-3d54-496c-834a-d6cdf7d72ebd",
                                  "requirements": "Code has been implemented such that the forward and reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Fisher) to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0c565abe-eaf8-476b-94ca-8f7b0a0722a9",
                                      "requirements": "Code has been implemented such that the forward empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f3d53b04-002f-4590-b67d-52ad1b1f38ff",
                                      "requirements": "Code has been implemented such that the reverse empirical KL divergences between the estimated and target posterior can be measured at each iteration when using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distributions with different skew and tail configurations",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f7235cbe-8bcf-4a59-8cce-df226dd72b43",
                                  "requirements": "Code has been implemented such that when using ADVI (Fisher) to estimate the posterior of a given 10-dimensional sinh-arcsinh normal distribution, ADVI (Fisher) can be run for at least 10E4 iterations",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5076880c-8fc8-451b-be3f-edb03aca043a",
                                  "requirements": "Code has been implemented such that 10 separate seeded runs of ADVI (Fisher) for estimating the posterior of a given 10-dimensional sinh-arcsinh normal distribution over some number of iterations can be run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ded0043c-5d13-434e-9471-7b58b34dd304",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ff9c6de1-680e-431e-9c4f-beafe519df4c",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "ac7f12f4-4ce6-4cb4-ba48-524f2d85a5e9",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0686194b-fadd-48c2-b161-e1ac4b82c88e",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2f9c441c-6e8c-449b-9c5c-e5599f6cd7b0",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "d84dcacd-ad80-4665-8829-a0a7b45c75fd",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c32b6acb-ba7a-4877-9162-acda5aa0172e",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ed43f67e-bc46-4893-b620-080e018985ed",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "888e4dcc-7b3c-41b4-bc09-1dcef6734c05",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "dcb27d2f-df41-45a2-a48f-a0c140462ed3",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "db2831ff-e7f9-4012-b5b0-26771eb705eb",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dcc9a15f-4d80-41a4-96e5-b922e5e609bd",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7639629-cbea-4374-978c-a64a4678feed",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "2c9bea44-6f86-4921-8237-de3682f56b51",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ae2acf11-98eb-4703-b775-b3f7d0621052",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3a8fed23-2f7a-43c4-a2e6-22f0537a6cff",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "105ca4e8-5969-46c2-9d76-b26605b303c3",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "68104c27-0eaa-4db7-86a6-549a45db223f",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b65f46c4-07e8-4519-ba5b-26dc712fd13f",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "bf28bc43-3893-4f55-8a17-8eb8b49d2057",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "493b1aae-a560-4c7b-94f9-39614a6b0f46",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "512edafa-0acb-43f1-9d00-7173fc24a508",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "24b26a89-8e5a-4b57-a1a7-5f1e8a54651d",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "acb503d6-f890-4e80-a52d-b81b152f4380",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "a08fb80c-5d38-449a-b7f6-88934d994941",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "46c877fd-1064-477d-bbc7-06e4b726646a",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "634f988d-1793-4fcc-99d7-933c6b0fd30b",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "810dc566-e704-464f-9444-397687161ebc",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b2c519e8-e277-4d7d-990c-0db96feb9b98",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f77cc91c-9310-4b57-b534-8e23ec9279ae",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "aeb48001-33ec-48a9-bb57-1db0b6e6b0ef",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "50995dc3-95a1-47e2-bd03-11ab7abbca30",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "736c7065-57d6-4c25-a436-8213b0604577",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=1.8$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9159ea6f-43bf-4f47-9506-701e1e23f15b",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3611d925-d2e6-4630-8ec2-10f108ff4489",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "42c5cdbc-3ebc-410a-b344-410a4ac23ff1",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7d665e7b-d57a-4b9d-965f-0b16f837ece3",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5f69e162-a701-4113-a6dc-2ebd73e0cc3e",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c6d6049c-8bfd-4c18-bdc0-ffc7860698e7",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1c0dd897-6924-4961-9a79-114eadd52559",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "64b3900e-bd82-4cd8-a261-01372e4e2ae1",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d826b219-76ee-438e-90b9-c69f42b8bcb4",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "5c12fd10-78ac-41d9-bb02-5ea27313411b",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "bd3e0fcb-c0e1-4a8b-a14b-db01aa349755",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.1$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1cb56051-98e4-4297-94b4-e80212bc5df0",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "783db56e-960f-4c8b-886c-d480852dce1c",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "19bd3493-e961-46ef-af83-cdd01652e8d2",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6284c74f-e116-4e52-9c01-cc8ebe044aec",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c710affd-a06b-4652-936e-83fec4a712a2",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0ba1c3c1-8276-4b69-b4ae-379ae0178a50",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "40cee27c-896d-4af7-ba0f-2b9b08cdf658",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5157ad05-5abd-4a74-aaed-ddde01a388e0",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "7fa8a2bc-d251-421c-8b77-f387d51efc31",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "e1e1940c-ef91-4ca5-95fb-757acc01e7bc",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "5a4842c3-e3bf-4857-8851-ac0ff2467d46",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=0.9$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3efa5c54-1bff-4f28-9aa4-fd2167a15225",
                                  "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1fbdf57f-55ca-4a24-be41-92b47ceacd2c",
                                      "requirements": "Code has been implemented for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "3e03d0cf-4147-4124-a77f-ab985b3f6ef3",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c69d8b34-4ae0-4fed-a3d6-57eba5ca6178",
                                      "requirements": "The optimal learning rate for using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4ec15363-b060-4ba6-b184-dc4078b745d9",
                                      "requirements": "ADVI (Fisher) has been run to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c171a7cc-2ce2-4953-a972-101bc8b61ea5",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, at least at least 10E4 iterations of ADVI (Fisher) have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "d93a5fb2-80ca-4813-aa25-34b44ef70e2b",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f1f766ae-71d3-42fd-ab4a-7d1a84b5b3a7",
                                      "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward and reverse empirical KL divergence between the estimated posterior and the target posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d625fc20-611b-4991-9e52-8e5ae6cfaaeb",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the forward empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "6677da00-6f0a-4d75-beed-2ac33d6af2a5",
                                          "requirements": "When using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5, the reverse empirical KL divergence has been measured at each iteration.",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "c46cde27-4b26-407b-811f-32c43957e22b",
                                      "requirements": "10 seeded runs using ADVI (Fisher) to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1.7$ and skew $s=0$ with batch size 5 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "ae506b90-2ca3-43ed-b43b-fd7d8ad59a08",
                      "requirements": "The results of Figure 5.2 and of Figure E.4 have been replicated",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "71fd6df1-5b42-4f6d-8933-641ffb8b7ba4",
                          "requirements": "The forward and reverse KL divergence between target and estimated sinh-arcsinh normal distributions with normal tails ($t=1$) and varying skews measured over VI iterations for BaM and ADVI show that BaM converges faster (in terms of number of iterations) than ADVI.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9f8f0bec-6419-425f-92d9-8f5d7ef45fcf",
                          "requirements": "The forward and reverse KL divergence between target and estimated sinh-arcsinh normal distributions with normal tails ($t=1$) and varying skews measured over VI iterations for BaM and ADVI show that, compared to ADVI, BaM converges to a higher value in terms of forward KL divergence and to a similar value in terms of reverse KL divergence",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bec65857-cc6a-419d-b5e0-1c78f235f062",
                          "requirements": "The reverse KL divergence between target and estimated sinh-arcsinh normal distributions with no skew ($s=0$) and varying tails measured over VI iterations for BaM, GSM, ADVI, Score and Fisher show that all methods converge to similar values",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b75c8f95-7b52-4c5b-880c-9ea50b5bb59f",
                          "requirements": "The reverse KL divergence between target and estimated sinh-arcsinh normal distributions with no skew ($s=0$) and varying tails measured over VI iterations for BaM, GSM and ADVI show that in some cases, BaM and ADVI converge to better values than GSM",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "609c1c97-01bd-4b8b-b117-caf34905f9de",
                          "requirements": "The forward and reverse KL divergence between target and estimated sinh-arcsinh normal distributions with no skew ($s=0$) and varying tails measured over VI iterations for BaM and ADVI show that BaM typically converges in fewer iterations than ADVI",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "b26b2d0f-6827-4dd6-9f23-ab3d3737bc9c",
              "requirements": "The results of Figure 5.3 and of Figure E.6 from Section 5.2 have been replicated",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "ece02738-9846-46c9-8d75-3bea03334df6",
                  "requirements": "BaM, ADVI, and GSM have been run to estimate the posterior of a PosteriorDB models at batch size 8 and batch size 32",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "70618018-8604-4e4c-9e6f-25011046b139",
                      "requirements": "Code has been implemented such reference samples generated with Hamiltonian Monte Carlo (HMC) can be sampled for specific PosteriorDB problems",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "f9f9945c-075b-4c5b-8dad-e17f4f855210",
                          "requirements": "Code has been implemented such reference samples generated with Hamiltonian Monte Carlo (HMC) can be sampled for the PosteriorDB `ark` problem, at dimension D=7",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "9f19cb98-2466-4e19-9b9b-13460ad71d1b",
                          "requirements": "Code has been implemented such reference samples generated with Hamiltonian Monte Carlo (HMC) can be sampled for the PosteriorDB `gp-pois-regr` problem, at dimension D=13",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "6ffc9f02-6602-426a-b5d8-cf007613e8aa",
                          "requirements": "Code has been implemented such reference samples generated with Hamiltonian Monte Carlo (HMC) can be sampled for the PosteriorDB `eight-schools-centered` problem, at dimension D=10",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "77a03a48-abe2-4f26-b30c-c8deb539cac9",
                      "requirements": "Code has been implemented such that the relative mean error and relative standard error between a given pair of estimated and HMC posterior parameters can be computed",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5afd823b-fe2e-43cc-96c6-74e61e317389",
                          "requirements": "Code has been implemented such that the relative mean error between a given pair of estimated and HMC posterior parameters can be computed, as outlined in equation (242) in Appendix E.5",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8cb1d179-bf13-4d66-976f-4fefc362dfa4",
                          "requirements": "Code has been implemented such that the relative standard error between a given pair of estimated and HMC posterior parameters can be computed, as outlined in equation (242) in Appendix E.5",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "96cc737f-06d0-4d08-98b4-35445d092047",
                      "requirements": "Code has been implemented such that the score function for specific PosteriorDB problems can be computed (likely via bridgestan)",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "7239250f-8ba2-4dc1-8b7a-55d21f0ce3c9",
                          "requirements": "Code has been implemented such that the score function for the PosteriorDB `ark` problem, at dimension D=7, can be computed (likely via bridgestan)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "15a0a7e0-5679-4cbe-81e4-767a7caaa3eb",
                          "requirements": "Code has been implemented such that the score function for the PosteriorDB `gp-pois-regr` problem, at dimension D=13, can be computed (likely via bridgestan)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c840a1e2-a7e5-48f3-a962-11624499939a",
                          "requirements": "Code has been implemented such that the score function for the PosteriorDB `eight-schools-centered` problem, at dimension D=10, can be computed (likely via bridgestan)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "760fee17-d639-417e-8040-ff1e44385392",
                      "requirements": "BaM, ADVI, and GSM have been run to estimate the posterior of a PosteriorDB models at batch size 8 and batch size 32",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0ca7a0e9-a2f8-4e07-901c-c0b9668e4214",
                          "requirements": "BaM has been run to estimate the posterior of a PosteriorDB models at batch size 8 and batch size 32",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "709db886-9aa9-417e-9a16-ceebfd811410",
                              "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a given PosteriorDB problem, the learning rate can be set to $DB/(t+1)$, where B is the batch size and t is the iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "b083089c-9f87-4a2d-a681-d6ec4ccf401d",
                              "requirements": "Code has been implemented such that the relative mean error and relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using BaM to estimate the posterior of a given PosteriorDB problem",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "dba97644-7829-4b04-8873-38341ad8ca7b",
                                  "requirements": "Code has been implemented such that the relative mean error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using BaM to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9b48b917-da7f-4bd1-b175-0bb7c4fda3e5",
                                  "requirements": "Code has been implemented such that the relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using BaM to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "497dfe00-c70d-47bb-91d9-3587ddbf8091",
                              "requirements": "Code has been implemented such that when using BaM to estimate the posterior of a given PosteriorDB problem, BaM can be run for at least 10E4 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "f7954dbd-e5b3-474a-854b-8919c0b410d9",
                              "requirements": "Code has been implemented such that 5 separate seeded runs of BaM for estimating the posterior of a given of a given PosteriorDB problem over some number of iterations can be run.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "28fe8fb1-67f2-420e-ac6f-acdb526d509a",
                              "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5f26d41d-6abf-4928-9334-7ee8956d33f7",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ed644299-7e44-4414-93cc-cf8bc6f7d32f",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "f837eff5-b654-4eb4-871c-089a24176c6e",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b2bff8f9-bce9-41a6-97dd-4c9fb48fd2a3",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5c51279d-cd45-4eee-8ec1-b9bfa4ea9d65",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "40c7b53e-f4b4-4ed5-9cc0-a487d1ab58ee",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "42b6b19f-73e5-481c-8c88-9295630c0ce8",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "56ae77eb-f010-4617-806e-fcbf725f7c91",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "24d3f024-2e96-4084-b860-add43b233edd",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "20cd57da-d936-4033-b9b1-14a1f8a364b2",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "685da7ed-db59-4ef8-9f47-017dc6f6f18a",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "6c2d7d49-3b1d-467a-8569-fcf6d14f05f1",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1297829c-9d5b-428d-9c54-9e8aaa51175a",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "62a4fcd4-71ac-4204-b5b3-5477be5e564f",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "82539f70-32cd-4dc1-8896-d6b28aff0c4b",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "beca4aaf-9f77-47eb-b44b-4f0a020bbd66",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "72683ca0-2cd2-4bdd-b201-e6fb7215f0ee",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "7a4bcf41-4085-45d7-b0e3-4dc4361214c2",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "f6b4393c-3b89-48b6-b35b-ad1dead2ab9f",
                              "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8b3da84a-b7d2-40c1-9a32-acfac91eab1e",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4422c31a-b820-4113-b883-6460a36dcae5",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "015bae58-b11f-4f57-a51d-f5cb7ccee7bd",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4cb0423c-3664-42a0-bb37-359b4a9b6d8f",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b85aa210-398d-40ad-a415-41de3b2abc7f",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "16c705cd-251b-4fe0-b3dd-9a48d30f3bed",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "b6ebb53c-665f-4d3d-9014-c7fc55dd1b08",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "b09f5f97-e9ef-43e8-981f-b39a4adb1906",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "4bbf804d-5234-4361-94ee-6c678ed53bb3",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9c4fa168-baab-4186-b5d9-ba7b137ab910",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7814872-24e9-4f2c-8c2e-4938f92eb838",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "0ca34203-84bb-465e-a4e4-44e632ca4f5c",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "82c175b1-9c51-4144-9662-e71111326ba0",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "4ce1270e-2a76-4619-adb5-9b9220ee488f",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "59ca0ccd-95d3-45e4-ac39-bb782bba6684",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "d438fa87-9c81-45ca-8c2a-b8bf51883b17",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "dc385833-683f-42d2-8967-622537e96d46",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "9c6c5973-756b-44ad-ba80-39082fafeb1e",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1cbdd7a1-a1ab-4654-8c93-a2cb57785ba1",
                              "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "44f277d6-c0c7-48fa-82c8-a265d4bc7c23",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7232a9c6-f4ca-4cac-b0ec-7f52d3d3ee03",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "e09285cb-7a24-4437-8bdd-e0f1ae0c87c6",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8e72a625-6f5e-4e45-9631-eb645a4d56cf",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a9b3491d-bd2c-4aa9-8431-75a69a9b63dd",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2c6318b1-b46a-437a-b624-67642e39afe9",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "dab11bf2-03ea-423e-afa5-d28f7a639962",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "899ea91d-4a63-485d-9320-b4b22eb3c497",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "72e544a7-a8da-4073-b0b1-63366384c25a",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ae00d209-2073-40f4-a258-18ff1d8fae89",
                                  "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8b33f3f6-5c3c-4a39-932b-e9117a2db7bb",
                                      "requirements": "Code has been implemented for using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "e4bafdae-76e6-4bd0-9d40-7daec888b662",
                                      "requirements": "BaM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "208f4237-219b-4318-a0e6-cd9169a3f686",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, at least at least 10E4 iterations of BaM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9cd1568d-cb5b-43f4-91ee-f6d65a4fd5f0",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the learning rate was set to $BD/(t+1)$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "af060e1b-364c-4f3a-88ee-ea136264cba4",
                                      "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "2d2dd630-ef7e-4fa2-b378-4a4e2e82947e",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "9eb38c89-e6d0-4f53-8873-f285fd019fda",
                                          "requirements": "When using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "3ae7d54c-2461-46cb-b9d0-1956b5565b5a",
                                      "requirements": "10 seeded runs using BaM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "fcac882d-cb8b-4a6b-a825-63c6229345a5",
                          "requirements": "GSM has been run to estimate the posterior of a PosteriorDB models at batch size 8 and batch size 32",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "0a87548f-f9ee-494c-b246-df03bddb2806",
                              "requirements": "Code has been implemented such that the relative mean error and relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using GSM to estimate the posterior of a given PosteriorDB problem",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "05aa3933-138f-49b4-b3b9-469bfe492df5",
                                  "requirements": "Code has been implemented such that the relative mean error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using GSM to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "84424446-0e76-485a-8f9f-cc4a33077589",
                                  "requirements": "Code has been implemented such that the relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using GSM to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3ac18481-c1f5-4849-b5f2-689da200fa11",
                              "requirements": "Code has been implemented such that when using GSM to estimate the posterior of a given PosteriorDB problem, GSM can be run for at least 10E4 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "018a3825-2b17-4db9-91d2-d13a8f316a43",
                              "requirements": "Code has been implemented such that 5 separate seeded runs of GSM for estimating the posterior of a given of a given PosteriorDB problem over some number of iterations can be run.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "10c87855-bf9d-47d9-86e9-2ca83262f4c8",
                              "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f03c0315-4405-4bf9-8601-49a1225471fd",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ac42eb54-7ed6-4bd5-90b5-f54a21cacb7a",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "c25dd614-2367-474d-8b0c-efa5c808d260",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "893babad-44c5-4eed-8a40-3ff0c6f40c7c",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "56421bd3-4e92-4cd4-a31d-39317509b89b",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "b878a678-81e6-4ba1-badf-8585113ab488",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "b5dde722-d968-4db7-9ebb-37bf2123ce74",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "8cdc984b-e3b3-45ce-aa8d-2c50511150a1",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b9b0bd9f-13fc-4996-9bf9-3bc377b5b7f0",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "37e8141a-5a1b-4e10-9596-0dc6e6963fc5",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "5cb168ee-9db1-4109-b16c-c5c702acf3b4",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c3a3c836-d238-4aca-bc42-9c31b2285c09",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "bb7d81b7-ba41-466c-a342-138be8ff281e",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "7f33e8fe-280b-4540-9bbc-4e4b40083a77",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "8f104ede-2f09-43f3-86fc-a68e68813bbe",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "36f6d2f5-3d36-469d-9478-129b3913470b",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d10dbbdf-d442-40ee-86e6-368a0df2541c",
                              "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "03df2bac-ac02-4276-94dd-77793d405b36",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "29399af4-02a7-475f-8549-f5ec78553bd9",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "4ff1459a-d66a-4f3f-bc34-db4d586357a8",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9f2f240e-d923-4c72-becc-4b83d6137360",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2259b368-0ca5-4e6c-9545-3ffdcc4ae399",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "cd3ee5f9-7d44-4821-9aa7-2b5ddbd8f882",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "f16d8608-589e-47d9-82c7-864aafcbd05d",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "ea968935-7675-46f4-8b07-4b898bb917ef",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a21bdf4f-dd55-4289-8b6d-428f62c9bb74",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f6c15b2d-56b7-4bb2-a67a-8ab93aafc3a5",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "dc4b9ae5-0c57-4f55-b798-c545689a97ab",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f1600521-a4f1-4076-ac20-a3a3feb9a66b",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "446b69a9-1101-47fe-8608-5c79235297fc",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "292ff5b5-770b-4400-a3ec-6d6ccb219e60",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "5c64afb7-4255-4bc3-b63f-de1af6752057",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "b6ca1761-eec4-4575-a09f-4c1983f3fd39",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "0a2a9d02-6707-4bcb-afae-064ab380cc9f",
                              "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6752e11c-1878-4a3d-b18e-3d093d148af5",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f1ecdb68-2e79-4e31-a1ea-38c7002c1f06",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "6a7e611f-545b-4815-8509-e7188c1d63f1",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f81e4479-84f4-4c02-92ce-ef6c77afcc9b",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "52e844e3-a8d0-432d-a676-a3f595884dbf",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "5cc85417-61ae-4a9f-8db0-afa5682fc92a",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "b313a0e6-7918-46f6-b84d-6542bbde60f7",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "e303643c-e84b-498c-9a98-5a612dda2a9d",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f7b3d380-ee22-4b70-a9f3-661ebc3cb045",
                                  "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7f820046-929f-4da1-add5-23d08128a931",
                                      "requirements": "Code has been implemented for using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "4a847921-4402-4684-8973-b7d72a583b12",
                                      "requirements": "GSM has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "143903aa-d529-4a79-b423-63b3a2c3ab4b",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, at least at least 10E4 iterations of GSM have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "23e0c41d-87c7-47c2-8d7a-e052a3f9d248",
                                      "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "3367cf7b-56a3-4334-9e64-23d82cf9225a",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "c3b77980-82a8-45fc-be50-25becac3e123",
                                          "requirements": "When using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "6b588e5e-8f49-4798-b1a5-755f860daef6",
                                      "requirements": "10 seeded runs using GSM to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "87af027f-00b0-4581-93e6-0348e7b306d7",
                          "requirements": "ADVI has been run to estimate the posterior of a PosteriorDB models at batch size 8 and batch size 32",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f14aa253-5a1b-47fe-9fb4-55c1430781c7",
                              "requirements": "Code has been implemented such that the relative mean error and relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using ADVI to estimate the posterior of a given PosteriorDB problem",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c973e81f-cac5-4248-9a1f-80e51b2fa1d7",
                                  "requirements": "Code has been implemented such that the relative mean error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using ADVI to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f8f8ec14-3d78-409e-bfaa-114c288f3873",
                                  "requirements": "Code has been implemented such that the relative standard error between a given pair of estimated and HMC posterior parameters can be measured at each iteration when using ADVI to estimate the posterior of a given PosteriorDB problem",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "874b6134-7a33-4846-b7bb-241ca7b8ded0",
                              "requirements": "Code has been implemented such that when using ADVI to estimate the posterior of a given PosteriorDB problem, ADVI can be run for at least 10E4 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "5cf2de1a-b303-47c0-9d25-f891119e4f9e",
                              "requirements": "Code has been implemented such that 5 separate seeded runs of ADVI for estimating the posterior of a given of a given PosteriorDB problem over some number of iterations can be run.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "848cc172-b8bd-4d12-b467-62d9d683c6b3",
                              "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "dc90756d-86af-40b0-8071-85ea9743d057",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0bc336d8-43c2-427f-84d2-c60b44ce0a76",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "6e37cfd8-6369-4d00-bcc4-eed046d72b6b",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "49b48f8a-c8b6-4805-811a-fa52816fe397",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "09c6f987-d1c2-409d-b310-19a65f53a5f5",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "eef1ece3-dd3f-48f3-be04-17be555c7a02",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "170d0eac-3827-498a-96fa-29a251ddf2f0",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "9f762e9e-89ed-4d30-a8d9-2a334d032e39",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "4eee7a51-69aa-4307-a31e-0f1f581f3fc3",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "93c5238b-9cef-4ffc-9d23-e7676654c82c",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "66537c8d-b749-44e8-bbb4-efc5c8ba42a3",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "55f1fb0e-7528-4579-8767-bd4f4a0e3ecf",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b6354d05-ee4e-47f4-8cda-a986140affef",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "c30c6c6e-9733-4feb-a697-5869ede43aae",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0e78618e-bf65-405c-8432-beb0ad087bcc",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0da174d4-dd67-4186-a769-420d985043d6",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a25d0c1a-b751-4534-ac49-b06768d8ad97",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "cadfa2fb-d037-4db7-9346-aeae4a2aead2",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "939be83e-0dba-489d-aba6-59466d88e846",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "51f771f6-2ad2-42ef-b8d0-ba3ef81b63c4",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "64fade5e-3fa9-4fe6-883a-cdac48418e50",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "59093363-fd86-41d2-8e04-0bcce926794b",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `ark` problem, at dimension D=7, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cd0c8fa7-cb9c-4b55-a28e-7c505945e6c2",
                              "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `gp-pois-regrs` problem, at dimension D=13",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8481cb19-0ebf-4868-9d15-cc3d8395d1e7",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ad56b976-6194-437a-89c6-a329c4830848",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "677188c1-0004-4404-848f-59765d1e7547",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "52b65034-4ffe-442f-92f8-2f18f43fb3ba",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2acedc23-f3d7-42e6-aa64-96ae7512af8a",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "197031d1-83c6-44c7-af19-a79ff7015679",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ad03053b-d208-4411-bb41-fb3c52aefd27",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e11b7acc-ca67-4741-8ea1-95c0ee0ec1e8",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "b4d586e6-c73f-4b4f-803c-d22a59fa1507",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "866b5614-ee07-4d9b-9102-44b066eaa229",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "fa09e183-c72e-4b1b-9949-b68f08da3911",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1db81f60-b9fa-4f48-8819-2725b7d8c63c",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ac0ae3d5-41bf-4a4e-8b5c-6c93305786e6",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "248c1684-7468-466b-af35-1a0b6001a6f0",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1bf67145-6e2b-4b22-90b1-836b90353a8a",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e4be020d-e25e-419c-85d9-88117a4faaee",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2b86577b-7f47-45e8-a51b-b48b32e94149",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "934936f0-6ae6-4c86-81e1-0e1cb8979929",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "5527123d-6f33-436d-9626-0074f29bcb30",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "7b6128ed-88e5-4da0-9753-e37e4e1a2362",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "8468c8b8-6bfd-4bf3-91eb-1dc2f94b3872",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "7ec676a0-dec0-43f6-9357-54a0ef6aaf9c",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `gp-pois-regr` problem, at dimension D=13, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "34369e9a-0e8d-45ea-bed3-67f14b62888f",
                              "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "607a10cc-cc5a-4958-aa3d-a04d28765d02",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c62b74ef-7480-40d4-8beb-b8bef5a4288b",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "57e4a6f5-98a7-470e-b120-bf29b56dfbfd",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f93c36f8-0c2f-4ffb-ba6c-75793539b9d3",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7c4c0ee4-8e9d-482a-901c-ba9c64e4d020",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a971509d-f1f9-4c7d-a17f-f0dd33e11d11",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "92e2e914-91ff-4b70-993f-2a6edb0a9772",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3499eaf3-9b47-4199-8b10-735d60e467df",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "b440b1c2-fdc2-4bfd-9b5e-979c2f544fc9",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "bbbeb0e4-b603-4ec7-ac70-3b2e1e9aa928",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "094edda1-f33d-4e73-9422-41423c4f8c06",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 8 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "947c6642-9d65-4b56-9c6f-fd4960d53ea5",
                                  "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7a4e53ce-180e-4a2e-a51d-3b4f056cb482",
                                      "requirements": "Code has been implemented for using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "ccc48c89-f32f-470a-9111-cf4e33a3ce33",
                                      "requirements": "Code has been implemented such that a grid search can be run for determining the optimal learning rate for using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1cc7c950-5c47-4d61-8cac-4182ff8bff8f",
                                      "requirements": "The optimal learning rate for using ADVI to estimate the posterior of a 10-dimensional sinh-arcsinh normal distribution with tail $t=1$ and skew $s=0.2$ with batch size 5 has been determined using a grid search",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7b7fe513-0da6-48eb-9a77-ee93ce87b9b2",
                                      "requirements": "ADVI has been run to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0ff35efe-0a73-4959-b3a5-4785c1c561c8",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, at least at least 10E4 iterations of ADVI have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0965035a-96e1-486a-b551-f0860a211db2",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the learning rate was set to the learning rate determined by the grid search.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "41fc24d0-c124-4349-b6c8-bd445debf9c2",
                                      "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error and relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                      "weight": 1,
                                      "sub_tasks": [
                                        {
                                          "id": "c2859754-9e61-4a4c-b42e-82858d1d7eee",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative mean error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        },
                                        {
                                          "id": "38a29fb9-a04c-4d85-9a37-75de0acc335d",
                                          "requirements": "When using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32, the relative standard error between the estimated posterior and the HMC posterior has been measured at each iteration",
                                          "weight": 1,
                                          "sub_tasks": [],
                                          "task_category": "Code Execution",
                                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                        }
                                      ],
                                      "task_category": null,
                                      "finegrained_task_category": null
                                    },
                                    {
                                      "id": "8629705b-0212-4e69-b492-9f5a8c733d47",
                                      "requirements": "10 seeded runs using ADVI to estimate the posterior of the PosteriorDB `eight-schools-centered` problem, at dimension D=10, with a batch size of 32 have been run.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Experimental Setup"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "cf4c3c08-732c-4b63-bdc5-1fb96fd73533",
                  "requirements": "The results of Figure 5.3 and of Figure E.6 have been replicated",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "b686ecb8-9b9c-405c-bffd-004e4881c42d",
                      "requirements": "The relative mean error between HMC and estimated PosteriorDB problem posteriors measured over VI iterations for BaM and ADVI show BaM outperforms ADVI, converging earlier (in terms of number of iterations) to lower relative mean errors.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "791e7650-8d70-4584-a966-ca4bf37bd3b4",
                      "requirements": "The relative mean error between HMC and estimated PosteriorDB problem posteriors measured over VI iterations for BaM and GSM show that GSM can converge faster than BaM for smaller batch sizes.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "43895a25-8e25-4b18-aee4-728c61a4a9db",
                      "requirements": "The relative mean error between HMC and estimated PosteriorDB problem posteriors measured over VI iterations for BaM, ADVI and GSM show that in general BaM tends to benefit from larger batch sizes, while ADVI and GSM do not.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5822d5a9-72f1-4730-a255-e40a31415d18",
                      "requirements": "The relative mean error and relative standard error between HMC and estimated PosteriorDB problem posteriors measured over VI iterations for BaM, ADVI and GSM show that in general the same trends can be observed for relative mean error and relative standard error, with the exception of the \"hierarchical\" `eight-schools-centered` problem where BaM converges to a higher relative standard error than GSM or ADVI.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "8803a184-1fa5-4a39-baca-386cb567f63b",
              "requirements": "The results of Figure 5.4 b) from Section 5.3 have been replicated",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "9cc7e7f5-064d-48f0-a73a-5cf4eb2fe7aa",
                  "requirements": "Various variational inference methods have been run at various batch sizes to reconstruct a sampled test image, and their performance has been measured in terms of MSE",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cb7abd7b-6641-4543-8d81-a35bbf096c1b",
                      "requirements": "The CIFAR 10 dataset has been acquired",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "6679061e-6501-4e0f-8e1a-ca8470bdcd2e",
                          "requirements": "Code has been implemented such that the CIFAR 10 dataset can be used",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "8789e782-2545-4758-a973-0f751ae6ea49",
                          "requirements": "Code has been executed such that the CIFAR 10 dataset can be used (e.g. the dataset has been downloaded and other experiments in the reproduction can use it)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "5f27f91b-a9f2-427b-b6fa-ff5e41b4c4d3",
                      "requirements": "A Variational Autoencoder (VAE) has been pre-trained on the CIFAR 10 image dataset",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "cbdea725-c958-4c4b-adc4-52fb6355b060",
                          "requirements": "A generative model based on a variational autoencoder architecture has been implemented as outlined in Section 5.3 and Appendix E.6",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b8517162-bb66-404a-af9c-39dcced08412",
                              "requirements": "A variational autoencoder architecture has been implemented such that the encoder and decoder each consist of 5 convolutional layers.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "fd19a4f4-ca51-4978-bcb4-73b45e2aa418",
                              "requirements": "The generative model has been implemented such that it models the images using a Gaussian Likelihood over the distribution of images",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "b8a1676d-4cd0-4397-b4a9-c91b70d1bfaf",
                              "requirements": "The generative model has been implemented such that its Gaussian likelihood is parameterized by a neural network (decoder) that takes the latent variable as input and outputs the mean of the Gaussian distribution.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c8f3e04d-9187-4949-91f9-8f363785ffc3",
                              "requirements": "The generative model's gaussian likelihood has been implemented such that the covariance is fixed to $\\sigma^2 I$, where $I$ is the identity matrix and $\\sigma^2$ is fixed to 0.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a8db3546-d879-4a06-b6a8-ffc58050515c",
                              "requirements": "The variational autoencoder hyperparameters and architecture generally align with what is outlined in the addendum",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "776005f7-83e6-4cc7-b525-cdde22e36115",
                          "requirements": "A Variational Autoencoder (VAE) has been pre-trained on the CIFAR 10 image dataset training split",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "787c443a-13bc-40b1-bdf1-1f685db90ef5",
                              "requirements": "Code has been implemented such that a VAE can be trained on the CIFAR 10 image dataset training split as described in section E.6",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5bcc62df-5cf7-4978-9fd8-b581f66848ed",
                                  "requirements": "Code has been implemented such that a VAE can be trained on the CIFAR 10 image dataset training split following the standard VAE training procedure from Kingma & Welling, 2014 described in Appendix E.6",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8d91ae75-4503-4268-a56b-67fb863db0ed",
                                  "requirements": "Code has been implemented such that a VAE can be trained on the CIFAR 10 image dataset training split for 100 epochs",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "265cfd4c-8965-4a27-83b1-949da54c932f",
                                  "requirements": "Code has been implemented such that a VAE can be trained on the CIFAR 10 image dataset generally following the training hyperparameters outlined in the addendum",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "48bfed00-8e9a-48db-8ba0-6493743b43cf",
                              "requirements": "A Variational Autoencoder (VAE) has been pre-trained on the CIFAR 10 image dataset training split",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "479536e1-9e0e-4673-8f51-f3988503c024",
                                  "requirements": "Code has been executed such that a VAE has been trained on the CIFAR 10 image dataset training split following the standard VAE training procedure from Kingma & Welling, 2014 described in Appendix E.6",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6d8670e2-8f99-48ba-bcef-5cbc1b96edf0",
                                  "requirements": "Code has been executed such that when training a VAE on the CIFAR 10 image dataset training split, the VAE was trained for 100 epochs.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "842cfb0d-e108-4089-a7ba-208d88bcf5a3",
                                  "requirements": "Code has been executed such that when training a VAE on the CIFAR 10 image dataset training split, the VAE was trained generally following the training hyperparameters outlined in the addendum",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "81ac357b-830a-4bad-9305-04a91ed77285",
                      "requirements": "Code has been implemented such that the score function for the posterior ($s(z) = \\nabla_z \\log p(z \\mid x) = \\nabla_z \\log p(z) + \\nabla_z \\log p(x \\mid z), $ where $p(x \\mid z)$ is the decoder network) can be computed (likely via an autodiff solution)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1d9d9df5-f7a5-40e4-800a-705d831371af",
                      "requirements": "Code has been implemented such that the Mean Squared Error (MSE) between two images can be computed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d64a1115-e48b-4c54-b859-e5ed8d42bce7",
                      "requirements": "An image x' has been drawn from the CIFAR 10 image dataset test split",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "7beb3412-0366-4f3f-93c6-814a5968ca47",
                          "requirements": "Code has been implemented such that an image x' can be sampled from the CIFAR 10 image dataset test split",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "fb40e7cd-4686-4df4-a152-9f787361db7d",
                          "requirements": "An image x' has been sampled from the CIFAR 10 image dataset test split",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "30cfc3c2-025c-427d-9e7f-abc61292eaeb",
                      "requirements": "Code has been implemented such that the estimated mean from a given VI method can be input into the decoder so to obtain the reconstructed image",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "449360f6-aa09-4d6e-907c-76814c544da1",
                      "requirements": "BaM, ADVI, GSM and AVI (the trained encoder network) have been run at various batch sizes to reconstruct the sampled test image, and their performance has been measured in terms of MSE",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "42fba8df-3c8c-4377-876c-f7f0f5bcbf17",
                          "requirements": "BaM has been run at various batch sizes to reconstruct the sampled test image, and its performance has been measured in terms of MSE",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "4b88bdfd-4056-4cf0-bfc7-86c59aea7047",
                              "requirements": "Code has been implemented such that the estimated mean from BaM can be input into the decoder at each iteration so to obtain the reconstructed image at that iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c447e67b-342e-47b4-bd00-a434bfd9bbbc",
                              "requirements": "Code has been implemented such that the MSE between reconstructed image obtained from BaM and the sampled test image can be computed at each iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9136b526-737a-452d-9b48-221ac549d532",
                              "requirements": "Code has been implemented such that when using BaM to reconstruct the sampled test image, BaM can be run for at least 1000 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "61e767ef-144e-48cb-ac7b-f80117429e28",
                              "requirements": "BaM has been run at batch size 10 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "92f8164c-6afa-41fe-9b33-1bcc20080e63",
                                  "requirements": "Code has been implemented such that BaM can be run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4bab7e9b-02aa-40b0-9e22-cf86cd8eb3fd",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using BaM at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "78f2fcf2-a5f1-4f41-92a1-b34e9ab0cd03",
                                  "requirements": "The optimal learning rate for using BaM to estimate the posterior mean needed for reconstructing the sampled test image with batch size 10 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "444bc2d7-6615-4d2a-9b6b-f24c03a6881b",
                                  "requirements": "BaM has been run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8f56f69f-35ec-4aea-b112-3a68654c47f0",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, at least at least 1000 iterations of BaM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "18a8972e-b70d-45b2-bb61-0bae8190c1a0",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "293b53bf-0280-401b-984f-31b9a013ca98",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "642a99d9-9bc6-498f-bf2e-43996915eb00",
                              "requirements": "BaM has been run at batch size 100 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5cf24aad-ca74-445b-a873-0d12fb447b3c",
                                  "requirements": "Code has been implemented such that BaM can be run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "362a7e97-2a07-4f20-af41-e4af3850bebf",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using BaM at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ef8e44b8-9ec2-49ee-b5bb-f6e4f9d81a55",
                                  "requirements": "The optimal learning rate for using BaM to estimate the posterior mean needed for reconstructing the sampled test image with batch size 100 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b0690065-7dff-45bd-bf6c-4ec1f0e5bc8a",
                                  "requirements": "BaM has been run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "9d9748a1-c0ad-4c7d-bbe5-5fb17afbf5d3",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, at least at least 1000 iterations of BaM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6ff3d104-79ab-44e8-8fe9-2e927e32b295",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a991dbb8-4629-4d6c-8398-ef4605e4ddfa",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "5d2b97fc-0a39-4094-8493-e6e8230d33da",
                              "requirements": "BaM has been run at batch size 300 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "65d88f8d-7c64-46cc-8a72-04e72441e024",
                                  "requirements": "Code has been implemented such that BaM can be run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "50ae9c10-4481-4a89-9944-f71198459a83",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using BaM at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "f3ebd402-acf6-4b4b-b157-c29070429970",
                                  "requirements": "The optimal learning rate for using BaM to estimate the posterior mean needed for reconstructing the sampled test image with batch size 300 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "0bd5bc5f-610c-4d6b-8a25-eff36993c3d7",
                                  "requirements": "BaM has been run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "143b6d2d-7745-4a54-9106-0c57610de19d",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, at least at least 1000 iterations of BaM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "82747cf2-6d84-451f-82dc-a841f36d8e82",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ad5934b0-78aa-4783-95c0-15e05c702d3a",
                                  "requirements": "When using BaM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "78b697ad-51bb-4792-af3e-9d479d51b5e2",
                          "requirements": "ADVI has been run at various batch sizes to reconstruct the sampled test image, and its performance has been measured in terms of MSE",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1599c293-f743-42a6-b270-2811a12d44b5",
                              "requirements": "Code has been implemented such that the estimated mean from ADVI can be input into the decoder at each iteration so to obtain the reconstructed image at that iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "dbea0f87-17b9-443d-85ba-04f9f67a084c",
                              "requirements": "Code has been implemented such that the MSE between reconstructed image obtained from ADVI and the sampled test image can be computed at each iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "16a7fbdb-d257-4ec0-af3e-0ce49bd9f60d",
                              "requirements": "Code has been implemented such that when using ADVI to reconstruct the sampled test image, ADVI can be run for at least 1000 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "e5263b24-0530-47fb-9039-f9628a9f2da9",
                              "requirements": "ADVI has been run at batch size 10 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "84a43414-e9c3-4765-aa3a-848b1b8b2014",
                                  "requirements": "Code has been implemented such that ADVI can be run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "c8c170eb-d12f-4546-bb75-f8376596c8f3",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using ADVI at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ad5f8cea-d7e3-4034-8a1b-57335d91c552",
                                  "requirements": "The optimal learning rate for using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with batch size 10 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "33b601eb-4850-47f1-aa0a-cb922a950568",
                                  "requirements": "ADVI has been run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "bd7a93a4-6f40-4a90-a230-487327325001",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, at least at least 1000 iterations of ADVI have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "0f945396-fb64-4464-97c5-245fa8a0dba7",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "8d713188-2d8b-4a32-8420-6436c2acc931",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "507245b2-40d2-4fcf-bcbc-4d4f80c794f2",
                              "requirements": "ADVI has been run at batch size 100 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8c7c43b4-481e-42ec-b699-91855feb3bc6",
                                  "requirements": "Code has been implemented such that ADVI can be run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6ff69661-d1fe-4cac-9f73-70ad6ab25df2",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using ADVI at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5c34a45f-b8bc-429f-8a35-a75d9d01f427",
                                  "requirements": "The optimal learning rate for using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with batch size 100 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "1b648575-fd50-4c80-b7c1-80056bdf212b",
                                  "requirements": "ADVI has been run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "105cd5c2-6b31-42fc-9b30-be0fffabff8d",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, at least at least 1000 iterations of ADVI have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6feffede-d52b-41cd-ab1b-81b353524171",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "409a175d-3094-4bda-b67b-a59aef9fefc5",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "66fbad5a-7d67-40ff-8864-477b278b1ece",
                              "requirements": "ADVI has been run at batch size 300 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7d45f253-70e1-4f43-b68c-1653ae3e38dd",
                                  "requirements": "Code has been implemented such that ADVI can be run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "e8ae0196-2a93-4226-8043-70544c914c2d",
                                  "requirements": "Code has been implemented such that a preliminary grid search on 100 iterations can be run for determining the optimal learning rate for using ADVI at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5ddd339b-f32b-40a0-ae02-679f58791615",
                                  "requirements": "The optimal learning rate for using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with batch size 300 has been determined using a grid search",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "01173144-a0f3-41d8-affd-9b1b351ef8fd",
                                  "requirements": "ADVI has been run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4b609e68-998b-4927-ab05-372feafa9b12",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, at least at least 1000 iterations of ADVI have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "34bb1182-bf82-4449-b80c-213530a7fd8b",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, the learning rate was set to the learning rate determined by the grid search.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "e535aeb4-eb78-4fa6-950c-48a1933aef50",
                                  "requirements": "When using ADVI to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3538427b-09a8-43b5-bf62-8295e4b89dcb",
                          "requirements": "GSM has been run at various batch sizes to reconstruct the sampled test image, and its performance has been measured in terms of MSE",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "746cbd4c-1558-49ad-bba3-abe9a8fd7c3f",
                              "requirements": "Code has been implemented such that the estimated mean from GSM can be input into the decoder at each iteration so to obtain the reconstructed image at that iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "f13eba45-776d-4dd6-8e04-8eaa468413b3",
                              "requirements": "Code has been implemented such that the MSE between reconstructed image obtained from GSM and the sampled test image can be computed at each iteration",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f3e2ff6e-c0b8-4b54-aee6-8285452f6000",
                              "requirements": "Code has been implemented such that when using GSM to reconstruct the sampled test image, GSM can be run for at least 1000 iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "2d448677-045e-4a6f-873d-ff4eb35fcb75",
                              "requirements": "GSM has been run at batch size 10 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a86e824a-6bc5-41c6-ab6c-89b8797d42a6",
                                  "requirements": "Code has been implemented such that GSM can be run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "44c8f43d-7e69-4f28-853f-efe0d2f2da29",
                                  "requirements": "GSM has been run at batch size 10 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a79c3275-b73a-4f05-a065-8506e1b924a4",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, at least at least 1000 iterations of GSM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b5399414-8376-4669-bcf4-13087a8f75aa",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 10, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a2fb844b-111d-4c3d-9877-c52dd263cc66",
                              "requirements": "GSM has been run at batch size 100 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "586b4963-d082-4d8d-8640-8055030820f6",
                                  "requirements": "Code has been implemented such that GSM can be run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "71ab7d5d-29a2-4fd3-afe5-ff4bb7d3e080",
                                  "requirements": "GSM has been run at batch size 100 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a19b55e0-b4f1-4a18-835f-ce9690e3264c",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, at least at least 1000 iterations of GSM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "75ee4374-3bcf-4253-be8e-def88934959e",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 100, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "41136115-fdd9-4523-8ec4-8dd9582e3747",
                              "requirements": "GSM has been run at batch size 300 to reconstruct the sampled test image",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "83b55f93-fb44-4259-909c-f3d5e529ab11",
                                  "requirements": "Code has been implemented such that GSM can be run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "f602226a-0a14-45d3-a43f-94d6888c0d34",
                                  "requirements": "GSM has been run at batch size 300 to estimate the posterior mean needed for reconstructing the sampled test image",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "477df8a0-2843-4307-908c-8abf635d06f7",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, at least at least 1000 iterations of GSM have been run.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4c2a435c-7588-4d3e-a9de-f2d4fc216649",
                                  "requirements": "When using GSM to estimate the posterior mean needed for reconstructing the sampled test image with a batch size of 300, the MSE between the reconstructed image and the sampled test image has been measured at each iteration",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4ab092fb-645e-4d36-a8db-1417295532f0",
                          "requirements": "AVI (the trained encoder network) has been run to reconstruct the sampled test image, and its performance has been measured in terms of MSE",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "97ed714b-be12-420d-8cec-37c94e7c1c82",
                              "requirements": "Code has been implemented such that the estimated mean from AVI (the trained encoder network) can be input into the decoder so to obtain the reconstructed image",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "34cd15c2-47e3-4cc5-86a1-ca64733d35e2",
                              "requirements": "Code has been implemented such that the MSE between reconstructed image obtained from AVI (the trained encoder network) and the sampled test image can be computed",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f0dbb6ed-4360-4315-b5ea-5f837cfcdb39",
                              "requirements": "Code has been implemented such that AVI (the trained encoder network) can be run at to estimate the posterior mean needed for reconstructing the sampled test image",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "1a663a4f-d707-48d1-9a22-5bcf121b6fd3",
                              "requirements": "AVI (the trained encoder network) has been run to estimate the posterior mean needed for reconstructing the sampled test image",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "9d3ca042-2b68-42b1-9c2b-8d5b75137e12",
                              "requirements": "When using AVI (the trained encoder network) to estimate the posterior mean needed for reconstructing the sampled test image, the MSE between the reconstructed image and the sampled test image has been measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ee240796-d386-486a-bd70-b1551f013947",
                  "requirements": "The results of Figure 5.4 b) from Section 5.3 have been replicated",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "949cbdd8-617b-4f85-8da4-79bfcb35ab5f",
                      "requirements": "The MSE between the reconstructed image and the sampled test image measured over the VI iterations for BaM at batch size 10 shows that BaM performs poorly (MSE greater than 0.2) at smaller batch sizes, i.e. at a batch size of 10.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8e0dacf2-f476-4941-9668-7bc455b46d9a",
                      "requirements": "The MSE between the reconstructed image and the sampled test image measured over the VI iterations for BaM at batch sizes 100 and 300 show that BaM performs competitively (MSE less than 0.05) at larger batch sizes, i.e. at a batch size of 100 and 300.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6e7bf691-0f0c-468e-be72-c16877e89da5",
                      "requirements": "The MSE between the reconstructed image and the sampled test image measured over the VI iterations for BaM, GSM and ADVI at batch size 300 show that BaM converges an order of magnitude (or more) faster (in terms of taking less iterations to converge) than ADVI and GSM",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d520be6a-63e5-4dcc-94af-e9cb5e094b1c",
                      "requirements": "The MSE between the reconstructed image and the sampled test image measured over the VI iterations for BaM, ADVI and AVI at batch sizes 10, 100 and 300 show that in general either BaM or ADVI or both achieve a MSE than AVI.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "bbox",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "root",
          "requirements": "The BBOX-ADAPTER approach for adapting black-box LLMs has been reproduced completely.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "core-implementation",
              "requirements": "Algorithm 1 (Online Adaptation) has been implemented correctly.",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "model-components",
                  "requirements": "The core model components required for Algorithm 1 have been implemented.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "energy-based-model",
                      "requirements": "The joint model parameterization $p_{\\theta}(y|x) = \\exp(g_{\\theta}(s_{1:L},x))\\prod_l p_{LLM}(s_l|x,s_{1:l-1})$ has been implemented with the correct adapter architecture as described in Section 3.3.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "adapter-backbone",
                          "requirements": "The adapter backbone models have been implemented as specified in Appendix H.2.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "deberta-base-tasks",
                              "requirements": "The deberta-v3-base (0.1B) model has been implemented for StrategyQA, GSM8K, and ScienceQA tasks.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "deberta-base-strategyqa",
                                  "requirements": "The deberta-v3-base model has been implemented for StrategyQA with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "deberta-base-gsm8k",
                                  "requirements": "The deberta-v3-base model has been implemented for GSM8K with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "deberta-base-scienceqa",
                                  "requirements": "The deberta-v3-base model has been implemented for ScienceQA with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "deberta-large-tasks",
                              "requirements": "The deberta-v3-large (0.3B) model has been implemented for StrategyQA, GSM8K, and ScienceQA tasks.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "deberta-large-strategyqa",
                                  "requirements": "The deberta-v3-large model has been implemented for StrategyQA with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "deberta-large-gsm8k",
                                  "requirements": "The deberta-v3-large model has been implemented for GSM8K with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "deberta-large-scienceqa",
                                  "requirements": "The deberta-v3-large model has been implemented for ScienceQA with the hyperparameters specified in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "bert-base-tasks",
                              "requirements": "The bert-base-cased (110M) model has been implemented for TruthfulQA with the hyperparameters specified in Appendix H.2.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-inputs",
                          "requirements": "The adapter accepts input text pairs (x,y) and processes them through the DeBERTa encoder.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "adapter-outputs",
                          "requirements": "The adapter outputs a scalar score $g_{\\theta}(x,y)$ representing the energy value for the input pair.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "nce-loss",
                      "requirements": "The adapter training loss from Equation 3 has been implemented with spectral normalization and training process from Section 3.2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "loss-components",
                          "requirements": "The NCE loss components have been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "positive-terms",
                              "requirements": "The positive sample terms $-\\mathbb{E}_{y^+ \\sim p_{data}(y|x)}[g_\\theta(x,y^+)] + \\alpha\\mathbb{E}[g_\\theta(x,y^+)^2]$ have been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "negative-terms",
                              "requirements": "The negative sample terms $\\mathbb{E}_{y^- \\sim p_\\theta(y|x)}[g_\\theta(x,y^-)] + \\alpha\\mathbb{E}[g_\\theta(x,y^-)^2]$ have been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "training-implementation",
                          "requirements": "The training process components have been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "adapter-training-execution",
                              "requirements": "The adapter has been trained using the NCE loss and spectral normalization for the specified number of steps.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "loss-computation",
                              "requirements": "The NCE loss has been implemented according to Equation (3) in the paper, which includes: $\\nabla_{\\theta}\\ell(\\theta) = \\nabla_{\\theta}\\{-\\mathbb{E}_{y+\\sim p_{data}(y|x)}[g_{\\theta}(x,y+)] + \\alpha\\mathbb{E}[g_{\\theta}(x,y+)^2] + \\mathbb{E}_{y-\\sim p_{\\theta}(y|x)}[g_{\\theta}(x,y-)] + \\alpha\\mathbb{E}[g_{\\theta}(x,y-)^2]\\}$, incorporating both positive and negative sample terms with regularization.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "gradient-updates",
                              "requirements": "The gradient updates $\\nabla_{\\theta} \\mathcal{L}_{NCE}$ have been implemented with $\\eta=5e-6$ as specified in Appendix H.2.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "spectral-normalization",
                              "requirements": "Spectral normalization has been applied to the energy model $g_{\\theta}$ to increase gradient stability.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "beam-search",
                      "requirements": "The adapted inference mechanism using beam search has been implemented, combining the black-box LLM's proposal with adapter scoring.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "sentence-level-factorization",
                          "requirements": "The sentence-level factorization of the adapted inference process has been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "sequence-decomposition",
                              "requirements": "The decomposition of complete solution $y$ into sentence-level sequences $[s_1, s_2, ..., s_L]$ has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "autoregressive-scoring",
                              "requirements": "The autoregressive scoring of sequences using both LLM probabilities and adapter scores has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "beam-management",
                          "requirements": "The beam management system for tracking and updating candidate solutions has been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "candidate-generation",
                              "requirements": "The generation of $M$ samples per beam at each step $l$ based on $p_{LLM}(s_l|x,s_{1:l-1})$ has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "beam-scoring",
                              "requirements": "The scoring of $nk$ candidate chains using the adapter $g_\\theta(s_{1:l},x)$ has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "beam-pruning",
                              "requirements": "The selection of top-k beams based on adapter scores has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "stopping-criteria",
                          "requirements": "The stopping criteria and final selection process have been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "termination-check",
                              "requirements": "The checking for either reaching $L$ iterations or encountering stop signals has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "final-selection",
                              "requirements": "The selection of the highest-scoring complete solution from the $k$ final candidates has been implemented.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adapter-variants",
                      "requirements": "Both single-step and full-step variants of the adapter have been implemented.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "single-step-implementation",
                          "requirements": "The single-step adapter variant has been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "single-step-generation",
                              "requirements": "The base model generates a set of complete answers in a single step.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "single-step-selection",
                              "requirements": "The adapter selects the best answer from the candidates as the final response.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "full-step-implementation",
                          "requirements": "The full-step adapter variant with beam search has been implemented.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "full-step-generation",
                              "requirements": "The base model generates multiple solution paths using beam search.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "full-step-selection",
                              "requirements": "The adapter scores and selects the top-$k$ paths at each step, maintaining a beam size of $k=3$ by default as specified in the paper.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "base-llm",
                      "requirements": "The base LLM (either GPT-3.5 Turbo or Mixtral-8x7B) has been integrated as a black-box model.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "llm-generation",
                          "requirements": "The LLM can generate text completions given input prompts.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "prompt-handling",
                              "requirements": "Code has been written to properly format and send prompts to the LLM API.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "completion-handling",
                              "requirements": "Code has been written to parse completion responses from the LLM API.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "generation-params",
                          "requirements": "The LLM generation parameters have been configured correctly.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "temperature-setting",
                              "requirements": "The temperature is set to 1.0 for generation as specified in Appendix H.2.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "max-length-setting",
                              "requirements": "The maximum generation length is set to 512 as specified in Appendix H.2.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-integration",
                          "requirements": "The LLM outputs can be used as proposals in the adapter framework.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "proposal-generation",
                              "requirements": "Code has been written such that the LLM can generate candidate proposals for the adapter to score.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "black-box-usage",
                              "requirements": "Code has been written such that the LLM is treated as a black box without accessing internal parameters or probabilities.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "online-adaptation-algorithm",
                  "requirements": "Algorithm 1 (Online Adaptation) has been implemented correctly.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "initialization",
                      "requirements": "The initialization steps of Algorithm 1 have been implemented.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "random-init",
                          "requirements": "Random initialization of adapter parameters $\\theta_0$ has been implemented.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "initial-sampling",
                          "requirements": "Initial sampling of $K$ responses for each input query has been implemented: ${y_{i,j}}^K_{j=1} \\sim p_{LLM}(y|x_i)$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "initial-selection",
                          "requirements": "Initial positive/negative sample selection has been implemented with the appropriate method based on data availability.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ground-truth-selection",
                              "requirements": "When ground truth data is available, positive samples are taken from ground truth solutions while negative samples are generated using an adapter with random parameters.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "ai-feedback-selection",
                              "requirements": "When ground truth data is unavailable, positive samples are selected based on AI feedback (using GPT-4) from generated candidates, while remaining candidates serve as negative samples.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adaptation-loop",
                      "requirements": "The main adaptation loop from Algorithm 1 has been implemented.",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "eq4-implementation",
                          "requirements": "Sampling $M$ candidates from adapted inference has been implemented as described in Equation 4 i.e., ${\\hat{y}_{i,m}}^M_{m=1} \\sim p_{\\theta_t}(y|x_i)$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "eq5-implementation",
                          "requirements": "The update of positive samples has been implemented as described in Equation 5 i.e., $y^{(t)}_{i+} = \\text{SEL}(y^{(t-1)}_{i+}, {\\hat{y}_{i,m}}^M_{m=1})$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "eq6-implementation",
                          "requirements": "The update of negative samples has been implemented as described in Equation 6 i.e., $y^{(t)}_{i-} = {\\hat{y}_{i,m} | \\hat{y}_{i,m} \\neq y^{(t)}_{i+}}^M_{m=1}$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "eq3-implementation",
                          "requirements": "The computation of the loss gradient has been implemented as described in Equation 3 i.e., $\\nabla_\\theta \\ell(\\theta_t)$ using $y^{(t)}_{i+}$ and $y^{(t)}_{i-}$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "eq7-implementation",
                          "requirements": "The parameter update has been implemented as described in Equation 7 i.e., $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\ell(\\theta_t)$",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "evaluation-setup",
              "requirements": "The evaluation environments and datasets have been set up for GPT-3.5 Turbo and Mixtral-8x7B.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "dataset-preparation",
                  "requirements": "The evaluation datasets have been prepared, including train/test splits and data preprocessing.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "gsm8k-setup",
                      "requirements": "The GSM8K dataset has been downloaded and split into train and test splits, as described in Appendix F.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "gsm8k-download-code",
                          "requirements": "Code has been written to download the GSM8K questions and step-by-step solutions.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "gsm8k-download-exec",
                          "requirements": "The GSM8K questions and step-by-step solutions have been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "gsm8k-split-code",
                          "requirements": "Code has been written to split the GSM8K dataset into 7473 training and 1319 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "gsm8k-split-exec",
                          "requirements": "The GSM8K dataset has been split into 7473 training and 1319 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "strategyqa-setup",
                      "requirements": "The StrategyQA dataset has been downloaded and split into train and test splits, as described in Appendix F.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "strategyqa-download-code",
                          "requirements": "Code has been written to download the StrategyQA questions and reasoning steps.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "strategyqa-download-exec",
                          "requirements": "The StrategyQA questions and reasoning steps have been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "strategyqa-split-code",
                          "requirements": "Code has been written to split the StrategyQA dataset into 2059 training and 229 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "strategyqa-split-exec",
                          "requirements": "The StrategyQA dataset has been split into 2059 training and 229 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "truthfulqa-setup",
                      "requirements": "The TruthfulQA dataset has been downloaded and split into train and test splits, as described in Appendix F.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "truthfulqa-download-code",
                          "requirements": "Code has been written to download the TruthfulQA questions.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "truthfulqa-download-exec",
                          "requirements": "The TruthfulQA questions have been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "truthfulqa-split-code",
                          "requirements": "Code has been written to randomly sample 100 questions for the test set and use the remaining 717 samples for training.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "truthfulqa-split-exec",
                          "requirements": "The TruthfulQA dataset has been split into 717 training and 100 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "scienceqa-setup",
                      "requirements": "The ScienceQA dataset has been downloaded and split into train and test splits, as described in Appendix F.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "scienceqa-download-code",
                          "requirements": "Code has been written to download the non-image ScienceQA questions.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "scienceqa-download-exec",
                          "requirements": "The non-image ScienceQA questions have been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "scienceqa-split-code",
                          "requirements": "Code has been written to randomly select 2000 questions for training and 500 for testing from the original splits.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "scienceqa-split-exec",
                          "requirements": "The ScienceQA dataset has been split into 2000 training and 500 test samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "base-model-setup",
                  "requirements": "The base models have been set up for evaluation with correct configurations, as specified in Appendix H.2.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "gpt-setup",
                      "requirements": "The GPT-3.5 Turbo model has been set up for evaluation with the correct configurations.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "azure-api-setup",
                          "requirements": "API access has been set up for text generation using GPT-3.5 Turbo, supporting the following features: (1) prompt-based text generation, (2) adjustable sampling temperature, and (3) control over maximum output length.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Environment & Infrastructure Setup"
                        },
                        {
                          "id": "gpt-generation-params",
                          "requirements": "The model is configured with temperature 1.0 and a maximum length of 512 tokens for generation.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "gpt-finetune-params",
                          "requirements": "The fine-tuning hyperparameters have been configured with number of epochs set to 5.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "mixtral-setup",
                      "requirements": "The Mixtral-8x7B model has been set up for evaluation with correct configurations.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "mixtral-model-loading",
                          "requirements": "The mixtral-8x7B-v0.1 model has been loaded from HuggingFace in half-precision.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "mixtral-generation-params",
                          "requirements": "The model is configured with temperature 1.0 and a maximum length of 512 tokens for generation.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "adapter-model-setup",
                  "requirements": "The adapter backend models have been set up with correct configurations.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "deberta-setup",
                      "requirements": "The DeBERTa models have been set up to be evaluated on the StrategyQA, GSM8K, and ScienceQA datasets.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "deberta-base-setup",
                          "requirements": "The deberta-v3-base model has been properly loaded and configured.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "model-loading",
                              "requirements": "Code has been written to load and initialize the deberta-v3-base model (86M) with correct model weights.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Dataset and Model Acquisition"
                            },
                            {
                              "id": "classification-head",
                              "requirements": "The final layer has been modified to a classification head with an output dimension of 1 to ensure the adapter outputs a scalar score value.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "deberta-large-setup",
                          "requirements": "The deberta-v3-large model has been properly loaded and configured.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "model-loading-large",
                              "requirements": "Code has been written to load and initialize the deberta-v3-large model (304M) with correct model weights.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Dataset and Model Acquisition"
                            },
                            {
                              "id": "classification-head-large",
                              "requirements": "The final layer has been modified to a classification head with an output dimension of 1 to ensure the adapter outputs a scalar score value.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "bert-setup",
                      "requirements": "The bert-base-cased model has been set up to be evaluated on TruthfulQA.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bert-model-loading",
                          "requirements": "The bert-base-cased model has been properly loaded and configured.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "model-loading-bert",
                              "requirements": "Code has been written to load the weights of the bert-base-cased (110M) model.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Dataset and Model Acquisition"
                            },
                            {
                              "id": "classification-head-bert",
                              "requirements": "The final layer has been modified to a classification head with an output dimension of 1 to ensure the adapter outputs a scalar score value.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "bert-inference-check",
                          "requirements": "Code has been written to query the model on TruthfulQA samples.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "training-config",
                      "requirements": "The training loop for the adapter modules has been implemented.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "optimizer-setup",
                          "requirements": "The AdamW optimizer has been configured with learning rate 5e-6 and weight decay 0.01.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "batch-config",
                          "requirements": "The training loop has been implemented to process data in batches of size 64 and run for 6000 training steps as specified in Appendix H.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "baseline-impl",
              "requirements": "The baseline models have been implemented and/or configured for evaluations.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "d88d22d8-e5cc-4248-bbe7-cddb35005c17",
                  "requirements": "The Chain-of-Thought using GPT-3.5 Turbo baseline has been implemented.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ab87b0ff-7caf-4678-89f5-8341600cebe9",
                      "requirements": "The two-shot prompt for StrategyQA has been implemented as specified in Appendix J.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d865c8bb-b7e2-4908-94cf-d1f854319112",
                      "requirements": "The four-shot prompt from Chain-of-Thought Hub has been implemented for GSM8K, as specified in Appendix J.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "86dd3099-e471-46fc-bd98-b49e899ba498",
                      "requirements": "The one-shot prompt for ScienceQA has been implemented as specified in Appendix J.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "azure-sft-impl",
                  "requirements": "The Azure-SFT baseline using OpenAI fine-tuning service has been implemented.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "azure-sft-setup",
                      "requirements": "The Azure OpenAI fine-tuning service has been set up.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "data-formatting",
                          "requirements": "The training data has been formatted according to Azure fine-tuning API requirements.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "hyperparameter-config",
                          "requirements": "The fine-tuning hyperparameters (epochs=3, batch size and learning rate as Azure OpenAI service default values) have been configured.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "azure-sft-training",
                      "requirements": "The fine-tuning process has been executed using Azure service.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "azure-sft-implementation",
                          "requirements": "Code has been written to execute fine-tuning jobs through the Azure OpenAI API.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "azure-sft-execution",
                          "requirements": "The fine-tuning jobs have been executed successfully for all tasks.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "training-monitoring",
                          "requirements": "The training loss curves have been saved during Azure-SFT fine-tuning.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "loss-tracking-implementation",
                              "requirements": "Code has been written to save the training loss curves during Azure-SFT fine-tuning for the StrategyQA, TruthfulQA, and ScienceQA datasets.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7e2f154e-02a3-43a6-bf8e-2bfb5cc3711e",
                                  "requirements": "Code has been implemented to compute and save the training loss curves for the StrategyQA fine-tuning process, following the specifications in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "357edc2c-417b-49ff-b3fd-59af7134f147",
                                  "requirements": "Code has been implemented to compute and save the training loss curves for the TruthfulQA fine-tuning process, following the specifications in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "c4d72598-0892-4d1a-98a7-9fa92fe0fbd7",
                                  "requirements": "Code has been implemented to compute and save the training loss curves for the ScienceQA fine-tuning process, following the specifications in Appendix H.2.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "loss-tracking-execution",
                              "requirements": "The training loss curves have been generated and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "strategyqa-loss-curves",
                                  "requirements": "Training loss curves have been saved for StrategyQA fine-tuning.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "truthfulqa-loss-curves",
                                  "requirements": "Training loss curves have been saved for TruthfulQA fine-tuning.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "scienceqa-loss-curves",
                                  "requirements": "Training loss curves have been saved for ScienceQA fine-tuning.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "lora-ft-mix",
                  "requirements": "The LoRA fine-tuning baseline for Mixtral-8x7B has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "lora-setup",
                      "requirements": "The LoRA fine-tuning setup has been implemented.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "lora-config",
                          "requirements": "The LoRA hyperparameters have been configured correctly.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "lora-rank-small",
                              "requirements": "The rank parameter $r$ has been set to 128 for the 0.1B adapter comparison.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "lora-rank-large",
                              "requirements": "The rank parameter $r$ has been set to 384 for the 0.3B adapter comparison.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "lora-alpha",
                              "requirements": "The scaling parameter $\\alpha$ has been set to $2r$ (256 and 768 respectively) for both adapter versions.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "training-setup",
                          "requirements": "The training hyperparameters have been configured correctly.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "learning-rate",
                              "requirements": "The learning rate has been set to 2e-4.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "weight-decay",
                              "requirements": "The weight decay has been set to 0.001.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "batch-size",
                              "requirements": "The batch size per GPU has been set to 8.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "other-params",
                              "requirements": "The remaining parameters have been configured: LoRA dropout is set to 0.1, number of epochs is set to 3, maximum gradient norm is set to 0.3, optimizer is set to Paged AdamW 32bit, and scheduler is set to Cosine.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "lora-training",
                      "requirements": "The LoRA fine-tuning process has been executed.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "lora-training-implementation",
                          "requirements": "Code has been written to fine-tune Mixtral-8x7B using LoRA adaptation. The hyperparameters used for fine-tuning, listed in Table 8, include a LoRA dropout of 0.1, 3 epochs, a learning rate of 2e-4, weight decay of 0.001, and a batch size of 8 per GPU.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "lora-training-execution",
                          "requirements": "Mixtral-8x7B using LoRA adaptation has been fine-tuned for 3 epochs.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "gradient-clipping",
                          "requirements": "Gradient clipping with max norm 0.3 has been implemented.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "baseline-comparison",
              "requirements": "Table 2 has been reproduced.",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "cot-evaluation",
                  "requirements": "The GPT-3.5 Turbo with Chain-of-Thought baseline has been evaluated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cot-execution",
                      "requirements": "The Chain-of-Thought baseline has been evaluated on the test splits of all datasets using GPT-3.5 Turbo.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cot-performance-calculation",
                      "requirements": "The metrics for the base GPT-3.5 Turbo model have been calculated on all datasets (StrategyQA, GSM, TruthfulQA, ScienceQA).",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "cot-strategyqa-accuracy",
                          "requirements": "The accuracy of the base GPT-3.5 Turbo model on the StrategyQA dataset has been calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "cot-gsm8k-accuracy",
                          "requirements": "The accuracy of the base GPT-3.5 Turbo model on the GSM8K dataset has been calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "cot-truthfulqa-accuracy",
                          "requirements": "The True+Info metric of the base GPT-3.5 Turbo model on the TruthfulQA dataset has been calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "cot-scienceqa-accuracy",
                          "requirements": "The accuracy of the base GPT-3.5 Turbo model on the ScienceQA dataset has been calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "azure-sft-eval",
                  "requirements": "The GPT-3.5 Turbo model, fine-tuned using Azure-SFT, has been evaluated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "sft-execution",
                      "requirements": "The Azure-SFT fine-tuned model has been evaluated on the test splits of all datasets.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2c90777a-b539-4e37-8108-b7a62a741a9e",
                          "requirements": "The Azure-SFT fine-tuned model has been evaluated on the StrategyQA test split.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c6f6c8d9-e975-4cad-91df-08df536f0d0a",
                          "requirements": "The Azure-SFT fine-tuned model has been evaluated on the GSM8K test split.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9a21233a-43e3-4bee-ae5f-11cea32568f6",
                          "requirements": "The Azure-SFT fine-tuned model has been evaluated on the TruthfulQA test split.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "02f77608-6c71-4e6a-aeb3-82f7017eaf00",
                          "requirements": "The Azure-SFT fine-tuned model has been evaluated on the ScienceQA test split.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "sft-performance-calculation",
                      "requirements": "The metrics for Azure-SFT and base model have been calculated on all datasets (StrategyQA, GSM8K, TruthfulQA, and ScienceQA).",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "sft-strategyqa-calculation",
                          "requirements": "The accuracy metrics for Azure-SFT and base model have been calculated on StrategyQA dataset.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-gsm8k-calculation",
                          "requirements": "The accuracy metrics for Azure-SFT and base model have been calculated on GSM8K dataset.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-truthfulqa-calculation",
                          "requirements": "The True + Info metrics for Azure-SFT and base model have been calculated on TruthfulQA dataset.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-scienceqa-calculation",
                          "requirements": "The accuracy metrics for Azure-SFT and base model have been calculated on ScienceQA dataset.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "adapter-training",
                  "requirements": "Task-specific adapters have been trained, with separate adapters initialized and trained for each task as described in the paper.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "small-adapter-training",
                      "requirements": "Task-specific 0.1B adapters have been trained separately for each dataset.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "strategyqa-small-adapter",
                          "requirements": "The training process for a dedicated 0.1B adapter on the StrategyQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "gsm8k-small-adapter",
                          "requirements": "The training process for a dedicated 0.1B adapter on the GSM8K dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "truthfulqa-small-adapter",
                          "requirements": "The training process for a dedicated 0.1B adapter on the TruthfulQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "scienceqa-small-adapter",
                          "requirements": "The training process for a dedicated 0.1B adapter on the ScienceQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "large-adapter-training",
                      "requirements": "Task-specific 0.3B adapters have been trained separately for each dataset.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "strategyqa-large-adapter",
                          "requirements": "The training process for a dedicated 0.3B adapter on the StrategyQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "gsm8k-large-adapter",
                          "requirements": "The training process for a dedicated 0.3B adapter on the GSM8K dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "truthfulqa-large-adapter",
                          "requirements": "The training process for a dedicated 0.3B adapter on the TruthfulQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "scienceqa-large-adapter",
                          "requirements": "The training process for a dedicated 0.3B adapter on the ScienceQA dataset has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "best-performer-selection",
                      "requirements": "The best performing adapter size has been selected for each dataset based on validation performance.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "performance-comparison-code",
                          "requirements": "Code has been written to compare adapter sizes and select the best performer.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "performance-comparison-exec",
                          "requirements": "The performance comparison has been run and best performers selected.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bbox-gt-eval",
                  "requirements": "BBox-Adapter (Ground-Truth) has been evaluated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "gt-adapter-training",
                      "requirements": "The adapter has been trained using ground truth data.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "gt-evaluation",
                      "requirements": "The ground truth adapter has been evaluated on the test splits of all datasets.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "gt-metrics",
                      "requirements": "The performance metrics have been computed for StrategyQA, GSM8K, ScienceQA, and TruthfulQA.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "gt-acc-sqa",
                          "requirements": "The accuracy has been computed for StrategyQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-gsm8k",
                          "requirements": "The accuracy has been computed for GSM8K.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-scienceqa",
                          "requirements": "The accuracy has been computed for ScienceQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-truthfulqa",
                          "requirements": "The True+Info metric has been computed for TruthfulQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bbox-ai-eval",
                  "requirements": "BBox-Adapter (AI Feedback) has been evaluated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ai-adapter-training",
                      "requirements": "The adapter has been trained using AI feedback.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "ai-evaluation",
                      "requirements": "The AI feedback adapter has been evaluated on the test splits of all datasets.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ai-metrics",
                      "requirements": "The metrics have been computed for StrategyQA, GSM8K, TruthfulQA, and ScienceQA.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "gt-acc-strategyqa",
                          "requirements": "The accuracy has been computed for StrategyQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-gsm8k",
                          "requirements": "The accuracy has been computed for GSM8K.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-truthfulqa",
                          "requirements": "The True+Info metric has been computed for TruthfulQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "gt-acc-scienceqa",
                          "requirements": "The accuracy has been computed for ScienceQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bbox-combined-eval",
                  "requirements": "BBox-Adapter (Combined) has been evaluated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "combined-adapter-training",
                      "requirements": "The adapter has been trained using combined feedback.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "combined-evaluation",
                      "requirements": "The combined feedback adapter has been evaluated on the test splits of all datasets.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "combined-metrics",
                      "requirements": "The performance metrics have been computed for StrategyQA, TruthfulQA, GSM8K, and ScienceQA.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "combined-strategyqa",
                          "requirements": "The True+Info metric has been computed for StrategyQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "combined-truthfulqa",
                          "requirements": "The True+Info metric has been computed for TruthfulQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "combined-gsm8k",
                          "requirements": "The True+Info metric has been computed for GSM8K.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "combined-scienceqa",
                          "requirements": "The True+Info metric has been computed for ScienceQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "table2-results",
                  "requirements": "The computed results match those presented in Table 2.",
                  "weight": 5,
                  "sub_tasks": [
                    {
                      "id": "baseline-performance",
                      "requirements": "The baseline performance matches the performance reported in Table 2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "baseline-strategyqa",
                          "requirements": "The baseline model achieves an accuracy of ~66.59% on StrategyQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "baseline-gsm8k",
                          "requirements": "The baseline model achieves an accuracy of ~67.51% on GSM8K.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "baseline-truthfulqa",
                          "requirements": "The baseline model achieves an accuracy of ~72.90% on ScienceQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "baseline-scienceqa",
                          "requirements": "The baseline model achieves a True + Info score of ~77.00% on TruthfulQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "sft-improvements",
                      "requirements": "The Azure-SFT improvements match those reported in Table 2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "sft-strategyqa-gain",
                          "requirements": "The Azure-SFT model achieves an improvement of ~10.27% over the baseline model on StrategyQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-gsm8k-gain",
                          "requirements": "The Azure-SFT model achieves an improvement of ~2.43% over the baseline model on GSM8K.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-truthfulqa-gain",
                          "requirements": "The Azure-SFT model achieves an improvement of ~6.10% over the baseline model on ScienceQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "sft-scienceqa-gain",
                          "requirements": "The Azure-SFT model achieves an improvement of ~18.00% over the baseline model on TruthfulQA.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adapter-improvements",
                      "requirements": "The BBox-Adapter improvements match those reported in Table 2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "gt-improvements",
                          "requirements": "The Ground-Truth adapter improvements match those reported in Table 2.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "gt-strategyqa-gain",
                              "requirements": "The Ground-Truth adapter achieves an improvement of ~5.03% on StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "gt-gsm8k-gain",
                              "requirements": "The Ground-Truth adapter achieves an improvement of ~6.35% on GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "gt-truthfulqa-gain",
                              "requirements": "The Ground-Truth adapter achieves an improvement of ~2.70% on TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "gt-scienceqa-gain",
                              "requirements": "The Ground-Truth adapter achieves an improvement of ~5.63% on ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-ai-feedback-trends",
                          "requirements": "The performance improvements for AI feedback match those reported in Table 2.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ai-feedback-strategyqa-trend",
                              "requirements": "The AI feedback adapter achieves an improvement of ~3.26% on StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ai-feedback-gsm8k-trend",
                              "requirements": "The AI feedback adapter achieves an improvement of ~5.99% on GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ai-feedback-scienceqa-trend",
                              "requirements": "The AI feedback adapter achieves an improvement of ~5.40% on ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ai-feedback-truthfulqa-trend",
                              "requirements": "The AI feedback adapter achieves an improvement of ~5.10% on TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-combined-trends",
                          "requirements": "The performance improvements for combined feedback match those reported in Table 2.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "combined-strategyqa-trend",
                              "requirements": "The Combined adapter achieves an improvement of ~5.68% on StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "combined-gsm8k-trend",
                              "requirements": "The Combined adapter achieves an improvement of ~6.77% on GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "combined-scienceqa-trend",
                              "requirements": "The Combined adapter achieves an improvement of ~6.50% on ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "combined-truthfulqa-trend",
                              "requirements": "The Combined adapter achieves an improvement of ~6.60% on TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "plug-and-play",
              "requirements": "Table 3 has been reproduced.",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "davinci-adaptation",
                  "requirements": "The adapter trained on GPT-3.5 Turbo has been evaluated on davinci-002 without retraining.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "davinci-setup",
                      "requirements": "The davinci-002 model has been set up with the OpenAI API for text generation with the following capabilities: (1) prompt-based text generation, (2) adjustable sampling temperature, and (3) control over maximum output length",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "davinci-api-setup",
                          "requirements": "API access has been configured to enable text generation using davinci-002",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Environment & Infrastructure Setup"
                        },
                        {
                          "id": "davinci-generation-params",
                          "requirements": "The model is configured with temperature 1.0 and a maximum length of 512 tokens for generation as specified in Appendix H.2",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "davinci-evaluation",
                      "requirements": "The evaluation of davinci-002 and adapted davinci-002 match those reported in Table 3.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "davinci-performance-calculation",
                          "requirements": "The accuracy metrics for base and adapted davinci-002 have been calculated for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "base-davinci-metrics",
                              "requirements": "The performance metrics for base davinci-002 have been calculated.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "base-davinci-strategyqa",
                                  "requirements": "The accuracy of base davinci-002 on StrategyQA has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "base-davinci-gsm8k",
                                  "requirements": "The accuracy of base davinci-002 on GSM8K has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "base-davinci-truthfulqa",
                                  "requirements": "The True+Info metric of base davinci-002 on TruthfulQA has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "adapted-davinci-metrics",
                              "requirements": "The performance metrics for adapted davinci-002 have been calculated.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "adapted-davinci-strategyqa",
                                  "requirements": "The accuracy of adapted davinci-002 on StrategyQA has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "adapted-davinci-gsm8k",
                                  "requirements": "The accuracy of adapted davinci-002 on GSM8K has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "adapted-davinci-truthfulqa",
                                  "requirements": "The True+Info metric of adapted davinci-002 on TruthfulQA has been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "davinci-performance-trends",
                          "requirements": "The performance improvements of adapted davinci-002 over base davinci-002 match those reported in Table 3.",
                          "weight": 4,
                          "sub_tasks": [
                            {
                              "id": "davinci-strategyqa-trend",
                              "requirements": "The adapted davinci-002 achieves an improvement of ~15.42% on StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "davinci-gsm8k-trend",
                              "requirements": "The adapted davinci-002 achieves an improvement of ~0.12% on GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "davinci-truthfulqa-trend",
                              "requirements": "The adapted davinci-002 achieves an improvement of ~5.00% on TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "davinci-average-trend",
                              "requirements": "The adapted davinci-002 achieves an average improvement of ~6.85% across all datasets.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "mixtral-adaptation",
                  "requirements": "The adapter trained on GPT-3.5 Turbo has been evaluated on Mixtral-8x7B without retraining.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "mixtral-baseline",
                      "requirements": "The baseline evaluation of Mixtral-8x7B has been conducted.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "baseline-inference-mixtral",
                          "requirements": "Mixtral-8x7B has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "baseline-metrics",
                          "requirements": "The baseline performance metrics have been calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adapter-evaluation-exp",
                      "requirements": "The plug-and-play evaluation using the GPT-3.5 Turbo trained adapter has been conducted on Mixtral-8x7B.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "adapted-inference-mixtral",
                          "requirements": "The inference with the adapted Mixtral-8x7B has been executed.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "performance-comparison-mix",
                          "requirements": "The performance comparison between base and adapted Mixtral-8x7B match those reported in Table 3.",
                          "weight": 4,
                          "sub_tasks": [
                            {
                              "id": "performance-calculation-mix",
                              "requirements": "Performance metrics have been calculated for both the base and adapted versions of Mixtral-8x7B for each dataset.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "base-mixtral-metrics",
                                  "requirements": "Performance metrics for the base Mixtral-8x7B model have been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "base-mixtral-strategyqa",
                                      "requirements": "The accuracy of base Mixtral-8x7B on StrategyQA has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "base-mixtral-gsm8k",
                                      "requirements": "The accuracy of base Mixtral-8x7B on GSM8K has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "base-mixtral-truthfulqa",
                                      "requirements": "The True+Info metric of base Mixtral-8x7B on TruthfulQA has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "adapted-mixtral-metrics",
                                  "requirements": "Performance metrics for the adapted Mixtral-8x7B model have been calculated.",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "adapted-mixtral-strategyqa",
                                      "requirements": "The accuracy of adapted Mixtral-8x7B on StrategyQA has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "adapted-mixtral-gsm8k",
                                      "requirements": "The accuracy of adapted Mixtral-8x7B on GSM8K has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "adapted-mixtral-truthfulqa",
                                      "requirements": "The True+Info metric of adapted Mixtral-8x7B on TruthfulQA has been calculated.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "performance-trends-mix",
                              "requirements": "The performance improvements over base Mixtral-8x7B match those reported in Table 3.",
                              "weight": 4,
                              "sub_tasks": [
                                {
                                  "id": "mixtral-strategyqa-trend",
                                  "requirements": "The adapted Mixtral-8x7B achieves an improvement of ~4.06% on StrategyQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Result Analysis",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "mixtral-gsm8k-trend",
                                  "requirements": "The adapted Mixtral-8x7B achieves an improvement of ~0.15% on GSM8K.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Result Analysis",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "mixtral-truthfulqa-trend",
                                  "requirements": "The adapted Mixtral-8x7B achieves an improvement of ~9.30% on TruthfulQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Result Analysis",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "mixtral-average-trend",
                                  "requirements": "The adapted Mixtral-8x7B achieves an average improvement of ~4.50% across all datasets.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Result Analysis",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "scaling-analysis",
              "requirements": "Figure 3 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "beam-size-analysis",
                  "requirements": "Figure 3(a) has been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "beam-experiments",
                      "requirements": "The experiments with different beam sizes have been conducted.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "beam-configurations",
                          "requirements": "The adapter has been configured to run with beam sizes $k$ = 1, 3, and 5.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "beam-inference",
                          "requirements": "The inference has been executed for each beam size configuration.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "beam-analysis",
                      "requirements": "The results evaluating the impact of beam size match those reported in Figure 3(a).",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "performance-tracking-beam",
                          "requirements": "The performance changes across beam sizes ($k$ = 1, 3, 5) have been tracked and calculated.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "beam-size-trends",
                          "requirements": "The results show that increasing the number of beams contributes to an average performance enhancement of ~2.41% across different adapter sizes (0.1B and 0.3B).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "iteration-analysis",
                  "requirements": "Figure 3(b) has been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "iteration-experiments",
                      "requirements": "The experiments evaluating the impact of different iteration counts have been implemented and run.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "iteration-configurations",
                          "requirements": "The online adaptation has been configured to run with $T$ = 0, 1, 2, 3, and 4 iterations.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "iteration-training",
                          "requirements": "The training and inference has been executed for each iteration configuration.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "performance-tracking-129838129",
                          "requirements": "Code has been written to compute and save the performance changes across iteration counts.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "performance-tracking",
                          "requirements": "The performance changes across iteration counts have been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "iteration-results",
                      "requirements": "The results evaluating the impact of iteration count match those reported in Figure 3(b).",
                      "weight": 4,
                      "sub_tasks": [
                        {
                          "id": "initial-performance-trend",
                          "requirements": "The results show that the un-finetuned adapter ($T=0$) performs worse than the base model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "adaptation-improvement-trend",
                          "requirements": "The results show that the adapted LLM surpasses the performance of the base model after one round of adaptation.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "subsequent-iterations-trend",
                          "requirements": "The results show that consistent improvements are observed with iterations up to $T=3$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "cost-evaluation",
              "requirements": "Table 4 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "training-cost",
                  "requirements": "The training cost comparison between BBOX-ADAPTER and baselines has been reproduced.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "azure-sft-cost",
                      "requirements": "The Azure OpenAI service costs have been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "azure-sft-training-costs",
                          "requirements": "The training costs ($) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "azure-sft-strategyqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-gsm8k-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-truthfulqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-scienceqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "azure-sft-inference-costs",
                          "requirements": "The inference costs ($/1k questions) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "azure-sft-strategyqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-gsm8k-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-truthfulqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-scienceqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "azure-sft-eval-costs",
                          "requirements": "The evaluation costs ($) for computing accuracy have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "azure-sft-strategyqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-gsm8k-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-truthfulqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing True+Info scores for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "azure-sft-scienceqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adapter-training-cost",
                      "requirements": "The GPT-3.5 Turbo API costs have been computed and saved during adapter training.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "adapter-training-costs",
                          "requirements": "The training costs ($) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "adapter-strategyqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            },
                            {
                              "id": "adapter-gsm8k-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            },
                            {
                              "id": "adapter-truthfulqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            },
                            {
                              "id": "adapter-scienceqa-cost",
                              "requirements": "Code has been written to compute and save the training cost ($) for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-inference-costs",
                          "requirements": "The inference costs ($/1k questions) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "adapter-strategyqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-gsm8k-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-truthfulqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-scienceqa-inf-cost",
                              "requirements": "Code has been written to compute and save the inference cost ($/1k questions) for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "adapter-eval-costs",
                          "requirements": "The evaluation costs ($) for computing accuracy have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "adapter-strategyqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for StrategyQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-gsm8k-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for GSM8K.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-truthfulqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing True+Info scores for TruthfulQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "adapter-scienceqa-eval-cost",
                              "requirements": "Code has been written to compute and save the cost ($) of computing accuracy for ScienceQA.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "inference-cost",
                  "requirements": "The inference cost comparison for both single-step and full-step variants has been reproduced.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "single-step-evaluation",
                      "requirements": "The single-step variant costs have been evaluated.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "single-step-inference-costs",
                          "requirements": "The inference costs ($/1k questions) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "single-step-strategyqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for StrategyQA have been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-strategyqa-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during single-step StrategyQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-strategyqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-gsm8k-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for GSM8K have been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-gsm8k-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during single-step GSM8K inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-gsm8k-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-truthfulqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for TruthfulQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-truthfulqa-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during single-step TruthfulQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-truthfulqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-scienceqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for ScienceQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-scienceqa-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during single-step ScienceQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-scienceqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "single-step-eval-costs",
                          "requirements": "The evaluation costs ($) for computing accuracy have been tracked for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "single-step-strategyqa-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for StrategyQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-strategyqa-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during accuracy computation for StrategyQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-strategyqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-gsm8k-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for GSM8K has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-gsm8k-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during accuracy computation for GSM8K.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-gsm8k-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-truthfulqa-eval-cost",
                              "requirements": "The cost ($) of computing True+Info scores for TruthfulQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-truthfulqa-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during True+Info computation for TruthfulQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-truthfulqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "single-step-scienceqa-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for ScienceQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "single-step-scienceqa-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during accuracy computation for ScienceQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "single-step-scienceqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "full-step-evaluation",
                      "requirements": "The full-step variant costs have been evaluated.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "full-step-inference-costs",
                          "requirements": "The inference costs ($/1k questions) have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "full-step-strategyqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for StrategyQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-strategyqa-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during full-step StrategyQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "full-step-strategyqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-gsm8k-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for GSM8K has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-gsm8k-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during full-step GSM8K inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "full-step-gsm8k-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-truthfulqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for TruthfulQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-truthfulqa-inf-tracking",
                                  "requirements": "Code has been written to track and log the API costs during full-step TruthfulQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "full-step-truthfulqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-scienceqa-inf-cost",
                              "requirements": "The inference cost ($/1k questions) for ScienceQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-scienceqa-inf-tracking",
                                  "requirements": "Code has been written to compute and save the API costs during full-step ScienceQA inference.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "full-step-scienceqa-inf-calculation",
                                  "requirements": "Code has been written to calculate the cost per 1000 questions from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "full-step-eval-costs",
                          "requirements": "The evaluation costs ($) for computing accuracy have been computed and saved for each dataset.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "full-step-strategyqa-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for StrategyQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-strategyqa-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during accuracy computation for StrategyQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "full-step-strategyqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-gsm8k-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for GSM8K has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-gsm8k-eval-tracking",
                                  "requirements": "Code has been written to track and log API costs during accuracy computation for GSM8K.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                },
                                {
                                  "id": "full-step-gsm8k-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-truthfulqa-eval-cost",
                              "requirements": "The cost ($) of computing performance metrics for TruthfulQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-truthfulqa-eval-tracking",
                                  "requirements": "Code has been written to compute and save API costs during metric computation for TruthfulQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "full-step-truthfulqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "full-step-scienceqa-eval-cost",
                              "requirements": "The cost ($) of computing accuracy for ScienceQA has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "full-step-scienceqa-eval-tracking",
                                  "requirements": "Code has been written to compute and save API costs during accuracy computation for ScienceQA.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "full-step-scienceqa-eval-calculation",
                                  "requirements": "Code has been written to calculate the total evaluation cost from the logged API usage.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Logging, Analysis & Presentation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "training-cost-trends",
                  "requirements": "The cost efficiency trends match those presented in Table 4.",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "training-reduction-trend",
                      "requirements": "The results show that BBOX-ADAPTER reduces training costs by ~31.30x compared to Azure-SFT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "inference-reduction-trend",
                      "requirements": "The results show that BBOX-ADAPTER reduces inference costs by ~1.84x compared to Azure-SFT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "single-step-trend-4",
                      "requirements": "The results show that the single-step variant reduces inference costs by ~6.27x compared to Azure-SFT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "training-efficiency-trend",
                      "requirements": "The results show that BBOX-ADAPTER achieves these cost reductions while maintaining competitive performance (within ~4% of Azure-SFT).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "full-step-trend",
                      "requirements": "The results show that the full-step variant reduces inference costs by ~1.84x compared to Azure-SFT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "single-step-trend",
                      "requirements": "The results show that the single-step variant reduces inference costs by ~6.27x compared to Azure-SFT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "performance-tradeoff-trend",
                      "requirements": "The results show that the single-step variant achieves ~3.45% improvement over the base model despite lower cost, compared to the full-step's ~5.90% improvement.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "ablation-studies",
              "requirements": "Table 5 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "mlm-implementation",
                  "requirements": "The MLM baseline has been implemented.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "mlm-training",
                      "requirements": "The training pipeline using masked word supervision has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "mlm-inference",
                      "requirements": "The inference process using masked word probability scoring has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "loss-comparison-eval",
                  "requirements": "The results match those presented in Table 5.",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "size-performance-calculation",
                      "requirements": "The accuracy metrics for both 0.1B and 0.3B adapters have been calculated.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "mlm-size-trend",
                      "requirements": "The results show that the MLM-based adapter achieves 61.52% (0.1B) and 60.41% (0.3B) accuracy on StrategyQA.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "nce-size-trend",
                      "requirements": "The results show that the NCE-based adapter achieves 71.62% (0.1B) and 71.18% (0.3B) accuracy on StrategyQA, showing consistent improvement of ~10% over MLM regardless of adapter size.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "white-box-extension",
              "requirements": "Table 6 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "white-box-performance",
                  "requirements": "Mixtral-8x7B, Mixtral-8x7B + LoRA and Mixtral-8x7B + BBox-Adapter have been evaluated on the StrategyQA test set, with the accuracy and VRAM recorded.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "db39284a-0937-4175-a5b0-f69eb677c2c6",
                      "requirements": "Mixtral-8x7B has been loaded in half-precision.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "mixtral-baseline-plug",
                      "requirements": "Mixtral-8x7B has been evaluated on the StrategyQA test set with its accuracy and VRAM computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "baseline-inference-plug",
                          "requirements": "Mixtral-8x7B on 0.1B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "748c5996-02da-4ef5-a9e2-09aa848218f0",
                          "requirements": "Mixtral-8x7B on 0.3B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "baseline-metrics-plug",
                          "requirements": "Mixtral-8x7B has been evaluated on the StrategyQA test set, with the VRAM computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "adapter-evaluation-wb",
                      "requirements": "Mixtral-8x7B + LoRA has been evaluated on the StrategyQA test set with its accuracy and VRAM computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "adapted-inference-wb",
                          "requirements": "Mixtral-8x7B with LoRA adaptation on 0.1B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e2171d3f-ab95-4daf-9f47-2439503f7ed0",
                          "requirements": "Mixtral-8x7B with LoRA adaptation on 0.3B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "performance-comparison-whitebox",
                          "requirements": "Mixtral-8x7B with LoRA adaptation on 0.1B parameters has been evaluated on the StrategyQA test set, with the VRAM computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "505cbfd8-8eeb-4b6b-8290-0956efeeebdf",
                      "requirements": "Mixtral-8x7B + BBox-Adapter has been evaluated on the StrategyQA test set with its accuracy and VRAM computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "21c168ee-c5a1-4b10-be7a-bdd84f9be988",
                          "requirements": "Mixtral-8x7B with BBox-Adapter adaptation on 0.1B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "eaefd25e-575f-4c06-a2b1-6f61f4496e25",
                          "requirements": "Mixtral-8x7B with BBox-Adapter adaptation on 0.3B parameters has been evaluated on the StrategyQA test set, with the accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b2407631-327e-4e5d-9a6d-579cb1ddad2e",
                          "requirements": "Mixtral-8x7B with BBox-Adapter adaptation has been evaluated on the StrategyQA test set using the 0.1B parameter model, with the VRAM computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "vram-measurement",
                  "requirements": "The results match those presented in Table 6.",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "base-memory",
                      "requirements": "Mixtral-8x7B achieves an accuracy of 59.91% on the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "adapter-memory",
                      "requirements": "Mixtral-8x7B takes up 90GB of VRAM during inference-time the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "lora-memory",
                      "requirements": "Mixtral-8x7B + LoRA on 0.1B parameters achieves an accuracy of 73.80% on the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4ab94afb-e410-4732-9b88-96815e66e4eb",
                      "requirements": "Mixtral-8x7B + LoRA on 0.3B parameters achieves an accuracy of 73.80% on the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7c3f6fb5-590f-4e65-afcb-8e15c590287f",
                      "requirements": "Mixtral-8x7B + LoRA takes up 208GB of VRAM during train-time the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "2eca0f28-5595-4957-857b-98208d886c3c",
                      "requirements": "Mixtral-8x7B + LoRA takes up 92GB of VRAM during inference-time the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "100a78df-af5a-410c-a8c1-6eea2331c3ee",
                      "requirements": "Mixtral-8x7B + Bbox-Adapter achieves an accuracy of 66.08% on the StrategyQA test set with the 0.1B parameter setting.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "504b46df-0b53-4f37-aa64-556b9cf108df",
                      "requirements": "Mixtral-8x7B + Bbox-Adapter achieves an accuracy of 65.26% on the StrategyQA test set with the 0.3B parameter setting.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2067127d-80e8-4b1c-93a6-54aa352e7607",
                      "requirements": "Mixtral-8x7B + Bbox-Adapter takes up 105GB of VRAM during train-time the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "52c38b9d-ce30-4d86-b7dc-90f31cf3ebb8",
                      "requirements": "Mixtral-8x7B + Bbox-Adapter takes up 92GB of VRAM during inference-time the StrategyQA test set.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "bridging-data-gaps",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "0d99d4ba-1b8e-4975-a285-6bea71c68933",
          "requirements": "The paper \"Bridging Data Gaps in Diffusion Models with Adversarial Noise-Based Transfer Learning\" has been reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "3c39fa89-b732-4b61-95ef-60f31e5865ab",
              "requirements": "Algorithm 1 for training DPMs with Adversarial Noise-based Transfer has been implemented.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "5d7eb9db-5d5a-47d0-a5ee-991ab9327106",
                  "requirements": "Code has been written to train a binary classifier to predict whether an input $x_t$ originates from the source domain or target domain.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "5d7eb9db-5d5a-47d0-a5ee-991ab9327103894398",
                  "requirements": "A binary classifier has been trained to predict whether an input $x_t$ originates from the source domain or target domain.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "44e8d794-412f-4b59-931d-c4076a73231a",
                  "requirements": "The adaptor module from Noguchi & Harada, 2019 has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "5acc0f6c-9b8a-496d-beb1-5ca89a44f5a353533",
                  "requirements": "Code has been written to select training samples from the target dataset, a time-step selected randomly, and standard Gaussian noise for each sample.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Data Processing & Preparation"
                },
                {
                  "id": "5acc0f6c-9b8a-496d-beb1-5ca89a44f5a3",
                  "requirements": "Training samples are drawn from the target dataset, each paired with a randomly selected timestep and standard Gaussian noise.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "1209cc8c-40e9-46c9-9b00-ae2a0c133f34343ffb",
                  "requirements": "Code has been written to compute the adaptive inner maximum as defined in Equation 7.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "1209cc8c-40e9-46c9-9b00-ae2a0c133ffb",
                  "requirements": "The adaptive inner maximum has been computed as defined in Equation 7.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "492163d6-6e41-46e9-a9b6-1ef49061d81d",
                  "requirements": "Code has been written to compute the similarity guided loss as defined in Equation 5.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "492163d6-6e41-46e9-a9b6-1ef49061d84234f1d",
                  "requirements": "The similarity guided loss has been computed as defined in Equation 5.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "34cb106d-4b83-4bbd-a1fd-29cba4c26f3gw3rw3d94",
                  "requirements": "Code has been written to update the adaptor module parameters via gradient descent with similarity-guided loss and adversarial noise as the objective. The objective function is defined in Equation 8.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "34cb106d-4b83-4bbd-a1fd-29cba4c26d94",
                  "requirements": "The adaptor module parameters are updated via gradient descent with similarity-guided loss and adversarial noise as the objective. The objective function is defined in Equation 8.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "fba2b11d-cf4f-47a0-bcd8-456d9f571a00",
              "requirements": "The experimental setup has been implemented, as described in Section 5.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "c9f4168b-fe05-4a76-981b-6e7fc9ad8028",
                  "requirements": "The experimental setup to evaluate the DDPM and LDM models has been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3b484d81-4352-4eea-a568-da927824c92f33ee9",
                      "requirements": "Code has been written to fine-tune a pre-trained LDM in the shift module of the U-net. The pre-trained DPM and autoencoders in LDM are kept fixed.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "3b484d81-4352-4eea-a568-da927824c9e9",
                      "requirements": "A pre-trained LDM has been fine-tuned in the shift module of the U-net. The pre-trained DPM and autoencoders in LDM are kept fixed.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "3282140d-e00b-45a1-9e14-cb2638632423494fa8",
                      "requirements": "Code has been written to initialize the parameters of the adapter layer to zero.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "3282140d-e00b-45a1-9e14-cb2638694fa8",
                      "requirements": "The parameters of the adapter layer are initialized to zero.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b41c12f5-f27e-433a-bbd3-66b1c343fwf3eedc097",
                      "requirements": "Code has been written to set the hyper-parameter gamma for similarity-guided training to 5.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "b41c12f5-f27e-433a-bbd3-66b1ceedc097",
                      "requirements": "The hyper-parameter gamma for similarity-guided training is set to 5.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "44de168e-4f56-4c7d-800f-16dda3432r3c66a289",
                      "requirements": "Code has been written to fine-tune a pre-trained model on ImageNet with a binary classifier head on 10 target domain images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "44de168e-4f56-4c7d-800f-16ddac66a289",
                      "requirements": "A pre-trained model on ImageNet is fine-tuned with a binary classifier head on 10 target domain images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "00c640f9-2865-4d4d-ab62-d381e5763423415b3",
                      "requirements": "Code has been written to set the hyperparameters $J$ and $\\omega$ to 10 and 0.02, respectively, for adversarial noise selection.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "00c640f9-2865-4d4d-ab62-d381e57615b3",
                      "requirements": "The hyperparameters $J$ and $\\omega$ are set to 10 and 0.02, respectively, for adversarial noise selection.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "d96e73af-6bc0-405d-bebf-0730dca61911",
                      "requirements": "The learning rate is set to 0.00005 for DDPM and 0.00001 for LDM. Both models are trained for 300 iterations and a batch size of 40.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "d96e73af-6bc0-405d-bebf-0730dca61911",
                      "requirements": "The learning rate is set to 0.00005 for DDPM and 0.00001 for LDM. Both models are trained for 300 iterations and a batch size of 40.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ee09fd31-4bd7-4c61-b9d4-4a459fe88dba",
                  "requirements": "The evaluation metrics have been implemented.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "af4e04f1-0820-4756-9504-c556a449d799",
                      "requirements": "The Intra-LPIPS metric has been implemented.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bb0a98fa-568e-452e-a51f-9a027223223314251a",
                          "requirements": "Code has been written to generate 1,000 images from the models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "bb0a98fa-568e-452e-a51f-9a027214251a",
                          "requirements": "1,000 images have been generated from the models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "57dc269b-20f0-445f-831f-8463079f3423r23be26",
                          "requirements": "Code has been written to assign each image to the training sample with the smallest LPIPS distance.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "57dc269b-20f0-445f-831f-8463079fbe26",
                          "requirements": "Each image has been assigned to the training sample with the smallest LPIPS distance.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2a3fc09c-ad26-4374-8892-28173fc8d669",
                          "requirements": "The average pair-wise distance within each cluster has computed. The average score from each cluster has been calculated as Intra-LPIPS metric.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2a3fc09c-ad26-4374-8892-28173fc8d669",
                          "requirements": "The average pair-wise distance within each cluster has computed. The average score from each cluster has been calculated as Intra-LPIPS metric.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9dc4e2e6-838a-4348-892a-a9592ceb55a1",
                      "requirements": "The FID metric has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "3391773b-c60b-4ee0-a727-c7761a68f1e8",
                  "requirements": "The target datasets have been selected for their corresponding source datasets.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cfa8eaba-9c8d-4cc4-8797-ea27404322131f3de8c3",
                      "requirements": "Code has been written to load Babies, Sunglasses, Raphael Peale, Sketches, and face paintings from the dataset FFHQ.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "cfa8eaba-9c8d-4cc4-8797-ea27404328c3",
                      "requirements": "Babies, Sunglasses, Raphael Peale, Sketches, and face paintings have been loaded from the dataset FFHQ.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "a40709b6-f522-45cb-b9c4-f05ef341b7f4",
                      "requirements": "Haunted Houses and Landscape drawings have been loaded from the LSUN dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "a40709b6-f522-45cb-b9c4-f05ef341b7f4",
                      "requirements": "Haunted Houses and Landscape drawings have been loaded from the LSUN dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c350894a-3d86-411d-b3d2-0bba4c5036b4",
                  "requirements": "The baseline models used in Table 1 have been implemented by adapting pre-existing implementations from the StyleGAN2 codebase.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "d20894c8-1e25-458f-96fe-db2ce2bd22a9",
                      "requirements": "TGAN has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1a32ffae-af23-465e-bc16-c0f0cd828ffd",
                      "requirements": "TGAN+ADA has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "afc80729-a8ca-4cce-aa43-2c1779cdabc8",
                      "requirements": "EWC has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d13c3a0b-1304-4e28-b3c4-ba9fb6eaf30a",
                      "requirements": "CDC has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1eb7c592-f303-4de0-ac80-73d11b55f6b3",
                      "requirements": "DCL has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "ca04bf90-d5cb-4703-86fa-c01372398751",
                      "requirements": "DDPM-PA has been implemented by adapting the StyleGAN2 codebase.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "2611ab60-d9d9-4f22-8cd3-ecb8af89c47f",
              "requirements": "Figure 2 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "1d502a68-3fb3-4bce-953a-764cd09d7ea6",
                  "requirements": "Code has been written to train a diffusion model to generate data from a 2-dimensional Gaussian distribution with mean [1, 1] and unit variance.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "1d502a68-3fb3-4bce-953a-764cd09d2443r7ea6",
                  "requirements": "A diffusion model has been trained to generate data from a 2-dimensional Gaussian distribution with mean [1, 1] and unit variance.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "f3935ee2-c8e0-401e-9b75-dc7260e5fc8d",
                  "requirements": "Code has been written to transfer the trained model to generate samples from a 2-dimensional Gaussian distribution with a mean of [-1, -1] and unit variance using three methods: DDPM, DDPM-ANT w/o AN, and DDPM-ANT.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "f3935ee2-c8e0-401e-9b75-dc7260e53f3afw3fc8d",
                  "requirements": "The trained model has been transferred to generate samples from a 2-dimensional Gaussian distribution with a mean of [-1, -1] and unit variance using three methods: DDPM, DDPM-ANT w/o AN, and DDPM-ANT.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "f614fbdc-1d89-4e3e-8edd-f1e18a8ce7fd",
                  "requirements": "Figure 2a has been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "7820ea5b-97be-4f81-ac79-3c971132342344423c",
                      "requirements": "Code has been written to calculate the gradient direction used as reference using 10,000 samples.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7820ea5b-97be-4f81-ac79-3c971134423c",
                      "requirements": "The gradient direction used as reference has been calculated using 10,000 samples.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cdfa5f7a-6d39-4228-959b-aecfe10243r31a0af",
                      "requirements": "Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "cdfa5f7a-6d39-4228-959b-aecfe101a0af",
                      "requirements": "The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "bd36332e-aed0-4d65-bf04-9d1432g3rw313ba4fee",
                      "requirements": "Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM fine-tuned using similarity-guided training only (DDPM-ANT w/o AN).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "bd36332e-aed0-4d65-bf04-9d1413ba4fee",
                      "requirements": "The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM fine-tuned using similarity-guided training only (DDPM-ANT w/o AN).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "eed7cd00-1ddd-4986-b5e6-76daff843423e2f3we848",
                      "requirements": "Code has been written to calculate the gradient of the output layer during the first iteration with 10-shot samples for DDPM fine-tuned using similarity-guided training and adversarial noise selection (DDPM-ANT as defined by Equation 8).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "eed7cd00-1ddd-4986-b5e6-76daff84e848",
                      "requirements": "The gradient of the output layer during the first iteration has been calculated with 10-shot samples for DDPM fine-tuned using similarity-guided training and adversarial noise selection (DDPM-ANT as defined by Equation 8).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "f43671c8-7696-4cc2-97ff-85029f88aaa1",
                      "requirements": "The gradients computed for DDPM show the largest angular deviation from the reference gradient. Using DDPM without AN shows a decrease in the angular difference, and the closest angular difference between the direction of the gradient and the reference was achieved by the proposed method DDPM-ANT.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "f6c411d4-3929-479d-bc56-028b22ebfbb9",
                  "requirements": "Figure 2b and Figure 2c have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "20389b30-6a9c-4c52-bbe4-595e132423rfd47548",
                      "requirements": "Code has been written to generate 20,000 samples using the DDPM model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "20389b30-6a9c-4c52-bbe4-595e1fd47548",
                      "requirements": "The DDPM model has been used to generate 20,000 samples.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "733d5b92-0acb-418b-bf4a-9c5793d3423rf3b3c17",
                      "requirements": "Code has been written to generate 20,000 samples using the DDPM-ANT model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "733d5b92-0acb-418b-bf4a-9c5793db3c17",
                      "requirements": "The DDPM-ANT model has been used to generate 20,000 samples.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "5c62087a-20c0-469c-8cdf-6ec267a7b4c8",
                      "requirements": "The samples generated by DDPM-ANT has a larger concentration of samples around -1,  which is the mean of the target distribution, than DDPM.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "f9386f7f-3e73-4b2f-bb21-4493444129fe",
              "requirements": "Figure 3 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "0fcccad1-f881-4ca9-9d59-c1196bedc933",
                  "requirements": "The 10-shot image generation for adapting LSUN Church to Landscape drawings have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "acf3e6db-2136-4b89-953a-e8132fe3fd33fdb25b63",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the CDC model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "acf3e6db-2136-4b89-953a-e813fdb25b63",
                      "requirements": "The CDC model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "91e045b5-a545-4a1c-92cb-8f0da2363f33frb5ea",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DCL model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "91e045b5-a545-4a1c-92cb-8f0da236b5ea",
                      "requirements": "The DCL model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "b0e511b4-a831-4c28-99ba-cffdd3f3fd1a454c",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DDPM-PA model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b0e511b4-a831-4c28-99ba-cffddd1a454c",
                      "requirements": "The DDPM-PA model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "0b788d47-6e35-4a79-8ff6-8b01932e23f377548a6",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the DDPM-ANT model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "0b788d47-6e35-4a79-8ff6-8b01977548a6",
                      "requirements": "The DDPM-ANT model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "6cbd6a02-363b-46d2-b179-c7667f23f365546d3",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings using the LDM-ANT model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "6cbd6a02-363b-46d2-b179-c766765546d3",
                      "requirements": "The LDM-ANT model has been used to perform 10-shot image generation, adapting the LSUN Church dataset to Landscape drawings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "063c7847-11ea-4fb7-88f2-1c233d2016dd",
                      "requirements": "The images generated by DDPM-ANT and LDM-ANT show better results at capturing the style of landscapes and representing buildings from the source domain.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3395e370-2eb0-4b73-bf02-2ad5774db404",
                      "requirements": "The images generated by CDC and DCL capture the color scheme of the target domain, but fail to capture the structure of the source domain.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "45cabdee-165f-4305-8d56-6be77eb58633",
                      "requirements": "The images generated by DDPM-PA capture the structure of the source domain, but fail to capture the color scheme of the target domain.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "aaa9a965-d745-4414-b333-5bfa16742eac",
                  "requirements": "The 10-shot image generation for adapting FFHQ to Raphael's paintings has been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "74baef43-248d-4b62-a5c6-c27255342341eb607",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings using the CDC model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "74baef43-248d-4b62-a5c6-c272551eb607",
                      "requirements": "The CDC model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d2b6ae69-fd8b-4e58-9e98-c95feb72324234322838",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings using the DCL model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d2b6ae69-fd8b-4e58-9e98-c95feb722838",
                      "requirements": "The DCL model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "58a28f17-9837-4c7f-9bc5-eeec22342342b4376c",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings using the DDPM-PA model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "58a28f17-9837-4c7f-9bc5-eeec22b4376c",
                      "requirements": "The DDPM-PA model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "37ed1897-f4c6-4da9-9828-e0bb69324234f32d2c",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings using the DDPM-ANT model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "37ed1897-f4c6-4da9-9828-e0bb69f32d2c",
                      "requirements": "The DDPM-ANT model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "b6c81e95-82ca-4c9b-83fd-9a7223423490f5548",
                      "requirements": "Code has been written to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings using the LDM-ANT model.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b6c81e95-82ca-4c9b-83fd-9a72890f5548",
                      "requirements": "The LDM-ANT model has been used to perform 10-shot image generation, adapting the FFHQ dataset to Raphael's paintings.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "9cc039c6-a2ff-440c-bcaf-714436639a52",
                      "requirements": "The images generated by CDC and DCL capture the style of the target domain, but the generated images are blurry or distorted.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "a10da90c-5368-4b3a-bbbc-b18a642d5d33",
                      "requirements": "The images generated by DDPM-PA are clear, but fail to capture the style of the target domain.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1681b1fb-ef15-4ca4-bd40-5e8170526456",
                      "requirements": "The images generated by DDPM-ANT and LDM-ANT results at better capture the style of the target domain, while being less blurry or distorted than those generated by CDC and DCL.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "86a12a48-96af-4538-9ec8-cecb379563e7",
              "requirements": "Table 1 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "cc28d906-ad25-47c4-b632-be5a5bdcb990",
                  "requirements": "The results for TGAN have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "44633b1b-0847-41c7-95a1-0ba8910b90232328",
                      "requirements": "Code has been written to update all parameters of TGAN during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "44633b1b-0847-41c7-95a1-0ba8910b9028",
                      "requirements": "All parameters of TGAN were updated during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "7c37b754-9301-4e6e-be00-dfdc9d89a0cb",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using TGAN was approximately 0.510.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "974200ad-33dd-42e1-ab26-569de0a40c54",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using TGAN was approximately 0.550.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "95959820-8424-4b4a-85b2-ee257922bdc7",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using TGAN was approximately 0.533.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0dc44954-bc82-4c95-83c8-56a1b7b43598",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using TGAN was approximately 0.585.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1c6e4adc-f61f-49c5-a4d9-c53ca75583b4",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using TGAN was approximately 0.601.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bdc117df-2bce-4357-b457-63e4503d6f7b",
                  "requirements": "The results for TGAN+ADA have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "501bca60-25bc-4526-9fb2-78ba689cc32323230b",
                      "requirements": "Code has been written to update all parameters of TGAN+ADA during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "501bca60-25bc-4526-9fb2-78ba689cc30b",
                      "requirements": "All parameters of the model were updated during fine-tuning of TGAN+ADA.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "113d31aa-fbfc-4174-8439-9d85b1fa90e9",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using TGAN+ADA was approximately 0.546. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1e57b62f-bc4d-456d-b491-a94f9ebcc73e",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using TGAN+ADA was approximately 0.571.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ef4d66f8-9fa2-46d1-b71e-075eb285d065",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using TGAN+ADA was approximately 0.546. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "37027468-1b5e-4455-9dc5-70cd2a1c8c84",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using TGAN+ADA was approximately 0.615.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fc9676f4-d2b4-407c-bdef-1348b109f314",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using TGAN+ADA was approximately 0.643.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "e296ece5-7825-4e40-ad9e-6d427caa54d4",
                  "requirements": "The results for EWC have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "1c449e47-a797-4e95-a4df-62aae23232370f15e",
                      "requirements": "Code has been written to update all parameters of EWC during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1c449e47-a797-4e95-a4df-62aae370f15e",
                      "requirements": "All parameters of the model were updated during fine-tuning of EWC.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "74d173bc-f118-4c57-be85-701a9c4e05eb",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using EWC was approximately 0.560. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5e3bd49e-eb36-4eea-bc6e-068c6e24e1d5",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using EWC was approximately 0.550. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7c911ac9-dc1e-4211-91f3-020564e07e7d",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using EWC was approximately 0.541. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4816272b-2f0a-4374-8df1-293449e181b1",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using EWC was approximately 0.579.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7cbca5c0-df59-4820-823f-cbbe48014be3",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using EWC was approximately 0.596.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "dbad73c8-9113-4064-b09d-81c098b6edfa",
                  "requirements": "The results for CDC have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "16f0e37d-e2a2-4ec3-a1f6-612fd23234ea3f79",
                      "requirements": "Code has been written to update all parameters of CDC during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "16f0e37d-e2a2-4ec3-a1f6-612fd4ea3f79",
                      "requirements": "All parameters of the model were updated during fine-tuning of CDC.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "13db3b4c-ed4c-4aff-9743-67eee97e775e",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using CDC was approximately 0.583. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e03e5934-cb83-472a-b646-6ec4feb6f1db",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using CDC was approximately 0.581. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "43da110f-9808-4444-b81a-f7fdd4a711c5",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using CDC was approximately 0.564. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4740fcf9-1223-4e23-9b8e-9ca1661829fb",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using CDC was approximately 0.620.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "8ea8dd6d-d405-476d-9ff2-d335a989683c",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using CDC was approximately 0.674.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "97663c20-b7b8-45e3-af35-8b7a39c4655a",
                  "requirements": "The results for DCL have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "35d26ce2-eacb-4394-8c7a-7175323235e2a81a",
                      "requirements": "Code has been written to update all parameters of DCL during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "35d26ce2-eacb-4394-8c7a-717535e2a81a",
                      "requirements": "All parameters of the model were updated during fine-tuning of DCL.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "21f6d97f-c7d9-4d5b-be65-e5e581b5b6d0",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DCL was approximately 0.579. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a233e3c1-23c8-4d95-8a0a-03902681749e",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DCL was approximately 0.574. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5a9f9eef-cf7b-41e2-8d01-5bd6256591e2",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using DCL was approximately 0.558. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "38f5ef2e-5e05-4724-b269-25cb338d1ee2",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DCL was approximately 0.616.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "35aa5b56-360a-4271-89ab-40633432b755",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DCL was approximately 0.626.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a39ffdca-97f7-4f61-83b2-5880e35f9035",
                  "requirements": "The results for DDPM-PA have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3a1f7621-ed55-4604-95a0-296223238bc90b5d",
                      "requirements": "Code has been written to update all parameters of DDPM-PA during fine-tuning.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "3a1f7621-ed55-4604-95a0-29628bc90b5d",
                      "requirements": "All parameters of the models were updated during fine-tuning of DDPM-PA.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "8c79c1fc-c87a-41c5-8c76-285004ed0a6c",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DDPM-PA was approximately 0.599. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cc587c72-982b-40a4-82d9-2a299fd9066b",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DDPM-PA was approximately 0.604. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f59ada11-1f81-4826-9a88-f20938af4a40",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using DDPM-PA was approximately 0.581. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "048c8922-ce0e-4fe5-8189-dc607b6e2451",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DDPM-PA was approximately 0.628.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9e0be390-39ac-4e80-b293-90b429826e6a",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DDPM-PA was approximately 0.706.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "e896daa1-fcac-40a5-a891-25ded5a3b181",
                  "requirements": "The results for DDPM-ANT have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "6e0a78b8-9b91-4232-affd-fc2d89d7674f",
                      "requirements": "Only 1.3% of the total number of parameters of the model were updated during fine-tuning of DDPM-ANT.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "f9b1e756-e242-424e-b38e-c52bd3cd7b5f",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using DDPM-ANT was approximately 0.592. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5470d90d-21fc-409e-a43a-702545cedad0",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using DDPM-ANT was approximately 0.613. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bbe9da95-6d05-4ddf-ade6-3f7f5d5c6e14",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using DDPM-ANT was approximately 0.621. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "853e5c69-6216-4ae0-b637-1e6f1e73e6ea",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using DDPM-ANT was approximately 0.648.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f7e247be-433e-481f-bb45-b22069ec9c0b",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using DDPM-ANT was approximately 0.723.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "1191aad4-d944-42db-85e3-742e3e2bae46",
                  "requirements": "The results for LDM-ANT have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "70b18b4a-1a76-406f-aca5-525cef082ea1",
                      "requirements": "Only 1.6% of the total number of parameters of the model were updated during fine-tuning of LDM-ANT. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "73d5e78f-0e8b-4431-934e-7f7865b35e82",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Babies using LDM-ANT was approximately 0.601. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b12177bc-5005-4eb1-8792-143c69268552",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Sunglasses using LDM-ANT was approximately 0.613. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ca670619-1466-4420-a8e4-15e84374635d",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting FFHQ to Raphael's painting using LDM-ANT was approximately 0.592. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5d2ee275-4a50-4ce1-a73a-aa0f5974ac5c",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Haunted houses using LDM-ANT was approximately 0.653.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ff1c3ebc-0421-442a-9614-db0b26ddd321",
                      "requirements": "The Intra-LPIPS score for the 10-shot image generation adapting LSUN Church to Landscape drawings using LDM-ANT was approximately 0.738.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "d3e99eb3-74e7-4a6b-b1f1-c2518d9e4350",
              "requirements": "Table 2 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "123310ee-0a70-47f8-a3c9-4dd50413954b",
                  "requirements": "The results for TGAN have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "2ece9f53-37f0-48f9-913d-57a9d02378fc",
                      "requirements": "The FID score using TGAN for 10-shot transfer from FFHQ to Babies is approximately 104.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fca53380-dbf2-48a1-b5ef-9bf57f57d2d0",
                      "requirements": "The FID score using TGAN for 10-shot transfer from FFHQ to Sunglasses is approximately 55.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5c283f6d-665d-4306-b79a-208805857315",
                  "requirements": "The results for ADA have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "c86b8b7e-c1f7-4d54-ac82-2ff4da304ffa",
                      "requirements": "The FID score using ADA for 10-shot transfer from FFHQ to Babies is approximately 102.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9eafca2f-1ce5-4fec-b4b2-8f6eaea87ca9",
                      "requirements": "The FID score using ADA for 10-shot transfer from FFHQ to Sunglasses is approximately 53.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "fe75fe4a-1e75-47f7-9e89-d21def58259d",
                  "requirements": "The results for EWC have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3657fc20-0ced-49df-b18f-364a4259b242",
                      "requirements": "The FID score using EWC for 10-shot transfer from FFHQ to Babies is approximately 87.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "14bbc0cc-4d2e-4e04-a94b-655d70850df1",
                      "requirements": "The FID score using EWC for 10-shot transfer from FFHQ to Sunglasses is approximately 59.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "2ad54574-09c1-4378-955f-ab05470a12d3",
                  "requirements": "The results for CDC have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "12930c5e-7cb6-4aa3-bbf5-b0187ab11c68",
                      "requirements": "The FID score using CDC for 10-shot transfer from FFHQ to Babies is approximately 74.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "603c094c-d569-49fb-88e4-7c7cf13503da",
                      "requirements": "The FID score using CDC for 10-shot transfer from FFHQ to Sunglasses is approximately 42.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "f2690b96-a564-4518-95b4-426c1845991a",
                  "requirements": "The results for DCL have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "4748a6cf-742e-4c47-9d04-c2dcb291ffb4",
                      "requirements": "The FID score using DCL for 10-shot transfer from FFHQ to Babies is approximately 52.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "36e4df66-c40b-4a01-aeb6-44b1f24fcd65",
                      "requirements": "The FID score using DCL for 10-shot transfer from FFHQ to Sunglasses is approximately 38.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "e52dc9bc-019d-4108-b65d-a70a30ec12c2",
                  "requirements": "The results for DDPM-PA have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "abab77f5-03e8-47e5-a422-56535046ea63",
                      "requirements": "The FID score using DDPM-PA for 10-shot transfer from FFHQ to Babies is approximately 48.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2edc3515-975b-4c4e-ab06-e0681dcd20d0",
                      "requirements": "The FID score using DDPM-PA for 10-shot transfer from FFHQ to Sunglasses is approximately 34.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "af955177-de84-4f84-8a59-2a720009a8ac",
                  "requirements": "The results for ANT have been replicated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9e2006e9-5289-4e71-aea3-9e5ace4bb038",
                      "requirements": "The FID score using ANT for 10-shot transfer from FFHQ to Babies is approximately 46.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c1d68df9-77e2-499b-85ef-e450d524be38",
                      "requirements": "The FID score using ANT for 10-shot transfer from FFHQ to Sunglasses is approximately 20.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "6f29040f-e853-4b30-9c26-8e83b0f2615d",
              "requirements": "Figure 4 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "5c926d2d-c604-4d54-b620-f11cd5e232327f2c9",
                  "requirements": "Code has been written to fine-tune the DPM model on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "5c926d2d-c604-4d54-b620-f11cd5e7f2c9",
                  "requirements": "The DPM model was fine-tuned on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "66c2a90b-8f8a-483b-bd37-906bb3c34234239c2",
                  "requirements": "Code has been written to fine-tune the DPM model using an adaptor layer on a 10-shot sunglasses dataset for 300 iterations, updating only the adaptor layer.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "66c2a90b-8f8a-483b-bd37-906bb3c239c2",
                  "requirements": "The DPM model was fine-tuned using an adaptor layer on a 10-shot sunglasses dataset for 300 iterations, updating only the adaptor layer.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "5ae20584-256c-4b30-9a02-0b2342ae3242344187",
                  "requirements": "Code has been written to fine-tune the DPM model using only similarity guided training on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "5ae20584-256c-4b30-9a02-0b2342ae4187",
                  "requirements": "The DPM model was fine-tuned using only similarity guided training on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "bcccd310-9ffd-4ad2-9ba8-0433e1ff32422342343455cf",
                  "requirements": "Code has been written to fine-tune the DPM model using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "bcccd310-9ffd-4ad2-9ba8-0433e1ff32423455cf",
                  "requirements": "The DPM model was fine-tuned using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "bcccd310-9ffd-4ad2-9ba8-0433e1ff55cf",
                  "requirements": "Code has been written to fine-tune the DPM model using the proposed DPM-ANT strategy on a 10-shot sunglasses dataset for 300 iterations.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "3f10eb63-5b7f-4e4f-899c-b2292224130a",
                  "requirements": "DPM-ANT generated images show better quality and detail than the other ones.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "02e8e688-3b00-4b17-b837-7bc28f693988",
                  "requirements": "The adaptor results have the highest FID score, followed by the baseline results. DPM-ANT w/o AN achieve a lower FID score while the proposed DPM-ANT has the smallest FID score.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "dd4fd0a1-cc9e-43c1-9ed1-c7661ba76d51",
                  "requirements": "Both DPM-ANT w/o AN and the proposed DPM ANT successfully transfer sunglasses to all images. The baseline and adaptor methods both fail to transfer sunglasses to some of the images generated.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "b3f0b97c-f328-4604-b74d-fc12b9251ee4",
              "requirements": "Table 3 has been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "32c937a9-063e-42c7-83a9-c6981088dfae",
                  "requirements": "The results for the 10-shot classifier have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "97c453a4-1925-40fe-aec7-c94c010a2323e8d5",
                      "requirements": "Code has been written to use the DPM-ANT model to transfer FFHQ to Sunglasses, and train a classifier on 10 adapted images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "97c453a4-1925-40fe-aec7-c94c010ae8d5",
                      "requirements": "The DPM-ANT model was used to transfer FFHQ to Sunglasses, and a classifier was trained on 10 adapted images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "862eb8c7-c2b2-45cc-8d33-bba33edd9f04",
                      "requirements": "The intra-LPIPS score of the 10-shot classifier is approximately 0.613.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4a5afb97-a578-4fde-87a9-114a0c20bdaf",
                      "requirements": "The FID score of the 10-shot classifier is approximately 20.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c1699dfe-778a-45b4-b847-e31cedf48982",
                  "requirements": "The results for the 100-shot classifier have been replicated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "84319b5f-e28f-4d85-a5c0-b8f324234e834dfcf4",
                      "requirements": "Code has been written to use the DPM-ANT model to transfer FFHQ to Sunglasses, and train a classifier on 100 adapted images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "84319b5f-e28f-4d85-a5c0-b8fe834dfcf4",
                      "requirements": "The DPM-ANT model was used to transfer FFHQ to Sunglasses, and a classifier was trained on 100 adapted images.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b0ac5f91-386e-4c6d-8340-e4f052c98221",
                      "requirements": "The intra-LPIPS score of the 100-shot classifier is approximately 0.637.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c9f1f68f-3cfa-4090-a51b-3d0a4f998481",
                      "requirements": "The FID score of the 100-shot classifier is approximately 22.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "fre",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "3c22ea3d-0574-44ff-bd8a-3052e4e06376",
          "requirements": "The paper \"Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings\" has been reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "138c5838-d020-487e-b442-83c0d5fdebcb",
              "requirements": "The necessary agent datasets and environments have been setup",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "6f646981-abbf-4660-bc48-68eacb3afee0",
                  "requirements": "The AntMaze dataset and environment have been setup",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "595c44a3-25a3-4f38-80d1-d3376b12476e",
                      "requirements": "Code has been implemented such that the `antmaze-large-diverse-v2` dataset from D4RL can be used for offline training of sequential decision making agents",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "5b3ccceb-d946-4ce3-96f1-6cb9c3ef8030",
                      "requirements": "Code has been implemented such that the D4RL Ant Maze environment (https://github.com/Farama-Foundation/D4RL/blob/71a9549f2091accff93eeff68f1f3ab2c0e0a288/d4rl/locomotion/ant.py or equivalent) can be used for online evaluation of sequential decision making agents",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d5ca20a0-0365-40c6-89f7-09e049284b31",
                  "requirements": "The ExORL datasets and environments have been setup",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "48fa5a73-3814-49f1-910e-184aec339801",
                      "requirements": "The ExORL `cheetah` (RND) dataset and environment has been setup",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bccaf966-1315-49b8-9d49-df1b0f30d109",
                          "requirements": "Code has been implemented such that the `cheetah` (RND) dataset from ExORL (https://github.com/denisyarats/exorl)  can be used for offline training of sequential decision making agents",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "15a0dc98-8a9f-4173-a7a0-ba07770200f2",
                          "requirements": "Code has been implemented such that environments from the `cheetah` domain from the custom DeepMind Control Suite ExORL environments (https://github.com/denisyarats/exorl/tree/main/custom_dmc_tasks) can be used for online evaluation of sequential decision making agents",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "28a49106-74a0-4af1-ae55-24168c5de2c1",
                      "requirements": "The ExORL `walker` (RND) dataset and environment has been setup",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2b14e66b-18a7-45ad-9dc9-94dd728cb448",
                          "requirements": "Code has been implemented such that the `walker` (RND) dataset from ExORL (https://github.com/denisyarats/exorl) can be used for offline training of sequential decision making agents",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "534f0b86-f31e-4b6e-8bc3-50159bfdd0a3",
                          "requirements": "Code has been implemented such that environments from the `walker` domain from custom DeepMind Control Suite ExORL environments (https://github.com/denisyarats/exorl/tree/main/custom_dmc_tasks) can be used for online evaluation of sequential decision making agents",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "25c0642c-b1a8-44dc-a6e3-97c5686482b8",
                  "requirements": "The Kitchen dataset and environment have been setup",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "4eb72ad4-06cc-48ee-891f-a3851d850ea0",
                      "requirements": "Code has been implemented such that the \"kitchen-complete-v0\" dataset from D4RL can be used for offline training of sequential decision making agents",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "190df881-45b2-409f-a204-e924be3eab79",
                      "requirements": "Code has been implemented such that the D4RL Kitchen environment (https://github.com/Farama-Foundation/D4RL/tree/71a9549f2091accff93eeff68f1f3ab2c0e0a288/d4rl/kitchen or equivalent) can be used for online evaluation of sequential decision making agents",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "cfe3f829-a169-4f6b-8d38-2b2a2be00b95",
              "requirements": "The necessary methods have been implemented",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "eca2e125-7e22-415c-8678-d30176ffd536",
                  "requirements": "The FRE model architecture has been implemented",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "ea36bca4-ce04-4d7c-a287-b1083812ecbf",
                      "requirements": "The FRE implementation consists of an Encoder-Decoder network, and a FRE-conditioned IQL policy",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "2c4d8206-afb9-42ce-bab2-55a62c18011f",
                      "requirements": "The FRE Encoder-Decoder network has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "351577f4-a1d9-4c59-9193-1a2a9546df77",
                          "requirements": "The FRE Encoder network has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "04d679d0-0bca-4103-a118-76df6a2b2473",
                              "requirements": "The FRE Encoder network has been implemented such that the input scalar reward is discretized into 32 bins by rescaling the reward to [0,1] and then multiplying by 32 and flooring to the nearest integer",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7297f42f-cad1-4777-8f1a-f8162637eed6",
                              "requirements": "The FRE Encoder network has been implemented such that the discretized reward is is mapped to a continuous vector representation using a learned embedding table",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a9ad5a0c-8b63-4801-861e-50b22ee57859",
                              "requirements": "The FRE Encoder network has been implemented such that the the environment state projected into an embedding using a learned linear transformation",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "4afafbc9-4040-40dd-8d33-6506edc2678a",
                              "requirements": "The FRE Encoder network has been implemented such that for each state, the reward embedding is concatenated to end of the state embedding before the set of reward-labeled states is passed through the encoder",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "90b8884f-8bdd-4027-a927-790015380e3b",
                              "requirements": "The FRE Encoder has been implemented such that it takes a set of states labeled with their scalar rewards as input",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "e812f3c1-5afa-4b52-8e07-0f878cb43f9e",
                              "requirements": "The FRE Encoder has been implemented such that it uses a permutation invariant transformer as the main architecture.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "b57031ba-92a4-4b93-b32f-175b1cc678de",
                              "requirements": "The FRE Encoder has been implemented such that the transformer does not use a causal mask on its attention, such that each input token can attend to any other input token.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "17bdcdac-2c97-4f1e-b7a9-c50bd16d060e",
                              "requirements": "The FRE encoder has been implemented such that positional embeddings are not used in the transformer",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "aa264dc2-4e1b-4301-9dd6-770c0d5c3081",
                              "requirements": "The FRE encoder has been implemented using the hyper-parameters specified in Appendix A",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "bb5b5214-9e4b-46ce-9cf4-76a653944e66",
                          "requirements": "The FRE decoder network has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "0748e789-817a-4dbe-89e9-b98bc37689c4",
                              "requirements": "The FRE Decoder has been implemented such that it uses a feedforward neural network as the main architecture.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6a54735c-e526-48fb-bc87-4a3a116083f8",
                              "requirements": "The FRE Decoder has been implemented such that it independently predicts the reward for a single input state, given a shared latent encoding z",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6d38f122-a3dd-464b-8a85-37f2fd538364",
                              "requirements": "The FRE Decoder has been implemented using the hyper-parameters specified in Appendix A",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "656e1556-dbe4-47cb-9058-08d686339f0f",
                      "requirements": "The FRE-conditioned policy network has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "6b6edf6b-bb31-4655-a24f-156f6dd5be12",
                          "requirements": "The FRE-conditioned policy network has been implemented such that it includes an actor, critic, value, and target critic network",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "40d26271-b5b9-4c00-abe7-3f5fb4c231d4",
                          "requirements": "The FRE-conditioned policy network has been implemented such that the RL components are conditioned on some latent variable z produced by the FRE encoder",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "95ebb4b4-110a-421f-8ca4-185cacaaffd0",
                          "requirements": "The FRE-conditioned policy network has been implemented such that the actor predicts a Gaussian distribution over actions (mean and log std)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "143af012-ca25-4037-a318-f17f62e7e984",
                          "requirements": "The FRE-conditioned policy has been implemented using the hyper-parameters specified in Appendix A",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "f33afcc0-38bc-4af8-91ab-5c6d56c33e04",
                  "requirements": "The GC-IQL model architecture has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "4bbda5e1-08af-4448-be55-a74b27109b85",
                      "requirements": "The GC-IQL model has been implemented such that it includes an actor, critic, value, and target critic network",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d1495479-c0b0-44d3-b327-d3f2e380adc2",
                      "requirements": "The GC-IQL model has been implemented such that the actor predicts a Gaussian distribution over actions (mean and log std)",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "55e9351f-7627-4664-afac-e76327412716",
                      "requirements": "The GC-IQL model has been implemented such that it is goal-conditioned by concatenating the current observation with the desired goal before feeding into the networks",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "4062374f-1197-498e-99af-77f6d29fd236",
                  "requirements": "The GC-BC model architecture has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "83fd90f6-0652-485b-a977-a9bb84af9d0d",
                      "requirements": "The GC-BC model has been implemented such that it is a MLP with three hidden layers of size 512",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "620a2b18-8964-4c29-86e0-fad951820c68",
                      "requirements": "The GC-BC model has been implemented such that it predicts a gaussian distribution over actions, with two outputs, a mean action and the log of the standard deviation",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "714d7e4a-a799-460a-84f4-b78d6e065449",
                      "requirements": "The GC-BC model has been implemented such that the log of the standard deviation is clamped with a lower bound of -5",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d297b5ab-65b6-49f4-8f92-e9944afeb159",
                      "requirements": "The GC-BC model has been implemented such that ReLU is applied between each hidden layer",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "424bb63c-fc0a-4c1c-9014-03c90a967ddc",
                      "requirements": "The GC-BC model has been implemented such that layer normalization is applied before each activation function",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "73cbe8e5-de06-47a4-85b0-2371eb0db4bf",
                  "requirements": "The OPAL model architecture has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "b4c6e00e-7da1-43e5-8d56-18d3162980e0",
                      "requirements": "The OPAL method has been implemented such that it consists at minimum of an encoder $q_{\\phi}(z\\mid\\tau)$ and a latent-conditioned decoder (primitive policy) $\\pi_{\\theta}(a\\mid s,z)$",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "fde7acc8-1d2e-4bdf-b2aa-011ab26440ec",
                      "requirements": "The OPAL encoder architecture $q_{\\phi}(z\\mid\\tau)$ has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0389ff82-4e00-4553-9dd6-816d3f816df0",
                          "requirements": "The OPAL encoder has been implemented such that it reads a sub-trajectory of length $c$, consisting of $(s_{t}, a_{t})$ pairs, and produces parameters of a latent distribution (e.g. mean $\\mu_{z}$ and log-standard-deviation $\\sigma_{z}$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c41ecad0-c7ef-4af1-bb7a-7009167b2c54",
                          "requirements": "The OPAL encoder has been implemented such that it uses a permutation invariant transformer to process the $c$ timesteps and output the latent distribution parameters.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8f4e8195-602b-4832-a7ff-1467d72f1d20",
                          "requirements": "The OPAL encoder has been implemented such that it uses a permutation invariant transformer that does not use a causal mask on its attention, such that each input token can attend to any other input token.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ce744ae1-4b2d-4344-a9f5-3dfdd13e3740",
                          "requirements": "The OPAL encoder has been implemented such that it uses a permutation invariant transformer does not use positional embeddings",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "431ad005-008b-4745-aa6a-db4c70ff16f1",
                          "requirements": "The OPAL encoder has been implemented such that it uses a permutation invariant transformer set up with the relevant hyper-parameters specified in Appendix A",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "7b768bcc-eecd-4cfa-a226-4b9fd827ce2c",
                          "requirements": "The OPAL encoder has been implemented such that it represents $q_{\\phi}(z\\mid\\tau)$ as a Gaussian distribution parameterized by $(\\mu_{z}^{\\mathrm{enc}}, \\sigma_{z}^{\\mathrm{enc}})$ for the latent variable $z$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "344115b5-e8dd-44e0-9e19-e17d4f80c887",
                      "requirements": "The OPAL decoder (primitive policy) $\\pi_{\\theta}(a\\mid s,z)$ has been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b6fbd20b-f697-4031-8f1e-48ec275608f9",
                          "requirements": "The OPAL decoder has been implemented such that it is a latent-conditioned policy that takes current state $s$ and latent $z$, and outputs a Gaussian distribution over actions, parameterized by $(\\mu_{a},\\sigma_{a})$.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "34d188ba-9c5b-49ba-ad5e-b7100acbdb18",
                          "requirements": "The OPAL decoder has been implemented as a feedforward network (e.g., multi-layer perceptron with $L$ layers and hidden dimension $H$) or an autoregressive variant if used for sequential action prediction.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "42e0e7d3-8a37-4647-93ba-a994d391c072",
              "requirements": "The necessary training and evaluation has been run",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "33b2c89d-88c7-42f2-a27e-640ff1562f16",
                  "requirements": "The necessary training has been run",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "1b0751d6-efde-4b5b-b1ad-47a4509d6679",
                      "requirements": "Code has been implemented for training the necessary agent architectures",
                      "weight": 3,
                      "sub_tasks": [
                        {
                          "id": "07887b3b-e88d-49c9-949a-12ee14d70b53",
                          "requirements": "Code has been implemented for training FRE agents",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "bad4958f-dcc0-4f8f-9328-198a6b1d58d1",
                              "requirements": "Code has been implemented such that FRE training is strided: In the first phase the encoder-decoder is trained. In the second phase, the encoder is kept frozen while its outputs are used to condition the IQL policy. The IQL policy is trained during this second phase. The decoder is not used in the second phase.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "15d902cd-80ef-4af9-8c10-7bed54c10d50",
                              "requirements": "Code has been implemented such that when training the FRE encoder-decoder, the variational lower bound outlined in equation (6) is used as the loss function to optimize, or equivalent implementations.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "8b30922a-67a0-4ae8-98d5-3c14aa1c4529",
                              "requirements": "Code has been implemented such that when training the FRE encoder-decoder, the states sampled for decoding and the states sampled for encoding are sampled separately, such that the states used for decoding and the states used for encoding are different.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "31fe79b6-7031-4468-9ba9-ff46d90957e7",
                              "requirements": "Code has been implemented such that the FRE-conditioned policy is trained using implicit Q-learning, conditioned on the output z from the frozen encoder.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d922ee95-cda8-4ccc-bb4d-07af9a8ee238",
                                  "requirements": "Code has been implemented such that when training the FRE-conditioned policy using implicit Q-learning, the critic is updated with an MSE loss to the Bellman target: r + discount * mask * next_value",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "422ffe1f-c3f0-4562-ba99-05e5c69a4e87",
                                  "requirements": "Code has been implemented such that when training the FRE-conditioned policy using implicit Q-learning, the value function is updated with an expectile regression objective on the critic's Q-values",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "5ff98598-e932-4fa7-8d81-342c04348da5",
                                  "requirements": "Code has been implemented such that when training the FRE-conditioned policy using implicit Q-learning, the actor is updated via advantage-weighted regression (AWR)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "31e4d8ce-e490-4bba-b371-8a6a8e16e66e",
                                  "requirements": "Code has been implemented such that when training the FRE-conditioned policy using implicit Q-learning, after the critic update, the target critic is updated via a soft update rule from the critic params and previous target critic params.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "f0ab7926-f357-41a2-b39d-3af3a94d4022",
                                  "requirements": "Code has been implemented such that when training the FRE-conditioned policy using implicit Q-learning, the output z from the frozen encoder is concatenated to the current observation before feeding them into the actor, critic, target critic and value networks",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "29cebba5-18e7-43e1-90d3-6424117ef1c2",
                              "requirements": "Code has been implemented such that when training a FRE agent, reward functions are sampled from some prior reward distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "4adeeba2-ffc3-4ed2-84a4-9f255c6706cc",
                              "requirements": "Code has been implemented such that when training a FRE-agent, the states are labeled with their associated reward as determined by the reward function sampled from the prior reward distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "3ef7f2f7-3243-4a49-815a-d2b38591b186",
                              "requirements": "Code has been implemented such that in general, training a FRE agent follows the steps outlined in algorithm 1.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "91a5d50c-97a3-4c35-ad49-35020d674b3b",
                              "requirements": "Code has been implemented such that when training a FRE agent, the hyper-parameters outlined in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "f9cc6afc-346e-4f24-b8c5-63ce36bb74b6",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to FRE agents trained on Ant Maze dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "2ed48cb3-713f-44b0-b318-591d610cffd3",
                              "requirements": "Code has been implemented such that the additional physics information outlined in Appendix C.2 is appended to the environment state when training the FRE encoder on the ExORL `cheetah` and `walker` (RND) datasets",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d3c7236a-5bab-4ed5-a07d-097d2b27a865",
                          "requirements": "Code has been implemented such that FB agents can be trained using the https://github.com/facebookresearch/controllable_agent codebase or a fork of it",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "f9a0f9f3-3224-4e5b-acd4-0ae6113bb505",
                          "requirements": "Code has been implemented such that SF agents can be trained using the https://github.com/facebookresearch/controllable_agent codebase or a fork of it",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "a2681656-b1c7-414f-bd06-54d1bfb4ad83",
                          "requirements": "Code has been implemented for training OPAL agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "caaf32fc-df77-4d3b-8f74-de48997e4b97",
                              "requirements": "Code has been implemented such that, to train OPAL agents, sub-trajectories of some length c can be sampled from the offline dataset (e.g. c=10), forming the data used to learn OPAL's encoder and decoder (primitive policy). No reward information is used at this stage.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "2507c345-a631-4170-89fe-ecf49b63c65f",
                              "requirements": "Code has been implemented such that, to train OPAL agents, the OPAL autoencoding objective is used: maximizing log-likelihood of actions conditioned on latent $z$ and state, with a KL penalty to keep $q_\\phi(z|\\tau)$ close to $\\rho_\\omega(z|s_0)$.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "85fdbd9e-59b7-452f-bae7-0b771ecdf855",
                              "requirements": "Code has been implemented such that, to train OPAL agents, a low-level policy $\\pi_\\theta(a|s,z)$ can optionally be fine-tuned using latent-conditioned behavioral cloning on the same sub-trajectories (now labeled with $z$).",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "f6c9dda4-677f-4781-ad6a-be15de0e20b0",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to OPAL agents trained on Ant Maze dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "49005ae8-e018-4023-ba4e-ccb3e38f9039",
                          "requirements": "Code has been implemented for training GC-IQL agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "bb88edab-e4bf-490a-950b-72dd28682056",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, the reward is 0 if the state==goal and -1 otherwise",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "4712e793-7bdd-4035-9366-9f0d75a3ef51",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, the critic is updated with an MSE loss to the Bellman target: r + discount * mask * next_value",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "72e563cc-0eb9-48c6-b89e-45652db21c88",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, the value function is updated with an expectile regression objective on the critic's Q-values",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "28572598-c026-4643-a7b2-3e1105eefd4c",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, the actor is updated via advantage-weighted regression (AWR)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "faa8f3bb-c478-47ad-b402-304d56c64e8d",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, after the critic update, the target critic is updated via a soft update rule from the critic params and previous target critic params.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "4da59d31-58f1-4fdf-8777-7a89fb85afdf",
                              "requirements": "Code has been implemented such that when training GC-IQL agents, the goal is concatenated to the current observation before feeding them into the actor, critic, target critic and value networks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "d4fb400c-5b88-452f-b138-ca5f43f7313f",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to GC-IQL agents trained on Ant Maze dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "df1b3c49-cfd2-4e9d-b77c-79adc2ec374b",
                          "requirements": "Code has been implemented for training GC-BC agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9cbeb1b9-465f-414c-8287-69284c0d3b26",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to GC-BC agents trained on Ant Maze dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "ae220267-1fb7-419b-ab43-f0f80371275b",
                              "requirements": "Code has been implemented such that when training a GC-BC agent, the negative log likelihood between the GC-BC agent's predicted action distribution and the ground truth action from the training dataset is used as the loss function to be optimized",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "afa01ba7-dc47-470c-9c89-408c2fbc8420",
                              "requirements": "Code has been implemented such that when training a GC-BC agent, no reward information or reinforcement learning is used",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4fd1ad12-90a5-468b-9b97-6580ca6e15f7",
                              "requirements": "Code has been implemented such that when training a GC-BC agent, hindsight relabeling is used to associate a goal state with each trajectory in the training set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "18d2e88d-002b-49dc-a5b9-dd002eb42bb4",
                              "requirements": "Code has been implemented such that when training a GC-BC agent, the trajectory's goal state is concatenated to the agent's input as a conditioning mechanism.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4c9a6fc4-f23d-4415-a5f8-ccf74a362c21",
                      "requirements": "The necessary agents have been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                      "weight": 3,
                      "sub_tasks": [
                        {
                          "id": "5117bf13-59cb-4905-bef3-87f2ea327c65",
                          "requirements": "Code has been implemented such that the appropriate rewards can be associated with the trajectories of the `antmaze-large-diverse-v2` dataset as outlined in Appendix B",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "d4e9f03d-d0a9-42e2-b767-780d8431981d",
                              "requirements": "Code has been implemented such that singleton goal-reaching reward functions can be sampled and applied to the trajectories of the `antmaze-large-diverse-v2` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "425c9fc8-538e-4143-abab-a33fa9e68d7f",
                                  "requirements": "Code has been implemented such that, when applying singleton goal-reaching reward functions to the trajectories of the `antmaze-large-diverse-v2` dataset, a goal is selected as a random state from the dataset with a probability of 0.2, a future state within the same trajectory with a probability of 0.5 and a completely random different state with a probability of 0.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "9d761158-1a97-467d-9390-5c34e5f0fbcf",
                                  "requirements": "Code has been implemented such that when applying singleton goal-reaching reward functions to the trajectoreis of the `antmaze-large-diverse-v2` dataset, a reward of -1 is assigned at every step unless the agent has reached the goal state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "120cbe7d-2d08-466a-b2c0-02118e1f49c0",
                              "requirements": "Code has been implemented such that random linear functions can be sampled and applied to the trajectories of the `antmaze-large-diverse-v2` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d2ad5f82-d2db-41c3-b970-e39b78fb8f63",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `antmaze-large-diverse-v2` dataset, the random vectors defining the functions are sampled from a uniform distribution bound between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "76cccc3d-c5e9-4bba-acd1-806120e12801",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `antmaze-large-diverse-v2` dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "abb3688b-9b8d-462a-8609-61b2c0769f79",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `antmaze-large-diverse-v2` dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c52ba9e2-d9b5-4044-88da-958fa7a89250",
                              "requirements": "Code has been implemented such that random MLP functions can be sampled and applied to the trajectories of the `antmaze-large-diverse-v2` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b8b9bd34-918e-45fb-a1bf-e8be3a65ec57",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `antmaze-large-diverse-v2` dataset, the random MLPs consist of two linear layers, mapping from the state dimension to a hidden dimension of 32, and from 32 to and output dimension of 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "b2fddd01-5de1-41b6-baf4-e0aaa98df12e",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `antmaze-large-diverse-v2` dataset, the parameters of the random MLPs are sampled using a normal distribution scaled by the average dimension of the respective layer.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "2f8b2fd8-e5ae-43b2-9ae9-eaebd81cca76",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `antmaze-large-diverse-v2` dataset, a tanh activation function is used between the two linear layers.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "98291113-8a01-4624-afcd-708d25c1f198",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `antmaze-large-diverse-v2` dataset, the output of the MLPs is clipped between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "6a203c21-bf58-4589-a46b-fe5278004732",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-all prior rewards distribution",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "df64e51f-da9f-4fd0-9a2c-c8d6dbd53e96",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-all prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "8d4bd046-febb-441e-af20-03a543ae4cea",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-all prior rewards distribution, there is an equal 0.33, 0.33, 0.33 probability of sampling a singleton goal-reaching reward function, a random linear reward functions or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "64d49648-6eab-4147-b455-a606c2d70473",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-all prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "58f95f5a-e8d0-4961-94d8-ccdee4310ae8",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-hint prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "6c4fce0f-cda0-443e-81a0-8dc320d5e107",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-hint prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "b0d6d6b4-b7d7-4424-afc2-611090b447e5",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-hint prior rewards distribution, the prior rewards distribution consists of all rewards corresponding to movement in a unit (x,y) direction.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6a19acfd-2ce1-43a8-b47c-2303f1329626",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-hint prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "39c1faa5-ca65-4a53-8b94-ca64b1e60a4e",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goals prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8cd85ad2-a145-4bb7-97c4-7cb1bbd40569",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goals prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "61a28b5f-f2a6-4faa-a163-60b323098150",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goals prior rewards distribution, only singleton goal-reaching reward functions are sampled and used for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "b40be6bd-1225-4755-b60e-dd16f5e43665",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goals prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "781e7ff4-2380-471b-aded-821db7987302",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-lin prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "61af561b-335b-47bb-a194-c47827bac7e9",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-lin prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "1cc28c97-59c7-4733-8a2e-45d44b367a2e",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-lin prior rewards distribution, only random linear reward functions are sampled and used for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a7667234-841f-4a08-8f9a-4b23cebb1c94",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-lin prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "812e0d8a-5690-488f-9d4a-e5406ff466b9",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-mlp prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "6e6558f9-765b-463e-a170-becf47ed9f0c",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-mlp prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "b08d7709-bb81-40f5-9a98-f48b7784cac3",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-mlp prior rewards distribution, only random MLP reward functions are sampled and used for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "e32669f0-98fb-4248-a7a1-54d73a66280b",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-mlp prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "7c2260d4-1387-49ea-973a-17275a126253",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-lin-mlp prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "03cec4d5-1fc2-488e-a786-975793861d3f",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-lin-mlp prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "c9914ca1-9135-417d-be08-2c0772a1434b",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-lin-mlp prior rewards distribution, there is an equal 0.5, 0.5 probability of sampling a random linear reward functions or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "3c1fee00-9a97-483e-91a2-4937c4e814e6",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-lin-mlp prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3deb054b-4435-4ef9-94c1-cd21cf98b823",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goal-mlp prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1b4a1806-0a39-400a-8b12-91a75db328e2",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goal-mlp prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d31b56be-b137-4f5f-a065-2bb280e18855",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goal-mlp prior rewards distribution, there is an equal 0.5, 0.5 probability of sampling a singleton goal-reaching reward function or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "7e2f3082-ede8-48f2-a9a7-b65457dcf704",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goal-mlp prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4c458374-2184-4f64-a440-ca184352636a",
                          "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goal-lin prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3963a475-7aeb-417b-9391-e5fbbd503cc1",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goal-lin prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "7d9b1fe6-0cd5-4751-8368-b6119eb535b0",
                              "requirements": "Code has been implemented such that when training a FRE agent on the Ant MazE `antmaze-large-diverse-v2` dataset using the FRE-goal-lin prior rewards distribution, there is an equal 0.5, 0.5 probability of sampling a singleton goal-reaching reward function or a random linear reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "fcb3612a-7c05-44e2-b2c1-fee7f06ab6f2",
                              "requirements": "A FRE agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset using the FRE-goal-lin prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3745b924-350f-448f-a71b-660eef0886b8",
                          "requirements": "An FB agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "14d5ca37-69e4-419d-add4-b87fa29d5ffe",
                              "requirements": "Code has been implemented such that an FB agent can be trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "6db428ff-d03c-4656-99a2-df1d2ed72393",
                              "requirements": "An FB agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "6fdb0766-bdb2-4f3d-a6fe-7d142375bdad",
                          "requirements": "An SF agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "2cdf7237-9338-4c2b-8a83-d4ff80fc2b7d",
                              "requirements": "Code has been implemented such that an SF agent can be trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "068a7499-5d33-4770-8b75-34d5d26f5089",
                              "requirements": "An SF agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a6e0a6e7-495b-4e81-a6ca-f47b8c4e9c67",
                          "requirements": "An OPAL agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3d7c6335-03c0-494f-88a7-6d8b7913f2b1",
                              "requirements": "Code has been implemented such that an OPAL agent can be trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "617c421b-1bcd-4b92-9e4f-39f8e06c1cc4",
                              "requirements": "An OPAL agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "2c1fc727-51cc-4842-ae60-551731ddb1a7",
                          "requirements": "A GC-IQL agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3b6b5d48-afec-4ec3-b44f-3dd0119b28db",
                              "requirements": "Code has been implemented such that an GC-IQL agent can be trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "f4f6c096-cb80-43cc-a32b-d11b02b48264",
                              "requirements": "An GC-IQL agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ae2c0727-7f7e-484f-93c7-f71476186056",
                          "requirements": "A GC-BC agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1c9a402d-66ec-49db-88f3-9d2a1047bb8b",
                              "requirements": "Code has been implemented such that an GC-BC agent can be trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "65f07ab6-1d8b-43b6-bf2f-0f2f637504d0",
                              "requirements": "An GC-BC agent has been trained on the Ant Maze `antmaze-large-diverse-v2` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4d394fe6-9829-4bdd-b131-90f6e2566714",
                      "requirements": "The necessary agents have been trained on the ExORL `cheetah` (RND) dataset",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "5dc327e7-571f-4b34-85e6-ca2c2c57e03e",
                          "requirements": "Code has been implemented such that the appropriate rewards can be associated with the trajectories of the ExORL `cheetah` (RND) dataset as outlined in Appendix B",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "8e8208f1-2013-42df-8b3a-618d519c837a",
                              "requirements": "Code has been implemented such that singleton goal-reaching reward functions can be sampled and applied to the trajectories of the ExORL `cheetah` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9eec4876-cc5e-4748-9233-e2b38c2ee76e",
                                  "requirements": "Code has been implemented such that, when applying singleton goal-reaching reward functions to the trajectories of the ExORL `cheetah` (RND) dataset, a goal is selected as a random state from the dataset with a probability of 0.2, a future state within the same trajectory with a probability of 0.5 and a completely random different state with a probability of 0.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "f97dff83-ed0b-4632-a8bd-07a70e7d1153",
                                  "requirements": "Code has been implemented such that when applying singleton goal-reaching reward functions to the trajectoreis of the ExORL `cheetah` (RND) dataset, a reward of -1 is assigned at every step unless the agent has reached the goal state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b1b6796a-7ead-4597-a12f-95a89cd72139",
                              "requirements": "Code has been implemented such that random linear functions can be sampled and applied to the trajectories of the ExORL `cheetah` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "25de5fa6-0439-4ff3-90ba-fcb19ba989a7",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `cheetah` (RND) dataset, the random vectors defining the functions are sampled from a uniform distribution bound between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "16c9bc52-89f6-4684-939f-e18d042bdea9",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `cheetah` (RND) dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "59ba87e2-45ea-47ca-b97a-0346f531fb60",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `cheetah` (RND) dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ec128002-b11c-4588-95c8-0c8b9ec89d8f",
                              "requirements": "Code has been implemented such that random MLP functions can be sampled and applied to the trajectories of the ExORL `cheetah` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9b800f88-cc3b-459d-b74f-90a64f5d0680",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `cheetah` (RND) dataset, the random MLPs consist of two linear layers, mapping from the state dimension to a hidden dimension of 32, and from 32 to and output dimension of 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "6ce5c5d8-9a04-4849-b7dc-003b567a045a",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `cheetah` (RND) dataset, the parameters of the random MLPs are sampled using a normal distribution scaled by the average dimension of the respective layer.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "1d462431-8905-49eb-915d-004a2c91a148",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `cheetah` (RND) dataset, a tanh activation function is used between the two linear layers.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "96250516-ae2d-4f7e-a23e-9f39ce3def6f",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `cheetah` (RND) dataset, the output of the MLPs is clipped between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "27e48e30-dc2e-40f8-8924-4edf8aada26f",
                          "requirements": "A FRE agent has been trained on the ExORL `cheetah` (RND) dataset using the FRE-all prior rewards distribution",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "5508cfda-56f4-48fd-b0bd-a417a43743d3",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `cheetah` (RND) dataset using the FRE-all prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a51dc0ea-9fd5-492b-9adc-cea1865dad5e",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `cheetah` (RND) dataset using the FRE-all prior rewards distribution, there is an equal 0.33, 0.33, 0.33 probability of sampling a singleton goal-reaching reward function, a random linear reward functions or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "0b794c64-9483-4ca3-9097-901ed7a7c635",
                              "requirements": "A FRE agent has been trained on the ExORL `cheetah` (RND) dataset using the FRE-all prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e7302a8f-b61f-46eb-bad2-42a120bf0f0b",
                          "requirements": "A FRE agent has been trained on the ExORL `cheetah` (RND) dataset using the FRE-hint prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "631eca30-68dd-413e-b88f-21e1782fc3ba",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `cheetah` (RND) dataset using the FRE-hint prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "390a671a-f24d-4132-8971-005ccde1bcca",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `cheetah` (RND) dataset using the FRE-hint prior rewards distribution, the prior rewards distribution consists of random initializations of reward functions rewarding the agent for moving in particular directions at particular speeds, forming a superset over the `exorl-cheetah-velocity` evaluation task.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a2b00b9a-dc67-4a00-9540-5469b7640e5f",
                              "requirements": "A FRE agent has been trained on the ExORL `cheetah` (RND) dataset using the FRE-hint prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "95d72a2f-363a-4bd3-8014-e14ce805c07b",
                          "requirements": "An FB agent has been trained on the ExORL `cheetah` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "41b4a468-1be8-4629-b407-32282b33af31",
                              "requirements": "Code has been implemented such that an FB agent can be trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a65e7075-f6cc-44e6-9854-5ec55a16a67e",
                              "requirements": "An FB agent has been trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e1a57a0c-5f5e-460b-a951-ebf64490dcf6",
                          "requirements": "An SF agent has been trained on the ExORL `cheetah` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "56b2fd60-2110-4e3b-b7a9-8912e9b6593f",
                              "requirements": "Code has been implemented such that an SF agent can be trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d16f1c7f-19b7-4385-a869-799c7f897486",
                              "requirements": "An SF agent has been trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4f683571-4c4f-4be7-9cfe-13baa72d770f",
                          "requirements": "An OPAL agent has been trained on the ExORL `cheetah` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8c010722-eba2-499b-a633-a189df4dffd8",
                              "requirements": "Code has been implemented such that an OPAL agent can be trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "577c9728-b03f-4836-912b-242b0dab0836",
                              "requirements": "An OPAL agent has been trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "263cdf82-1aed-4890-86fb-9699a62b0d70",
                          "requirements": "A GC-IQL agent has been trained on the ExORL `cheetah` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "733cab32-1712-47d6-9db0-b06f6c6d2a24",
                              "requirements": "Code has been implemented such that an GC-IQL agent can be trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6b8fdb2d-4089-4fd3-bf64-2c47c3acc811",
                              "requirements": "An GC-IQL agent has been trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "030e63b4-42ac-4e02-bee9-dfe233e32616",
                          "requirements": "A GC-BC agent has been trained on the ExORL `cheetah` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "27fdf748-2d6c-4b43-bf65-3a7173f12a3e",
                              "requirements": "Code has been implemented such that an GC-BC agent can be trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d27214c8-a231-46fb-af22-7db92d29a990",
                              "requirements": "An GC-BC agent has been trained on the ExORL `cheetah` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "2e277d6a-c808-4d35-b8d0-9e03db9b38a3",
                      "requirements": "The necessary agents have been trained on the ExORL `walker` (RND) dataset",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "29d47566-aedf-4d45-80c6-a4aeaad48b01",
                          "requirements": "Code has been implemented such that the appropriate rewards can be associated with the trajectories of the ExORL `walker` (RND) dataset as outlined in Appendix B",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "d5bd1dbf-d217-4b8a-a546-99469e26db67",
                              "requirements": "Code has been implemented such that singleton goal-reaching reward functions can be sampled and applied to the trajectories of the ExORL `walker` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c6e84c9a-f6b3-46a8-8c71-5d3c8412e7ee",
                                  "requirements": "Code has been implemented such that, when applying singleton goal-reaching reward functions to the trajectories of the ExORL `walker` (RND) dataset, a goal is selected as a random state from the dataset with a probability of 0.2, a future state within the same trajectory with a probability of 0.5 and a completely random different state with a probability of 0.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "d431628a-47c7-455b-b8a9-2fe4140cf9cb",
                                  "requirements": "Code has been implemented such that when applying singleton goal-reaching reward functions to the trajectoreis of the ExORL `walker` (RND) dataset, a reward of -1 is assigned at every step unless the agent has reached the goal state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c8bc6a65-f389-4055-a474-dbd661ecaac1",
                              "requirements": "Code has been implemented such that random linear functions can be sampled and applied to the trajectories of the ExORL `walker` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "85b2ac3b-353e-4e57-b72b-62b978d87bf6",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `walker` (RND) dataset, the random vectors defining the functions are sampled from a uniform distribution bound between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "8b2072db-4a70-4da4-9c35-8e3cb424f06f",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `walker` (RND) dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "d0abdeb0-751f-4dc5-86c5-107b0ea4ccf5",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the ExORL `walker` (RND) dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "65368b17-5223-4ce7-ab72-cf38d1b61992",
                              "requirements": "Code has been implemented such that random MLP functions can be sampled and applied to the trajectories of the ExORL `walker` (RND) dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d82b74a2-eb0d-41b8-9bd2-6da738987951",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `walker` (RND) dataset, the random MLPs consist of two linear layers, mapping from the state dimension to a hidden dimension of 32, and from 32 to and output dimension of 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "be93b961-b705-4b4a-acf2-07cc02d9ed61",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `walker` (RND) dataset, the parameters of the random MLPs are sampled using a normal distribution scaled by the average dimension of the respective layer.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "54a70818-076a-4055-9796-a97fef49d0af",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `walker` (RND) dataset, a tanh activation function is used between the two linear layers.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "09b1a0d2-dc20-481e-9a0b-c4bde9fe4bed",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of ExORL `walker` (RND) dataset, the output of the MLPs is clipped between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3bb1f750-e3a0-40f1-9f24-bce96e51a542",
                          "requirements": "A FRE agent has been trained on the ExORL `walker` (RND) dataset using the FRE-all prior rewards distribution",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "11bd7539-4847-405c-ae7f-a0b616d73305",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `walker` (RND) dataset using the FRE-all prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "20b53e62-fb49-41bf-8553-ac7a7a55a29d",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `walker` (RND) dataset using the FRE-all prior rewards distribution, there is an equal 0.33, 0.33, 0.33 probability of sampling a singleton goal-reaching reward function, a random linear reward functions or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "9e20fc23-3d36-4bdb-8165-289b0d3b6952",
                              "requirements": "A FRE agent has been trained on the ExORL `walker` (RND) dataset using the FRE-all prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8b63065b-3d5a-4656-9393-39c12723600f",
                          "requirements": "A FRE agent has been trained on the ExORL `walker` (RND) dataset using the FRE-hint prior rewards distribution",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "77f406ad-abab-4468-be37-d6ed28067dc7",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `walker` (RND) dataset using the FRE-hint prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "ff48b670-3096-4cf5-9fec-7a481540f46d",
                              "requirements": "Code has been implemented such that when training a FRE agent on the ExORL `walker` (RND) dataset using the FRE-hint prior rewards distribution, the prior rewards distribution consists of random initializations of reward functions rewarding the agent for moving in particular directions at particular speeds, forming a superset over the `exorl-walker-velocity` evaluation task.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "39866a97-304e-47e8-b3fe-e263fc5cb643",
                              "requirements": "A FRE agent has been trained on the ExORL `walker` (RND) dataset using the FRE-hint prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "15608482-70e5-41c3-801a-76c5707a5d25",
                          "requirements": "An FB agent has been trained on the ExORL `walker` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "36e66dbe-cb69-4d36-8bf8-60a29f3d08f0",
                              "requirements": "Code has been implemented such that an FB agent can be trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "9c9a94c6-dce1-417a-bd29-5e0e5ce0c541",
                              "requirements": "An FB agent has been trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ffe2887b-fd5a-4f0e-829b-74f484b4b94d",
                          "requirements": "An SF agent has been trained on the ExORL `walker` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "0c8ac890-af63-4c26-b369-8296f7fdcd30",
                              "requirements": "Code has been implemented such that an SF agent can be trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7a319144-0829-4662-bb5d-577dc3f22878",
                              "requirements": "An SF agent has been trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4051b89e-5273-427c-ae1e-217ee98d2682",
                          "requirements": "An OPAL agent has been trained on the ExORL `walker` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "126dfc88-a0b1-4ba6-bc8c-bf9772c41a11",
                              "requirements": "Code has been implemented such that an OPAL agent can be trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d463b992-ec5d-4ce0-9f05-a8b73bf2b605",
                              "requirements": "An OPAL agent has been trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "157e7e6d-c099-46e2-b762-7bcbea044581",
                          "requirements": "A GC-IQL agent has been trained on the ExORL `walker` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "057833f3-bfae-4237-8b50-d360713cb0a9",
                              "requirements": "Code has been implemented such that an GC-IQL agent can be trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "68fbf341-5861-4b78-9733-bd5579659789",
                              "requirements": "An GC-IQL agent has been trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c60a507f-2249-4f23-9581-eec0e68430e6",
                          "requirements": "A GC-BC agent has been trained on the ExORL `walker` (RND) dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "bd31ca48-37ed-46dc-b12a-8283c37384dc",
                              "requirements": "Code has been implemented such that an GC-BC agent can be trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "badabb41-0321-4828-a655-9f0251427dee",
                              "requirements": "An GC-BC agent has been trained on the ExORL `walker` (RND) dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "cb8bbe00-3d08-43f0-90f3-18e166a883d2",
                      "requirements": "The necessary agents have been trained on the `kitchen-complete-v0` dataset",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4afb62b9-503f-4912-877c-bbf07a43c7ff",
                          "requirements": "Code has been implemented such that the appropriate rewards can be associated with the trajectories of the `kitchen-complete-v0` dataset as outlined in Appendix B",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "64503118-73a2-46b0-ad88-86f9009e1e2d",
                              "requirements": "Code has been implemented such that singleton goal-reaching reward functions can be sampled and applied to the trajectories of the `kitchen-complete-v0` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "2a86fe14-96c5-4940-8025-bac07f3ea724",
                                  "requirements": "Code has been implemented such that, when applying singleton goal-reaching reward functions to the trajectories of the `kitchen-complete-v0` dataset, a goal is selected as a random state from the dataset with a probability of 0.2, a future state within the same trajectory with a probability of 0.5 and a completely random different state with a probability of 0.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "660e39bc-01ce-4487-819f-b192fcecd33e",
                                  "requirements": "Code has been implemented such that when applying singleton goal-reaching reward functions to the trajectoreis of the `kitchen-complete-v0` dataset, a reward of -1 is assigned at every step unless the agent has reached the goal state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "51282e3e-8d42-4454-92ac-4b894cb28fda",
                              "requirements": "Code has been implemented such that random linear functions can be sampled and applied to the trajectories of the `kitchen-complete-v0` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "29350167-f138-4491-84a2-fb69b3a42ee7",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `kitchen-complete-v0` dataset, the random vectors defining the functions are sampled from a uniform distribution bound between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "c34f41d7-53a6-4ec3-b834-fc66c2971453",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `kitchen-complete-v0` dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "27c0c34f-ef21-413f-b9f2-eb930f369110",
                                  "requirements": "Code has been implemented such that when applying random linear reward functions to the trajectories of the `kitchen-complete-v0` dataset, a random binary mask with 0.9 probability of 0 is applied to the random vector defining the reward function.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "bab0d8f1-5652-45de-9057-ab7d80df7911",
                              "requirements": "Code has been implemented such that random MLP functions can be sampled and applied to the trajectories of the `kitchen-complete-v0` dataset as outlined in Appendix B",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d62cd5d1-2d48-4511-bf4a-ba6f0ecabbde",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `kitchen-complete-v0` dataset, the random MLPs consist of two linear layers, mapping from the state dimension to a hidden dimension of 32, and from 32 to and output dimension of 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "c87269a8-c3f8-4d69-b999-ca6d3582b78c",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `kitchen-complete-v0` dataset, the parameters of the random MLPs are sampled using a normal distribution scaled by the average dimension of the respective layer.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "42273065-fd8b-4e08-b279-0384aa33430f",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `kitchen-complete-v0` dataset, a tanh activation function is used between the two linear layers.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "194f8a3e-4da1-4384-92d6-7a7d58cdcccd",
                                  "requirements": "Code has been implemented such that when appying random MLP reward functions to the trajectories of `kitchen-complete-v0` dataset, the output of the MLPs is clipped between -1 and 1.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "24a6d412-d018-494b-aa2f-59ce4475bd2d",
                          "requirements": "A FRE agent has been trained on the `kitchen-complete-v0` dataset using the FRE-all prior rewards distribution",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "2eb7183e-dfe1-433b-8f22-5afc08076539",
                              "requirements": "Code has been implemented such that when training a FRE agent on the `kitchen-complete-v0` dataset using the FRE-all prior rewards distribution, the training and architecture hyperparameters specified in Appendix A are used.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "83202f54-a253-445f-87c5-b20c2073cf85",
                              "requirements": "Code has been implemented such that when training a FRE agent on the `kitchen-complete-v0` dataset using the FRE-all prior rewards distribution, there is an equal 0.33, 0.33, 0.33 probability of sampling a singleton goal-reaching reward function, a random linear reward functions or a random mlp reward function for each training trajectory.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4c9cfa23-a8b8-478e-998e-a4a1f0a0d2f6",
                              "requirements": "A FRE agent has been trained on the `kitchen-complete-v0` dataset using the FRE-all prior rewards distribution",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d894bb66-5a8d-4c38-94df-c2d05a567ec2",
                          "requirements": "An FB agent has been trained on the `kitchen-complete-v0` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "7936e1fc-9a80-4a68-b0ca-d270b1807d1e",
                              "requirements": "Code has been implemented such that an FB agent can be trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "73895090-ddd8-49e8-b96f-2292783faf28",
                              "requirements": "An FB agent has been trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ff3c3dca-e927-4124-a5c2-4c04e1350441",
                          "requirements": "An SF agent has been trained on the `kitchen-complete-v0` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "33f254f6-e00a-4c5a-8bbd-9349c4c01398",
                              "requirements": "Code has been implemented such that an SF agent can be trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7c051e05-5a4c-4e5e-9532-79ae9d4b4d3d",
                              "requirements": "An SF agent has been trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "b77577ed-d631-4d06-a333-4b5a35a3bf8d",
                          "requirements": "An OPAL agent has been trained on the `kitchen-complete-v0` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f901be1c-2239-4d5c-b34c-9a839842fbe4",
                              "requirements": "Code has been implemented such that an OPAL agent can be trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "3d1b54ba-72e5-4bbd-9caf-f08ec6952a55",
                              "requirements": "An OPAL agent has been trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cb28f72e-e57b-4648-b254-309aaf3c7681",
                          "requirements": "A GC-IQL agent has been trained on the `kitchen-complete-v0` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5a20458c-8da5-4b52-a5a0-8dc6831385bf",
                              "requirements": "Code has been implemented such that an GC-IQL agent can be trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d1249f99-5619-495f-9692-abfc733cc3fa",
                              "requirements": "An GC-IQL agent has been trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a427bad2-c037-4ae3-ba90-4177dfcb6c7b",
                          "requirements": "A GC-BC agent has been trained on the `kitchen-complete-v0` dataset",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5d1739d9-997b-4fff-ae36-7fbdf7ff8071",
                              "requirements": "Code has been implemented such that an GC-BC agent can be trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "56f5605d-331a-4ca5-aeba-c747321616f9",
                              "requirements": "An GC-BC agent has been trained on the `kitchen-complete-v0` dataset",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d9dde6d5-66a3-46e8-b7fa-8f5b2a50e471",
                  "requirements": "The necessary evaluation has been run",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "244667bf-831a-4d38-a8d0-18547ddb8189",
                      "requirements": "Code has been implemented such that evaluation can be repeated and averaged over twenty (20) episodes",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6697fcce-1f11-4431-8221-ce30cc6154fe",
                      "requirements": "Code has been implemented such that each evaluation can be repeated and averaged over five (5) seeds, where each seed corresponds to multiple episodes being evaluated.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c521ff08-d940-4972-8ca0-be9fb7f01d32",
                      "requirements": "Code has been implemented for evaluating the necessary agent architectures",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b0b46f2d-3dd4-453f-9226-013220527a76",
                          "requirements": "Code has been implemented for evaluating FRE agents",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "e3e36e0a-d276-4726-9e22-8754eb9f799a",
                              "requirements": "Code has been implemented such that when evaluating a FRE agent, 32 state-reward pairs are sampled the from the evaluation task environment and passed through the corresponding FRE encoder to obtain the latent z for policy conditioning.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c48319bf-ee1b-40e7-b5a8-54d124e8dca3",
                              "requirements": "Code has been implemented such that, for evaluating a FRE agent, the z latent produced by the FRE encoder is used to condition a pre-trained implicit Q-learning policy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b2f98ca4-2805-4e7c-afa2-16f58c8fb4d4",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to FRE agents evaluated on Ant Maze environments",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "a92f411b-2e8f-444c-9af5-1dc116d8f281",
                              "requirements": "Code has been implemented such that the additional physics information outlined in Appendix C.2 is appended to the environment state when evaluating the FRE agent on the ExORL `cheetah` and `walker` tasks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7a33ccdc-e0c6-4da8-a392-9f9455bbbfc3",
                              "requirements": "Code has been implemented such that an agent pretrained via FRE can be evaluated on target tasks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "0169f82d-aef1-4700-97b4-1a761fe4e633",
                          "requirements": "Code has been implemented such that FB agents can be evaluated using the https://github.com/facebookresearch/controllable_agent codebase or a fork of it",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c0b275fd-272b-4656-8895-206808a35713",
                          "requirements": "Code has been implemented such that SF agents can be evaluated using the https://github.com/facebookresearch/controllable_agent codebase or a fork of it",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bf48c787-116e-4c39-a79a-e79fff8d4e63",
                          "requirements": "Code has been implemented for evaluating OPAL agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "c3dd8354-9247-4d2b-89fa-e46534fef3ee",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to OPAL agents evaluated on Ant Maze environments",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "8024564e-c86d-48ed-ad23-76553c6b350a",
                              "requirements": "Code has been implemented such that, for evaluating OPAL agents, for a given episode, 10 random OPAL skills can be sampled from a unit gaussian.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fac710db-d53e-4001-bdf2-8aed198f978d",
                              "requirements": "Code has been implemented such that, for evaluating OPAL agents, for a given episode, the agent is evaluated on the target task separately conditioning on each skill sampled from the unit gaussian",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2e132b5f-15a0-4774-9b6f-6e2538c5ef9f",
                              "requirements": "Code has been implemented such that, for evaluating OPAL agents, for a given episode, the performance is taken to be the best performance across the 10 sampled skills for that episode.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c2300ee7-b5ac-4b80-a92f-276a7fdf4d2b",
                              "requirements": "Code has been implemented such that an agent pretrained via OPAL can be evaluated on target tasks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "6fc9a15c-036e-4cf7-a592-e334013ce83a",
                          "requirements": "Code has been implemented for evaluating GC-BC agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3eab10fb-3d76-484e-9ffb-16ab6b7fdeda",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to GC-BC agents evaluated on Ant Maze environments",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "93fa32e7-593d-4632-96a2-cff95ceedb47",
                              "requirements": "Code has been implemented such that an agent pretrained via GC-BC can be evaluated on target goal-reaching tasks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3900f1ca-dbc3-4976-a397-847a0661c8c4",
                              "requirements": "Code has been implemented such that when evaluating GC-BC agents, the goal state is made available to the agent at the beginning of the rollout",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4fcc5dd3-0929-4104-8a49-09b2f39258ec",
                          "requirements": "Code has been implemented for evaluating GC-IQL agents",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1d10e358-68ab-4f7b-8343-9a92f71edd5e",
                              "requirements": "Code has been implemented such that the observation space's XY coordinates are discretized into 32 bins for input to GC-IQL agents evaluated on Ant Maze environments",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "24c19136-2671-489d-88b9-6a203e7df7e1",
                              "requirements": "Code has been implemented such that an agent pretrained via GC-IQL can be evaluated on target goal-reaching tasks tasks",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "d079bcac-1277-4ae5-933f-f3ccb9e28453",
                              "requirements": "Code has been implemented such that when evaluating GC-IQL agents, the goal state is made available to the agent at the beginning of the rollout",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "e7df2f50-8022-4bfe-9b77-0bfbe02669b4",
                      "requirements": "The necessary agents have been evaluated on the Ant Maze evaluation tasks",
                      "weight": 3,
                      "sub_tasks": [
                        {
                          "id": "e07c5e86-6c2c-4610-8d97-44531cbfaa06",
                          "requirements": "Code has been implemented such that Ant Maze tasks are evaluated online, i.e. the agent to evaluate and environment are instantiated and the agent acts in the environment",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ed6854c2-5521-431a-9aa3-3b0efc4aaaf1",
                          "requirements": "Code has been implemented such that during the evaluation of Ant Maze tasks, trajectories are limited to a maximum of 2000 steps.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "0ae7b1c7-88f9-4654-8b8a-277d059955bf",
                          "requirements": "The necessary agents have been evaluated on the `ant-goal-reaching` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "aea4f085-1983-4658-be1f-3ef4a968494a",
                              "requirements": "The `ant-goal-reaching` evaluation task has been implemented as outlined in addendum.md and Appendix C.1",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "66e8abac-44b0-4a9f-8975-8c3e23f44889",
                                  "requirements": "The `ant-goal-reaching` evaluation task has been implemented such that the agent is evaluated on the 5 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d9bf8c02-ce28-4005-87e9-913791e71807",
                                  "requirements": "The `ant-goal-reaching` evaluation task has been implemented such that the average cumulative reward across the 5 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f5dc7467-50c8-46a1-ba2d-0ae10b43b9a0",
                                  "requirements": "The `ant-goal-reaching` evaluation task has been implemented such that the goal is considered reached if an agent reaches within a distance of 2 from the target position.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f4430c7e-445c-4492-bdd7-1cb1f766999f",
                                  "requirements": "The `ant-goal-reaching` evaluation task has been implemented such that the agent receives a reward of -1 at each timestep until it successfully reaches the goal.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c2a5aaed-5017-4bc9-b7a7-d3a08249bdae",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "ca9b0276-199e-45ec-9483-058caa982237",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d21d6d68-6dff-4eb6-80db-d4bbbfc7aa77",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "13941dc4-74f6-4208-9f87-7bb570a63926",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c9462682-e03b-4d73-81db-8134eafd600d",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "116f3620-7d86-4ed8-a7dd-e128f882c971",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "8f9d6b84-a3e0-44fe-8383-f0e3055b3efe",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "1f185bff-60dc-4033-9391-20b2824f02b8",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "fdb27e83-9219-4995-a500-6f894b19c095",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "51a39759-6c40-42b2-8ad6-cce16d5eca54",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3424489d-558d-4c6a-96ef-103b94526b1d",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "813a726d-fc10-4917-9af6-9d3da77f037a",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a48ae741-956a-46d2-9d83-b2feaceadcd6",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "406f3c3a-d123-4967-a0ea-2958f12300ab",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "0493ce85-421b-45b2-a53e-f8377110f667",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ace2916a-4c89-4109-a8c2-c1bf78140031",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "35803a76-441e-445e-a97f-0d8fd80d6353",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "4d92c43b-7dae-4383-b1fb-314cb120cb98",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "bc8476ec-cda2-4ff1-ae53-90943824df58",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b3577421-5b7c-4889-875d-a82b188dce8e",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "79652880-b782-4fca-bbff-b52a55d13fcd",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "00f2dd72-7f94-44a8-8ee9-a7012ce1e2c8",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "fa867daf-5b7c-44b9-8400-64fc4043fbda",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "599da9c6-ab0f-43c4-a432-ce71d842b02f",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "45a3404b-ce28-46c1-808d-b619d4189a54",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "becd59d0-28dc-4be6-8496-6abd3ffd0ebd",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3979ee05-5dc7-4691-8eb8-434b5fc65c48",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "97de119d-45b4-4fb5-9759-59fc4cb1191c",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "eab067af-c526-431d-b1e8-4a08f06b9e53",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b1395b9e-7452-4fe1-a4e6-73b7e8f35a5d",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "f946606d-8f2b-4090-b9c7-e003569b8f44",
                              "requirements": "A GC-IQL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "57058927-33c6-413b-a38a-b74428a85074",
                                  "requirements": "Code has been implemented such that an GC-IQL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f1df89e5-a4f0-4c58-aa76-dca210459be9",
                                  "requirements": "Code has been executed such that an GC-IQL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "529e70bb-7b4b-4de0-8336-d112998f3169",
                              "requirements": "A GC-BC agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6bc39ee5-f085-4f4f-9619-6bd2d7063a00",
                                  "requirements": "Code has been implemented such that a GC-BC agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "fe30a1f7-dd62-4b98-bc6d-90aa7afa3825",
                                  "requirements": "Code has been executed such that a GC-BC agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "659f0556-d354-4a0b-b523-d7e4a4a87664",
                          "requirements": "The necessary agents have been evaluated on the `ant-directional` evaluation task",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "ad13f9e9-4649-4fe7-b632-c7ba88809777",
                              "requirements": "The `ant-directional` evaluation task has been implemented as outlined in addendum.md",
                              "weight": 3,
                              "sub_tasks": [
                                {
                                  "id": "53a057fc-5ffd-4e73-8a7c-02aa42696f48",
                                  "requirements": "The `ant-directional` evaluation task has been implemented such that the agent is evaluated on the 4 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e6193543-b632-4855-853e-40f64e39b1fe",
                                  "requirements": "The `ant-directional` evaluation task has been implemented such that the average cumulative reward across the 4 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "68f27cfa-dd32-4bf1-9062-904f70b929ad",
                                  "requirements": "The `ant-directional` evaluation task has been implemented such the reward is scaled by how much the agent's velocity aligns with the target direction, utilizing a dot product.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a362c17d-4904-4d25-8c39-dd766c0f4cef",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 3,
                              "sub_tasks": [
                                {
                                  "id": "448f277f-d512-44c2-8525-c01c6e0ca803",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "32f02dcc-bff3-43a7-92e4-aa831cd4d35d",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "30713969-bfcb-4550-9d54-950ed1e1f9d1",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "474b4b95-7317-4987-aac5-d489853562ea",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-hint can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "19d94a96-5dce-486b-85fa-ea0be685fe85",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6e7f3ffd-60ed-4d64-9be3-a6d2ceec8d77",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "52e140d7-ea50-4057-b624-5d558af8ec93",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b05ece5e-7867-4867-ae0d-6efadd9e596c",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "199d8a34-4a3c-4234-a670-68765f127b8a",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "099200fd-9f2c-4202-9dd7-7dcf50122f2f",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ad275ec2-4fb6-47e0-9b6d-8f20e8df9d60",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7eba4273-bcc0-446f-b80e-681f846ab57a",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "71b720f2-1787-4940-b8be-ba7ae5c64c48",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "16e1778f-88ec-4050-a7cf-841be12a6bd2",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "2853fd5d-9d7a-449c-935a-308088423d55",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "172274db-cd1f-40b5-a3a1-cfede0780664",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "4de68bc0-fc38-4052-b0ac-521a9893f488",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "469aa2e2-df9f-43a5-8340-1802b35a5917",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "40b673b0-0638-4d93-8be7-f20b8aac6cad",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9e6051ed-5185-4e9e-a9fe-4b1538310a24",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3c5c1892-f46b-4d64-9ee7-d22c8d381e21",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5532df06-3a7b-4a47-9306-f7ef6bb77208",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3f2d0ba9-ed70-408d-b395-e8f3eb846624",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "2cc49e56-5c88-4fda-b756-a178318e4b9f",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3587539b-7f64-49b5-b3bf-8201548f4775",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e1e1ed7f-fedb-4ec9-b30a-b6be0f853d38",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cdafa4b3-7c64-4250-980f-9a2abbd338c6",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7e63b8ff-7d60-4113-9ae6-5238d01bdbe0",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "56c078eb-5e16-4a6c-bcbf-3c8cf842d1cd",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "23b0fcd2-60f6-4d33-b9e6-0880f3f3b2e8",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c41d6c2c-6809-43e3-876c-15988826703f",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "31143ebe-3946-4f45-a6f1-c17f6a252265",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "24453843-3c8a-4345-abc3-18afa140772f",
                          "requirements": "The necessary agents have been evaluated on the `ant-random-simplex` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "567e90bf-2bea-478e-80c7-28ea602d297c",
                              "requirements": "The `ant-random-simplex` evaluation task has been implemented as outlined in addendum.md",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "8a6209c8-4cb5-4e2f-8401-64089b88b171",
                                  "requirements": "The `ant-random-simplex` evaluation task has been implemented such that the agent is evaluated on the 5 seeded opensimplex height and velocity preferences as outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "2ff868ca-cb09-4867-8ba2-46340e1039a2",
                                  "requirements": "The `ant-random-simplex` evaluation task has been implemented such that the average cumulative reward across the 5 seeded tasks is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "60cad4b9-d5ae-46ee-a6a9-dd7f8f6c89b7",
                                  "requirements": "The `ant-random-simplex` evaluation task has been implemented such the agent gets baseline negative reward (-1) at each step, a bonus if it stands in higher 'height' regions, and an additional bonus for moving in the local 'preferred' velocity direction indicated by the noise field.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a976ad6c-352e-4fab-bb89-c51de14d65de",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "2839bbbb-e381-4cae-8100-998b50f220f0",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b738bad3-4d91-4029-8005-dcf9cd7cb2ea",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "80b84f55-a1c0-4249-9646-305abebcc7f4",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d1b9d52c-9a8b-464d-b7fc-1f66dd079e4c",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "0810257e-aff0-4aca-815a-80761e346e2b",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9755cad2-760b-4c22-9adc-fa2fe68c875e",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3377b462-0b2f-4d2b-a819-8d38f08cfcd2",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "8de00d0e-55ac-4112-ad30-06e22470457f",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3fc6d4a4-b4c6-47bf-9710-66eacfffca8a",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d430077d-68c8-4869-9f1d-7ff1989ada70",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "1b1bb40a-180f-4c76-8724-1416e00b8c81",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "97925c41-26b0-43d6-835e-f7e39771a321",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "18ed0467-9ef8-4ba2-b9fc-560ed3cc88cf",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "6ac8e446-6758-4374-997b-3cb030b5ba31",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "4473d617-c06d-4cbf-884c-c329fcf2631a",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "201ad6e9-c09b-474b-90cd-cdb65bd69491",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ccadbc78-e6b1-4124-91ba-a03529bcd13a",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "13b3d00f-265b-4701-9921-f1198f986b84",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4c731f80-30f2-4371-8b7b-3eeba5d66ab6",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c3d92133-77da-4676-ae89-5c30633d0433",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "fd86ca36-b5cc-444b-bd68-e27a0d574c11",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "2da828b8-831b-4ec4-b093-2a2094c0add3",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3ed0cb01-b80f-41a6-924d-68f4df2bfa0c",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "80ad4d7a-fed8-4654-83dc-2ae6a6872e91",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0843355d-de6c-46f2-805a-f241b92265bb",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c3c7b10d-e1ce-468b-87b4-2b5562b9753d",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "231e1dcb-d3b7-4a2a-96fb-6cdfedba48f1",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e2afb0ab-77d2-48ef-bc80-db13d6f87c85",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "51faccc9-4564-4ecd-92c4-dce51c619138",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-random-simplex`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "fce616d3-1e21-4ba8-99e9-41480d5c48ee",
                          "requirements": "The necessary agents have been evaluated on the `ant-path-center` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "2c3f2517-10b4-4a39-bda7-3984790987a7",
                              "requirements": "The `ant-path-center` evaluation task has been implemented as outlined in addendum.md",
                              "weight": 2,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "73e3637c-3815-4c79-b4f3-4157b219e966",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "42a4428a-2309-4ecb-a832-a6de7c6c6667",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "069e26a9-f025-4dd1-b587-cdad05e82d1e",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "fb1608df-b705-4d64-85bb-ca462e20e85c",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b1e109c5-768a-41b5-aa9c-b406b3c875e1",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "1b0ef2bb-0e39-4c70-853e-816f4e10d429",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c856c023-a4e0-4256-931a-e3dc05b9e44b",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9128e117-2ae5-4011-871a-029e14d46db2",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d4dcc933-61a3-4af3-aae0-962430b6c15f",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "5e9d1bc4-9a5c-47eb-8267-847224cd1166",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c58a7007-5978-4dd9-8da2-733474eb6f6f",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b3a4a1c3-ceb4-4b3c-ba5e-22f67210609a",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b3ab26c6-6058-4502-9617-cbfacfcc0010",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4bae6b40-8d28-41ec-8d7e-663a54175960",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d044f326-1ab1-4aa5-8f3d-2795fcda2d64",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "39d90422-c20b-4b0d-b448-08b22fd77fe7",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "fd65d129-1bc4-4da2-8986-3efa5d3a72cd",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c7ca7150-7e34-4251-8fc5-e731020a8d26",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a4082358-1e67-4894-9fd8-b3cdeecc9098",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "fad601e1-0c67-4b47-99d4-7acfe6453219",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ab275099-337d-4693-86e4-71ef8dc784af",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ceeb5f59-542d-4554-8f9d-afb3051b0e41",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a23d0d26-a12a-46c7-b741-706d6cbc6753",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "208a3900-8429-4542-acfb-0e0dc771948d",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3505bb4b-7131-4d74-b3cc-055f65101168",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b1978052-7248-43e1-b2fc-0bf002e9e104",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "cb6cf3a6-8e4c-42fb-bb9a-7a9d28b753eb",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "33bedca9-25ba-4a53-b352-535427581243",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f55032a4-8fdf-42c3-bd20-965c1251e206",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d48e1545-f0d6-4355-b55c-9576491052bd",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-center`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4c609cc0-b563-4e3e-916f-7dde0411f704",
                          "requirements": "The necessary agents have been evaluated on the `ant-path-loop` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "8a61c6b3-2e7c-445a-8f92-e9bee61d5735",
                              "requirements": "The `ant-path-loop` evaluation task has been implemented as outlined in addendum.md",
                              "weight": 2,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "63fef61d-93e1-4cc1-8646-64f19201dff0",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "f83bcd10-6d64-4681-8a08-b5ae823239c1",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "58b77f28-5fd8-42a7-b623-67cb5cb583de",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b233e510-1512-4e9d-8391-e57b5804fa2c",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "71cabbee-4b99-494c-bc68-2fcd4fde9c3b",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "acf4e73f-9f48-4868-8106-cc50a042544f",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "bf574842-571b-45ed-88cd-c1c001069828",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a4929297-e3df-4c5e-bc39-9aadce85309c",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a02d8fb3-587f-449f-9d20-16da975b3303",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cf086f69-f3e5-4940-b702-5b9b534167e9",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6da729f0-398f-4c28-90f5-e570f318a4b7",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "444792aa-8de9-4806-8034-b54271e8367b",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "11e1d128-0bf2-4165-ad4a-1f3dd447ea97",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a2146a9c-d5cf-44b6-bf50-6c65f0213cb6",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "4d7ce037-a59d-498d-a5ea-4b5552d5d9b5",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "31486647-f8cf-41f5-99a6-292109ad5583",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7b8d648c-d256-42f3-a95a-65278333437c",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c313d0d9-90f0-428f-8b7f-3bf2ffe8c6a0",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3def2878-7539-4b87-a2be-91578ab72019",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "172583d7-a2e5-445c-a05f-1108f7b6a92a",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "eab3ad1d-03b7-48c6-8ceb-16d18a3fd288",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "eeb285ca-fa48-47cf-b80d-3b789dc7d1fa",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9c0ec0c7-2558-403c-8d06-01ddf9f188ec",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "46dd6087-a973-4b8e-99c3-b1719c231971",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "14e9cf39-28c2-4fe2-a4ec-cdb6bdeb7849",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "48b5fc95-9e8b-467c-827c-4ea77366d642",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "0d565a3e-dfc3-4194-bca7-eadc9fcb946d",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "fbc45a96-715f-4b97-be54-a06e277e62d9",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "18d94c00-8ae3-4817-bfc1-c738121f1fe1",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "16905fa3-99bf-4659-bc25-4c994a4a1a64",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-loop`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "06599656-f4b9-4f95-8a86-9da7ee7d8659",
                          "requirements": "The necessary agents have been evaluated on the `ant-path-edges` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "f488ec49-0d0f-450f-84d6-e417da5481e7",
                              "requirements": "The `ant-path-edges` evaluation task has been implemented as outlined in addendum.md",
                              "weight": 2,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "80e13062-ffce-4380-a3c6-65b697708875",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "7563ccd1-a6b2-4fdb-bf43-cd1f77879857",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a2605a3c-3303-41ee-8c61-5cee58369259",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d503bd0b-1298-463d-96e8-b42da1438b2b",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6f38b438-da07-4841-8c0d-cee40721456b",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e688938c-8991-4280-9e27-e58c10c96182",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goals has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cda9ac3e-9f9a-4e46-bb4e-5b9a9fbf2891",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f949e379-b6f0-4d0b-ad50-ae8879b8ab8a",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "14068c03-da3d-4e72-9d1e-0cd783513935",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "5f402fdd-7ebc-48f3-8089-621ecce04c44",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "373f3845-c736-4dd1-ad88-d5e788523f03",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "fede5443-8b54-4833-acf2-f53cda139c78",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "4975ac51-85cc-403d-9d39-881916c46107",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "909d13a6-b1bf-41aa-ab04-bc3bf9254650",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f7b14f26-f3c7-4632-8069-137cc1ac0ff2",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-lin-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a60efde4-80fe-4cdc-a880-378db017afe9",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c59574b9-432a-4d9d-9de8-2d1a7af9bc89",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "852706da-2ec6-4633-90ca-2d5c400434df",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-mlp has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "aac91715-6e48-443e-84cc-125923416d2d",
                              "requirements": "A FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3545d45c-ea17-4e35-bb97-bb16360f5c30",
                                  "requirements": "Code has been implemented such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "aef98935-89aa-4272-8b2a-879a4947ac90",
                                  "requirements": "Code has been executed such that a FRE agent trained on `antmaze-large-diverse-v2` with the prior reward distribution referred to as FRE-goal-lin has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "52ec9f33-474a-4bea-837e-62d9b6b7fcb8",
                              "requirements": "An FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d3ed7c0c-9e7a-454e-9e5d-bb4d55853115",
                                  "requirements": "Code has been implemented such that an FB agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "71e4572b-63f4-4444-8cd4-f8a5750f3ef3",
                                  "requirements": "Code has been executed such that an FB agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-directional`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "cb9670c9-d93d-4583-924c-351c9a6029c6",
                              "requirements": "An SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "82b053b3-9d81-4092-959a-d7c3a2dece32",
                                  "requirements": "Code has been implemented such that an SF agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "f66b6567-15d1-4eb4-adeb-56039164f799",
                                  "requirements": "Code has been executed such that an SF agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "397d4471-ed11-4154-83c2-815a19d35aa6",
                              "requirements": "An OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d9fca992-a961-4a06-8a11-e3fc20d84f66",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on `antmaze-large-diverse-v2` can been evaluated on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "78e86adc-8074-440d-a616-9666df4649cb",
                                  "requirements": "Code has been executed such that an OPAL agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-path-edges`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "778741a8-bbb4-4d77-b855-ebcb74f0c6f9",
                      "requirements": "The necessary agents have been evaluated on the ExORL evaluation tasks",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "1fc923e9-004a-47f9-aaaa-820343600023",
                          "requirements": "Code has been implemented such that ExORL evaluation tasks are evaluated online, i.e. the agent to evaluate and environment are instantiated and the agent acts in the environment",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "73141dba-08d8-47a8-b616-ecd160f31f4a",
                          "requirements": "Code has been implemented such that during the evaluation of ExORL tasks, trajectories are limited to a maximum of 1000 steps.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "20a37a80-69bb-4e80-99b3-9d95a28c3ef1",
                          "requirements": "The necessary agents have been evaluated on the `exorl-cheetah-velocity` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "4b6e9c2e-66b8-4150-b534-2f210fc188ee",
                              "requirements": "The `exorl-cheetah-velocity` evaluation task has been implemented as outlined in addendum.md and Appendix C.1",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "355ad887-e94a-4c14-b291-4c5c71d91130",
                                  "requirements": "The `exorl-cheetah-velocity` evaluation task has been implemented such that the agent is evaluated on the 4 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "152a0cb1-280d-48fd-8b50-13a751d61780",
                                  "requirements": "The `exorl-cheetah-velocity` evaluation task has been implemented such that the average cumulative reward across the 4 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "fdc87d30-7749-4b8c-917f-f74a0fa1cd80",
                                  "requirements": "The `exorl-cheetah-velocity` evaluation task has been implemented such that at each step, the agent is assigned a reward of 1 if the agent's horizontal velocity is at least equal to the target velocity, with the reward otherwise linearly decaying towards 0 the lower the agent's velocity is with respect to the target velocity.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "62a0721f-5638-451d-acc3-9d0ccadab91f",
                                  "requirements": "The `exorl-cheetah-velocity` evaluation task has been implemented such that at each step, the agent is assigned a reward of 0 if the agent's horizontal velocity is in the direction opposite to the one specified by the target velocity.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "899d50a9-7cf3-43f5-af4c-8b33685b0014",
                              "requirements": "A FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "2392fdea-cf2d-4915-9db4-ad39e26cdea4",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all can been evaluated on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "08e88294-c3b7-451d-98a3-3dbbd4567622",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d853a921-c743-4741-9774-cfc77395d1af",
                              "requirements": "A FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "62aa743f-e54c-4796-8ce5-951ded8b20b4",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-hint can been evaluated on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "076e55aa-699b-4835-98b4-8ca4066bab21",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "dce6b8ae-f378-48a1-94a3-dec4363c9b12",
                              "requirements": "An FB agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f3a91d55-4e45-481e-a8c6-475a418c94e7",
                                  "requirements": "Code has been implemented such that an FB agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "32648639-c6f5-47ae-bb9f-cf8a20f9a6c0",
                                  "requirements": "Code has been executed such that an FB agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "05666f05-9c23-4214-9cc6-8ed5710b4ab2",
                              "requirements": "An SF agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "381bc3f8-4e99-4d21-ba10-4eab4bb239fb",
                                  "requirements": "Code has been implemented such that an SF agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a412b218-687b-4964-9541-48a16a8f902b",
                                  "requirements": "Code has been executed such that an SF agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a165db73-23ed-4716-9320-ef3479740b8e",
                              "requirements": "An OPAL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f97d5c45-21bc-4af4-89e5-83cb27124ca1",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "915b1b79-d594-41b4-8674-f36047c03f4a",
                                  "requirements": "Code has been executed such that an OPAL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "27bf8f0b-dd83-468c-8b45-f53558e98110",
                          "requirements": "The necessary agents have been evaluated on the `exorl-walker-velocity` evaluation task",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "a54260a2-5406-49c8-995c-65639e06d8be",
                              "requirements": "The `exorl-walker-velocity` evaluation task has been implemented as outlined in addendum.md and Appendix C.1",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "f8a8ff9c-16c6-4ec5-8231-0c84b6586f85",
                                  "requirements": "The `exorl-walker-velocity` evaluation task has been implemented such that the agent is evaluated on the 4 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "74f98f7f-fb30-4f2b-9c48-433396c9ea0d",
                                  "requirements": "The `exorl-walker-velocity` evaluation task has been implemented such that the average cumulative reward across the 4 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d79ab8b4-25aa-44e7-876a-3623e1b26c77",
                                  "requirements": "The `exorl-walker-velocity` evaluation task has been implemented such that at each step, the agent is assigned a reward of 1 if the agent's horizontal velocity is at least equal to the target velocity, with the reward otherwise linearly decaying towards 0 the lower the agent's velocity is with respect to the target velocity.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "65369374-24af-429d-abfb-f8034d3cda58",
                                  "requirements": "The `exorl-walker-velocity` evaluation task has been implemented such that at each step, the agent is assigned a reward of 0 if the agent's horizontal velocity is in the direction opposite to the one specified by the target velocity.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c0e296be-7da8-4964-ac3c-e367976bb759",
                              "requirements": "A FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                              "weight": 2,
                              "sub_tasks": [
                                {
                                  "id": "25b99cdd-8e28-471e-b811-737c12b68312",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all can been evaluated on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "8d884b04-b9e3-451c-8026-9c802a4b5a79",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "fe2f10e7-94d5-419e-8eec-a7a087c42ffa",
                              "requirements": "A FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0431ce4a-43e6-409c-9dd0-66f9a91a484d",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-hint can been evaluated on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ecf0ca0d-5753-44d4-a6fe-f31d3a990658",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-hint has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c0df807c-0b2e-430c-b010-0806b6c368a0",
                              "requirements": "An FB agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "978163bc-7af6-4ce9-b0c0-a890097cf1a1",
                                  "requirements": "Code has been implemented such that an FB agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e60f2dd7-99d4-447a-8011-2477425ea3ff",
                                  "requirements": "Code has been executed such that an FB agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "89362b8d-7a8e-4c05-9321-2b1c944e5366",
                              "requirements": "An SF agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "25babc37-5720-4aac-9c70-6cbc3127bebc",
                                  "requirements": "Code has been implemented such that an SF agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "7c82fe04-ca0f-44f1-84c4-88f5a16f8c16",
                                  "requirements": "Code has been executed such that an SF agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "2c3a7aa9-badf-44f8-b49e-5ed4e7086071",
                              "requirements": "An OPAL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5e391219-7b65-4545-8b89-fa68fb460079",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "4ed668ae-0b4e-454a-a486-c37bec600d23",
                                  "requirements": "Code has been executed such that an OPAL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-velocity`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "00075416-ba65-4761-9a11-d0073f671615",
                          "requirements": "The necessary agents have been evaluated on the `exorl-cheetah-goals` evaluation task",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "fee616d9-f4e4-4df3-8d5f-2a0c3f4b8017",
                              "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented as outlined in addendum.md and Appendix C.1",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "484d1b87-8cf0-4ccb-b962-424dda13c7e8",
                                  "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented such that the agent is evaluated on the 5 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9c9c3824-f636-469d-9290-ea6678e87219",
                                  "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented such that the average cumulative reward across the 5 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "cea75914-0d1a-4ece-908d-f3e106d121d7",
                                  "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented such that the goal is considered reached if an agent reaches within a distance of 0.1 from the target position.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e68e0cbb-02fd-44ca-81cd-6c32aa31d105",
                                  "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented such that the agent receives a reward of -1 at each timestep until it successfully reaches the goal.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ab4b3fb8-eef0-4264-9725-36874589938d",
                                  "requirements": "The `exorl-cheetah-goals` evaluation task has been implemented such that the \"distance\" is the euclidian distance between the current state and the target state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7304ecfb-e7cd-4d89-acc2-51459817ad5e",
                              "requirements": "A FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3b3c59cc-d09d-4ff4-b26e-f431477c49ee",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "196c3d18-16fd-4885-aaed-9356d456c254",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `cheetah` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c6a0f378-2575-4a91-b985-b5a9921ff46f",
                              "requirements": "An FB agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b01813a2-f291-421c-89e7-3759947ad902",
                                  "requirements": "Code has been implemented such that an FB agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a14a40d6-fc3e-414d-b933-0422e1be5d12",
                                  "requirements": "Code has been executed such that an FB agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "f55e4d9b-425d-42cb-a0e1-b151736a0460",
                              "requirements": "An SF agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ef21a23b-6d3f-4eb5-9ac5-70e866712286",
                                  "requirements": "Code has been implemented such that an SF agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "950e4e31-dba8-438f-a3c2-22d88af6d61b",
                                  "requirements": "Code has been executed such that an SF agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "05ffed62-883c-4d78-95be-aea6ef2800ac",
                              "requirements": "An OPAL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "11ad2689-7b95-4fff-9911-0e214be06223",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a465ea35-ecc3-4b6a-a8f6-415a9283f42d",
                                  "requirements": "Code has been executed such that an OPAL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3049944a-7e4c-49e5-a38f-c48218bd7a7a",
                              "requirements": "A GC-IQL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3421320a-fcd2-4cb6-8194-eef5b09366e1",
                                  "requirements": "Code has been implemented such that an GC-IQL agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "39e51d18-ab26-49d6-8c50-84409d2f2c55",
                                  "requirements": "Code has been executed such that an GC-IQL agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "11f03bba-2fc4-4606-9875-1c9af81f51bd",
                              "requirements": "A GC-BC agent trained on the `cheetah` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-cheetah-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "608692e5-818e-4e2f-bf13-d563dd219ad8",
                                  "requirements": "Code has been implemented such that a GC-BC agent trained on the `cheetah` (RND) dataset can been evaluated on `exorl-cheetah-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "0020c065-4c18-4969-a23e-00c4b66b7fc7",
                                  "requirements": "Code has been executed such that a GC-BC agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a74fafb1-d5af-449f-9d8d-b4f555d14d68",
                          "requirements": "The necessary agents have been evaluated on the `exorl-walker-goals` evaluation task",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a548b643-33ab-4e91-849a-4a775b41aee0",
                              "requirements": "The `exorl-walker-goals` evaluation task has been implemented as outlined in addendum.md and Appendix C.1",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8eceb966-2eef-4959-af07-67bb229ffff5",
                                  "requirements": "The `exorl-walker-goals` evaluation task has been implemented such that the agent is evaluated on the 5 reward functions outlined in addendum.md",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "e5ee2347-7bff-4863-ab55-02203ea0e12b",
                                  "requirements": "The `exorl-walker-goals` evaluation task has been implemented such that the average cumulative reward across the 5 reward functions is used as the evaluation metric",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b640ce00-1af4-4581-a708-8f2c3ceebede",
                                  "requirements": "The `exorl-walker-goals` evaluation task has been implemented such that the goal is considered reached if an agent reaches within a distance of 0.1 from the target position.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ebff729f-fb91-4e3b-8bce-0aa7557e252c",
                                  "requirements": "The `exorl-walker-goals` evaluation task has been implemented such that the agent receives a reward of -1 at each timestep until it successfully reaches the goal.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9efc5692-574e-4b10-bf25-f5bb763bf5ea",
                                  "requirements": "The `exorl-walker-goals` evaluation task has been implemented such that the \"distance\" is the euclidian distance between the current state and the target state.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "17bd46d8-124e-4e90-ac6b-edd742d61990",
                              "requirements": "A FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "464f7d18-70e3-4d87-8fd8-e5063a4a766c",
                                  "requirements": "Code has been implemented such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "201a0d18-9eb0-455f-8bc0-18ff18858f3c",
                                  "requirements": "Code has been executed such that a FRE agent trained on the `walker` (RND) dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "498573f8-27ee-4b11-bf89-2a3d9cdad850",
                              "requirements": "An FB agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "aef4f70c-8724-4f68-812c-50bbcf3a6716",
                                  "requirements": "Code has been implemented such that an FB agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "2d89f877-2993-40c9-89be-ac60d929c46f",
                                  "requirements": "Code has been executed such that an FB agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a56b39da-fd45-420c-b6f9-c6cefe09c824",
                              "requirements": "An SF agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9266176a-45ef-44f4-bd5a-f7d5ae83285d",
                                  "requirements": "Code has been implemented such that an SF agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "7be56ff7-4b6e-42e7-90c3-6565c5dc0959",
                                  "requirements": "Code has been executed such that an SF agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "95891d00-f5f7-466b-97fb-37349ad3dc2f",
                              "requirements": "An OPAL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e31c9c07-284c-4b8b-b40b-a8114e7a6928",
                                  "requirements": "Code has been implemented such that an OPAL agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "d867fa10-2dc6-4d4a-9c6b-f48129859950",
                                  "requirements": "Code has been executed such that an OPAL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9036cffd-d60d-49b1-802d-8df6a633f104",
                              "requirements": "A GC-IQL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ab5ca13a-b32b-40de-901a-ea58ef9a42a3",
                                  "requirements": "Code has been implemented such that an GC-IQL agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "36c0aa54-3b7f-46f3-9ec0-262a84c80e8c",
                                  "requirements": "Code has been executed such that an GC-IQL agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e80cafe3-fe53-4fe3-95a3-85ae041746af",
                              "requirements": "A GC-BC agent trained on the `walker` (RND) dataset has been evaluated over 5 seeds with 20 episodes per seed on `exorl-walker-goals`",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7736cd75-7071-4b8b-bda2-4f2bca3fc4b0",
                                  "requirements": "Code has been implemented such that a GC-BC agent trained on the `walker` (RND) dataset can been evaluated on `exorl-walker-goals`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "7a49a6ad-d34a-434b-8724-7e649d7282ea",
                                  "requirements": "Code has been executed such that a GC-BC agent trained on `antmaze-large-diverse-v2` has been evaluated over 5 seeds with 20 episodes per seed on `ant-goal-reaching`",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "80997156-bab2-4fb8-93f0-4f4b5087d54d",
                      "requirements": "The necessary agents have been evaluated on the `kitchen` evaluation task",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ac9dc484-cddc-4e53-8731-71ed85288e30",
                          "requirements": "Code has been implemented such that Kitchen evaluation tasks are evaluated online, i.e. the agent to evaluate and environment are instantiated and the agent acts in the environment",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b69de9ff-27a3-4932-971b-3d892aeac920",
                          "requirements": "The `kitchen` evaluation task has been implemented as outlined in Section 5 and Appendix C.1",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "bb2371d7-b938-487a-94d5-be868b8b6d4c",
                              "requirements": "The `kitchen` evaluation task has been implemented such that the agent is evaluated on the 7 standard tasks of the Franka Kitchen environment: `bottom-burner`, `kettle`, `light-switch`, `microwave`, `slide-cabinet`, `hinge-cabinet`, `top-burner`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3fc9b62f-ca5e-4d7b-93a2-4617443cc987",
                              "requirements": "The `kitchen` evaluation task has been implemented such that the sparse rewards from the 7 standard tasks of the Franka Kitchen environment are used as the reward functions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5272c7f4-83fa-431c-819c-16e5908a450f",
                              "requirements": "The `kitchen` evaluation task has been implemented such that the average cumulative reward across the 7 standard tasks of the Franka Kitchen environment is used as the evaluation metric",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "04fa6463-5530-446d-8615-a8b82d1722ae",
                          "requirements": "A FRE agent trained on the `kitchen-complete-v0` dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "c46c155a-e146-4489-b4ea-d2aabe650195",
                              "requirements": "Code has been implemented such that a FRE agent trained on the `kitchen-complete-v0` dataset with the prior reward distribution referred to as FRE-all can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "a8265cc7-2215-4395-a8c0-44af2c0100fc",
                              "requirements": "Code has been executed such that a FRE agent trained on the `kitchen-complete-v0` dataset with the prior reward distribution referred to as FRE-all has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "82db54e3-dbbc-4b05-a2f4-e492e18f384e",
                          "requirements": "An FB agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "dafc9310-1d81-457e-9214-a55dc5ca1c33",
                              "requirements": "Code has been implemented such that an FB agent trained on the `kitchen-complete-v0` dataset can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "d367d317-48d7-4bd6-a3ed-51202ad133d1",
                              "requirements": "Code has been executed such that an FB agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "971e0104-0828-4ed8-b74f-936dfab42175",
                          "requirements": "An SF agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "09fdc2a7-a0c7-43b1-84c4-b640d2a2cd6e",
                              "requirements": "Code has been implemented such that an SF agent trained on the `kitchen-complete-v0` dataset can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5e5ad647-67d4-40d4-b4bc-2d44a5b8067b",
                              "requirements": "Code has been executed such that an SF agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f1c03e69-f171-4da4-8b55-1a4ceae9653f",
                          "requirements": "An OPAL agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a0dd5509-d456-4b47-a63b-7e8efe23e9f4",
                              "requirements": "Code has been implemented such that an OPAL agent trained on the `kitchen-complete-v0` dataset can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "bef7996b-08e8-4a85-a8df-3303765c5385",
                              "requirements": "Code has been executed such that an OPAL agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "26697913-cf69-4853-a917-d2f47ac397d2",
                          "requirements": "A GC-IQL agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "70b728c0-16d2-4395-9eaf-8e1ba2dc9431",
                              "requirements": "Code has been implemented such that a GC-IQL agent trained on the `kitchen-complete-v0` dataset can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "57109f90-2e89-4f42-a9fb-45d555079f9e",
                              "requirements": "Code has been executed such that a GC-IQL agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "02419fa6-f20e-4ba9-946e-ab486485d270",
                          "requirements": "A GC-BC agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9ae46f69-3529-4400-9acf-0debe80f5b9a",
                              "requirements": "Code has been implemented such that a GC-BC agent trained on the `kitchen-complete-v0` dataset can been evaluated on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c78015f1-6eca-4e14-8313-1ec5ef024b1d",
                              "requirements": "Code has been executed such that a GC-BC agent trained on the `kitchen-complete-v0` dataset has been evaluated over 5 seeds with 20 episodes per seed on `kitchen`",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "2f3c493a-5cde-4ff4-b4d2-d14f4322e4e1",
              "requirements": "The evaluation outcome shows or implies results that reproduce those shown in the paper in section 5.2 and Table 1.",
              "weight": 4,
              "sub_tasks": [
                {
                  "id": "2f2d443f-aadb-455b-95e0-5bff35e369f9",
                  "requirements": "The outcome of the evaluation shows that on most goal-reaching tasks (at least 3 of ant-goal-reaching, exorl-cheetah-goals, exorl-walker-goals, kitchen), the performance of the FRE agent is significantly higher than the performance of the SF and FB baselines, as discussed in section 5.2 of the paper",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "081c9d9f-838d-4ac1-9564-ea7e0d0c54ca",
                  "requirements": "The outcome of the evaluation shows that on most goal-reaching tasks (at least 3 of ant-goal-reaching, exorl-cheetah-goals, exorl-walker-goals, kitchen), the performance of the FRE agent is not significantly lower than the performance of GC-IQL and GC-BC baselines, as discussed in section 5.2 of the paper",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "6ff5f645-a29c-4705-8d80-533f8269c8d2",
                  "requirements": "The outcome of the evaluation shows that the performance of the FRE agent is competitive (either top or joint top performance) on at least 4 of (ant-directional, ant-random-simplex, ant-path-loop, ant-path-edges, ant-path-center) when compared to all of the SF, FB, GC-IQL, GC-BC and OPAL baselines, as discussed in section 5.2 of the paper",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "0a57fe73-6b37-400a-843f-53e66f8945a6",
                  "requirements": "The outcome of the evaluation shows that on average, the FRE agent significantly outperforms the OPAL agent, as discussed in section 5.2 of the paper.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "f3c64555-6880-4766-8f22-4f8e7133c0d3",
              "requirements": "The evaluation outcome shows or implies results that reproduce those shown in the paper in section 5.3 and Table 4/Figure 5.",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "5f01970b-62b9-4c59-9cc4-1b81958f506a",
                  "requirements": "The outcome of the evaluation shows that the FRE agent trained with the FRE-all prior reward distribution achieves the highest average score compared to FRE agents trained with any of {FRE-goals, FRE-lin, FRE-mlp, FRE-lin-mlp, FRE-goal-mlp, FRE-goal-lin} prior reward distributions, as discussed in section 5.3 of the paper and shown in Table 4.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "4860910a-d4bf-4d67-b599-d9ede5491eb0",
                  "requirements": "The outcome of the evaluation shows that the FRE agent trained with the FRE-all prior reward distribution either outperforms or matches the performance of FRE agents trained with any of {FRE-goals, FRE-lin, FRE-mlp, FRE-lin-mlp, FRE-goal-mlp, FRE-goal-lin} prior reward distributions on all of the individual tasks (antmaze-goal-reaching, antmaze-directional, antmaze-random-simplex, and antmaze-path-all, which is the average performance on antmaze-path-loop, antmaze-path-edges and antmaze-path-center), as discussed in section 5.3 of the paper and shown in Table 4.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "2f455b0f-b596-4bd1-a793-64aa3bc493ed",
              "requirements": "The outcome of the evaluation shows or implies that the FRE agent trained with the augmented FRE-hint prior reward distribution outperforms the FRE agent trained on the vanilla FRE prior reward distribution on all of {ant-directional, cheetah-velocity, walker-velocity} evaluation tasks, as shown in the paper in section 5.4 and Figure 6",
              "weight": 2,
              "sub_tasks": [],
              "task_category": "Result Analysis",
              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "ftrl",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "b0cb3a38-aa20-411c-9935-1cf7443bdffc",
          "requirements": "The paper \"Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem\" has been reproduced",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "4b477641-57ff-446a-919c-ab82fa4f7414",
              "requirements": "The environments are setup correctly",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "2d9c8f6b-f5fc-45e9-8922-cce54824b215",
                  "requirements": "The NetHack environment, models, training, and evaluation have been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "e38df225-da05-4d47-9eb1-fb7694e82620",
                      "requirements": "The NetHack environment has been imported from https://github.com/heiner/nle",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Environment & Infrastructure Setup"
                    },
                    {
                      "id": "5649ccb5-b36d-41b9-aeaa-7abe206a6888",
                      "requirements": "The correct necessary models for the NetHack environment have been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "7f23c5cf-25f7-4f0f-be15-c4f4e7dd0fe1",
                          "requirements": "The architecture hyperparameters for the 30M LSTM have been implemented, following Table 1",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9f015c64-e1fb-4a5c-a5d2-1cea580ab5cf",
                              "requirements": "For NetHack, the 30M LSTM uses ReLU activation functions",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "3ec91367-616b-4c59-b25b-bcc451e79d81",
                              "requirements": "For NetHack, the 30M LSTM uses a hidden dimensionality of 1738",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "acfc8769-18c6-4860-9807-1e2e3af5e0a2",
                          "requirements": "The 30M pre-trained LSTM trained by \"Scaling Laws for Imitation Learning in Single-Agent Games\" (Tuyls et al. (2023)) is available. The weights are downloaded from https://drive.google.com/uc?id=1tWxA92qkat7Uee8SKMNsj-BV1K9ENExl",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "fec855c8-9fd8-4add-8faf-9a0d95c3d44a",
                      "requirements": "The datasets used for training models in the NetHack environment have been setup",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "47b7bf81-b897-4266-8255-67f4cda736be",
                          "requirements": "The NLD-AA dataset is constructed by following the instructions from https://github.com/dungeonsdatasubmission/dungeonsdata-neurips2022",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "556adc51-d77a-415b-af74-d6ccff113bab",
                          "requirements": "8000 games of Human Monk are randomly selected from the NLD-AA dataset, to make up the dataset used for training models on NetHack",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "60ae47f9-8131-4dc2-9974-a9af6d2da1da",
                      "requirements": "The AutoAscend saves needed for evaluation have been collected",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5b808a19-e687-4331-8661-9626b1ba66a0",
                          "requirements": "The NetHack environment has been modified to support saving and loading the game",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Environment & Infrastructure Setup"
                        },
                        {
                          "id": "03f1e111-3743-444b-82d3-fe9e547ec0c5",
                          "requirements": "AutoAscend has been implemented, using the implementation from https://github.com/cdmatters/autoascend/tree/jt-nld",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "832dc72d-1813-4ffc-9f5d-c977cacb42e6",
                          "requirements": "The AutoAscend agent is executed to play the game and save the state when it reaches Level 4 of NetHack. 200 game saves satisfying such criteria are generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "c039593c-3c80-4de1-8600-83b19cc56246",
                          "requirements": "The AutoAscend agent is executed to play NetHack and save the state when it reaches the first level of Sokoban. 200 game saves satisfying such criteria are generated",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "fb366e4c-946a-43d3-82ac-98f067e4ffba",
                      "requirements": "The process for training models in the NetHack environment has been implemented",
                      "weight": 5,
                      "sub_tasks": [
                        {
                          "id": "4fa5d4b0-1c36-4794-b3f2-b7b227c67359",
                          "requirements": "APPO is used when training all models on the NetHack environment, using the implementation from https://github.com/alex-petrenko/sample-factory/",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "15d5dd79-1adf-4ad4-ad07-f8dfc06f85cb",
                          "requirements": "The training hyperparameters for NetHack have been implemented, following Table 1",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "0da1cc8b-80bd-42bc-90d8-9d8bc10faecb",
                              "requirements": "All models trained on NetHack use the correct optimizer",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4a024d31-5414-4830-a38e-99325784f61b",
                                  "requirements": "All models trained on NetHack use the ADAM optimizer",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "070f8846-402a-4074-88a1-22d84a7bbabc",
                                  "requirements": "All models trained on NetHack use $\\beta_1=0.9, \\beta_2=0.999, \\epsilon=0.0000001$ as hyperparameters for the ADAM optimizer",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "d552126e-e9bd-4561-9a7e-a94e5f80cf30",
                                  "requirements": "All models trained on NetHack use a learning rate of 0.0001",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "ce46a3bd-4824-423f-bb3f-af4d91250387",
                                  "requirements": "All models trained on NetHack use a weight decay of 0.0001",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9b430504-55c1-4c43-b066-143aecf6ec60",
                              "requirements": "All models trained on NetHack use a batch size of 128",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d982052f-e5cb-4660-94ee-81f3b2d99295",
                              "requirements": "All models trained on NetHack use a value of 4 for the global norm for gradient clipping",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "8a3bec01-9ad5-4d55-a19c-c1782fa113d0",
                              "requirements": "All models trained on NetHack use the correct APPO parameters",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8e6503da-3b9e-4609-893a-3cfd17ad6948",
                                  "requirements": "All models trained on NetHack use a clip parameter for APPO of 0.1",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "36283b09-d40b-40fd-bfaf-e158910bfa92",
                                  "requirements": "All models trained on NetHack use a clip baseline for APPO of 1.0",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4f5a51bb-9520-4013-8345-6327f9ecd149",
                                  "requirements": "All models trained on NetHack use a baseline cost (i.e. coefficient weighting the value function loss) of 1.0",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6442c7f8-5e3f-4456-be7a-ae9ccd79beae",
                                  "requirements": "All models trained on NetHack use a discounting factor of 0.999999",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "3a878514-0f60-413d-9f3c-37ace246c358",
                                  "requirements": "All models trained on NetHack that don't use knowledge retention methods have an entropy cost of 0.001",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b13f35ea-a588-48c2-a47c-34cea83d7d02",
                                  "requirements": "All models trained on NetHack don't have any reward added (negative or positive) for each time step",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "1c251dfa-625d-4c37-8d3c-496b4af0c1de",
                                  "requirements": "All models trained on NetHack have rewards clipped to +-10",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "cb0233d3-a8c5-472b-ab70-3bbf5a002dba",
                                  "requirements": "All models trained on NetHack have a reward scale of 1.0, i.e., rewards are not scaled (beyond clipping)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "491ae6e3-f83f-4cd9-97cd-cb5c6cb3e4c9",
                                  "requirements": "All models trained on NetHack use rollout size of 32",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "aa4932c4-8089-4b83-9c3b-08371f4e5854",
                          "requirements": "In NetHack, when fine-tuning any model (not when pre-training models from scratch), the model is first pre-trained for 500M environment steps where the entire model is frozen aside from the critic head",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "3ccae3d0-b213-4df7-8e4f-268d68833042",
                          "requirements": "When fine-tuning models in the NetHack environment, all encoders are frozen during the course of the training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "2285a496-0f2a-45e7-93cb-8a02edf7ac56",
                          "requirements": "The knowledge retention methods have been correctly implemented when training models in the NetHack environment",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "b13b89e2-5111-4ad5-9a6d-9bbd73a02d29",
                              "requirements": "When fine-tuning models in the NetHack environment using either elastic weight consolidation (EWC), behavioral cloning (BS), or kickstarting (KS), the entropy maximization loss is not used when computing the total loss",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "01cb2701-c047-4d3a-980c-0d8de0b2d136",
                              "requirements": "Fine-tuning models in the NetHack environment using kickstarting (KS) has been correctly implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5bd83334-172e-4ee8-a984-a7270dca5f78",
                                  "requirements": "For NetHack the Kickstarting knowledge retention method is implemented; an auxiliary loss is implemented as $\\mathcal{L}_{KS}(\\theta) = \\mathbb{E}_{s \\sim \\pi_\\mathcal{B}_\\theta} \\left[ D_{KL} \\left( \\pi_{*}(s) \\parallel \\pi_{\\theta}(s) \\right) \\right]$, where $\\pi_\\star$ is the frozen pre-trained model for NetHack from (Tuyls et al., 2023), $\\pi_\\theta$ is the current model, and $\\mathcal{B}_\\theta$ is a buffer of states",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "bc514fb5-8efd-4998-be2d-aec7057164a1",
                                  "requirements": "When fine-tuning models in the NetHack environment using kickstarting (KS), the auxiliary loss is computed on a buffer of data generated by the online policy",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "294d8931-c699-4722-8836-1979b4c6289c",
                                  "requirements": "When fine-tuning models in the NetHack environment using kickstarting (KS), the auxiliary loss is scaled by a factor of 0.5 and an exponential decay  of 0.99998 is used, where the coefficient is decayed every training step",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "326d7aba-c5c7-436c-9412-f8b601cf48fa",
                              "requirements": "Fine-tuning models in the NetHack environment using behavioural cloning (BC) has been correctly implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "1f53c387-fe05-407c-9ccf-08fcc23957c2",
                                  "requirements": "In the behavioural cloning (BC) implementation for NetHack, before training, a subset of states $\\mathcal{S}_{BC}$ is gathered on the 8000 trajectories generated by the AutoAscend algorithm, and a buffer is constructed as $\\mathcal{B}_{BC} := \\{(s,\\pi_\\star(s)) : s \\in \\mathcal{S}_{BC} \\}$, i.e., the action that the AutoAscend algorithm took on each of such states is recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Data Processing & Preparation"
                                },
                                {
                                  "id": "623ba7fa-b4a0-4a78-b384-131a85d8c018",
                                  "requirements": "In the behavioural cloning (BC) implementation for NetHack, when fine-tuning, an auxiliary loss is implemented as $\\mathcal{L}_{BC}(\\theta) = \\mathbb{E}_{s \\sim \\mathcal{B}_{BC}} \\left[ D_{KL} \\left( \\pi_{*}(s) \\parallel \\pi_{\\theta}(s) \\right) \\right]$, where $\\pi_\\star$ is the frozen pre-trained model from (Tuyls et al., 2023), and $\\mathcal{B}_{BC}$ is a buffer of data containing states from the AutoAscend algorithm",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "eb4004f8-f230-4d97-b94a-7054f8e9e0d8",
                                  "requirements": "When fine-tuning models in the NetHack environment using behavioral cloning (BC), the auxiliary loss is scaled by a factor of 2.0. No decay is used",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "61c916cd-a428-4166-a345-5e23bcf3abd2",
                              "requirements": "Fine-tuning models in the NetHack environment using elastic weight consolidation (EWC) has been correctly implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "88c2362c-c9ad-4d4d-960c-44c0f6c50343",
                                  "requirements": "For NetHack, the diagonal Fisher matrix can be computed as $F_{ii} = \\mathbb{E} [\\Delta_\\thetal(\\theta)_i^2]$, where the expectation is computed using the squared gradients of the loss wrt. each parameter over 10000 batches sampled from the NLD-AA subset of 8000 monk trajectories",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "eb31b5b8-9523-47d3-96a2-90f818fa36d4",
                                  "requirements": "For NetHack, the Elastic Weight Consolidation (EWC) knowledge retention method is implemented; the auxiliary loss is implemented as $\\mathcal{L}_{\\text{aux}} (\\theta) = \\sum_i F^i(\\theta_\\star^i-\\theta^i)^2$, where $\\theta$ is the weights of the current model, $\\theta_\\star$ is the weights of the pre-trained model from (Tuyls et al., 2023), and $F$ is the diagonal of the Fisher matrix",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "fb4230d6-f469-482c-88db-63590988a152",
                                  "requirements": "When fine-tuning models in the NetHack environment using EWC, a regularization coefficient of $2 \\cdot 10^6$ is used",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d0fc7e3c-6ee4-4e34-b46c-8eb28b783748",
                              "requirements": "For the NetHack environment, the knowledge retention methods are not applied to the parameters of the critic",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "baecc3c2-5507-4efa-8fe3-98daeacbb19d",
                      "requirements": "The evaluations required to replicate the results related to the NetHack experiments have been implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e31bc54b-fc4e-417d-92d1-7c344e28e925",
                          "requirements": "For the experiments in Section 4 related to NetHack, the average return for a method that has been trained for N steps is computed as the average return over all steps in the trajectory",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d63bf606-7095-470e-bb04-cd401e82ca9e",
                          "requirements": "When evaluating an agent on NetHack, the agent is rolled out until 1) it dies, 2) 150 steps are taken without progress being made, or 3) 100k steps are taken",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "506f55fb-2d28-437f-b8cd-0452b3494fb5",
                          "requirements": "For the experiments in Section 4 related to NetHack, the maximum dungeon level achieved over the course of training is recorded",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1a042a11-2efa-4959-a84e-04c75d2385f1",
                          "requirements": "For the experiments in Section 5 related to NetHack, when training models, the average return from Level 4 is computed throughout training",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b3967331-d908-4027-8f7b-ca21bc84cdd9",
                              "requirements": "For the experiments in Section 5 related to NetHack, to compute the Level 4 evaluation, the model is evaluated on each of the 200 saves generated by AutoAscend by loading each game (running the agent where the AutoAscend agent finished) and computing the score the model achieved on top of the AutoAscend agent's score. The average score across the 200 game saves is computed as the average return",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "14de6420-98b4-44d7-b5cb-dce7cce2bda3",
                              "requirements": "For the experiments in Section 5 related to NetHack, the average return from Level 4 is computed every 25 million training steps",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8ce6899e-c902-463c-8e77-59339326e1f7",
                          "requirements": "For the experiments in Section 5 related to NetHack, when training models, the average Sokoban score is computed throughout training",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b1075dca-9054-4829-948a-55a15ce059cf",
                              "requirements": "For the experiments in Section 5 related to NetHack, to compute the Sokoban score (number of filled pits), the model is evaluated on each of the 200 saves by loading each game (running the agent where the AutoAscend agent finished) and computing the score the model achieved on top of the AutoAscend agent's score (number of filled pits). The average score across the 200 game saves is computed as the Sokoban score",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c1894983-c61c-49b3-8058-7b21e4a7cbfc",
                              "requirements": "For the experiments in Section 5 related to NetHack, the average Sokoban score (number of filled pits) is computed every 25 million training steps",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "eec5335a-e1e6-4073-90a2-d2044c1c9b9a",
                  "requirements": "The Atari environment, models, training, and evaluation for Montezuma's Revenge have been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "d8ea9cf5-62c3-4c5a-8a87-7cbe3b1da390",
                      "requirements": "The Montezuma's Revenge environment has been imported from https://github.com/jcwleo/random-network-distillation-pytorch",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Environment & Infrastructure Setup"
                    },
                    {
                      "id": "bb8f2b81-bb76-44ff-80e3-6b7e2f828432",
                      "requirements": "The models used in the Montezuma's Revenge environment have the correct architecture",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "44ecfe05-4fdd-4d47-8eef-2ffae202e802",
                          "requirements": "All models for the Montezuma's Revenge environment are based on the architecture from https://github.com/jcwleo/random-network-distillation-pytorch",
                          "weight": 2,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "5a67161e-54c8-47a9-90b6-97161b2f9e7e",
                          "requirements": "The models trained on the Montezuma's Revenge environment use Random Network Distillation (RND) for training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "3ab393d2-ea35-4823-a8e3-cd9cbad6666b",
                          "requirements": "The models trained on the Montezuma's Revenge environment receive and return vectors of size 512 for both the target network and prediction network",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "8a369c7a-1a75-4d42-8f4c-2d510eb6b6f3",
                      "requirements": "The models used in the Montezuma's Revenge environment are trained correctly",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "14dc7245-8122-4df9-b30e-efcf93e882de",
                          "requirements": "The models trained on the Montezuma's Revenge environment use PPO for training, using the implementation from https://github.com/jcwleo/random-network-distillation-pytorch",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "c8a1ac33-c85d-47d6-8890-3fca8328de35",
                          "requirements": "The models trained on the Montezuma's Revenge environment use the correct hyperparameters, following Table 2",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ffd1c5e2-0b87-480c-ac39-85b225ef7c59",
                              "requirements": "All models trained on Montezuma's Revenge have a maximum of 4500 steps per episode",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "27a87bc3-3016-4fe9-83a5-fe1bbeae2673",
                              "requirements": "All models trained on Montezuma's Revenge have the \"ExtCoef\" hyperparameter set to 2.0",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4db385ef-36aa-4f00-8574-6bff77eb3f1e",
                              "requirements": "All models trained on Montezuma's Revenge use a learning rate of 1e-4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "47d6c57d-69b4-45c3-be5f-2a037190fe08",
                              "requirements": "All models trained on Montezuma's Revenge have the \"NumEnv\" hyperparameter set to 128",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "54d5e6d1-ad76-40a5-b820-da6090af0410",
                              "requirements": "All models trained on Montezuma's Revenge have the \"NumStep\" hyperparameter set to 128",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "09160858-4969-4b69-9d5d-eadb12ab9eac",
                              "requirements": "All models trained on Montezuma's Revenge have the \"Gamma\" hyperparameter set to 0.999",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4b6ae9b0-43ff-4197-8726-0af7cd3c48a8",
                              "requirements": "All models trained on Montezuma's Revenge have the \"IntGamma\" hyperparameter set to 0.99",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a644cd26-5450-4c36-85d0-18dac6ece999",
                              "requirements": "All models trained on Montezuma's Revenge have the \"Lambda\" hyperparameter set to 0.95",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "2d29420f-dbf2-4be3-8b02-fd0729cbd5bc",
                              "requirements": "All models trained on Montezuma's Revenge have the \"StableEps\" hyperparameter set to 1e-8",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "1cc11bdb-3f62-45bb-9017-c6e1154fe637",
                              "requirements": "All models trained on Montezuma's Revenge have the \"StateStackSize\" hyperparameter set to 4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "23a7b10f-0515-4452-931f-6ab3d31329d9",
                              "requirements": "All models trained on Montezuma's Revenge have the \"PreProcHeight\" hyperparameter set to 84",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "45974989-8788-4468-a03c-757a73d63e4f",
                              "requirements": "All models trained on Montezuma's Revenge have the \"PreProcWidth\" hyperparameter set to 84",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4f895e10-afc4-4b14-b7dc-a8fd5571a32a",
                              "requirements": "All models trained on Montezuma's Revenge have the \"UseGAE\" hyperparameter set to True",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "89f5dfe3-8387-418b-aeed-f789c95f9825",
                              "requirements": "All models trained on Montezuma's Revenge have the \"UseNorm\" hyperparameter set to False",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "9bfe3114-7f95-4b73-ab28-12df6f9676b6",
                              "requirements": "All models trained on Montezuma's Revenge have the \"UseNoisyNet\" hyperparameter set to False",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "71da356d-1436-45df-b3a1-2a482e0a73eb",
                              "requirements": "All models trained on Montezuma's Revenge have the \"ClipGradNorm\" hyperparameter set to 0.5",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "279302d4-54b1-424e-98ba-2f790bd0ab64",
                              "requirements": "All models trained on Montezuma's Revenge have the \"Entropy\" hyperparameter set to 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "4724cd08-fcc4-4bc1-8645-465a41e183d2",
                              "requirements": "All models trained on Montezuma's Revenge are trained for 4 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "f9554ef5-802d-48c4-a161-2f6965e57983",
                              "requirements": "All models trained on Montezuma's Revenge have a mini-batch size of 4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "31b9787f-9fd4-4687-9309-9f06eb27bc01",
                              "requirements": "All models trained on Montezuma's Revenge have the \"PPOEps\" hyperparameter set to 0.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "7c799a96-3e8c-4df1-a7ad-35526aa1bc9c",
                              "requirements": "All models trained on Montezuma's Revenge have the \"IntCoef\" hyperparameter set to 1.0",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "74d5a083-6501-4642-98c2-c4568a8a3bba",
                              "requirements": "All models trained on Montezuma's Revenge have the \"StickyAction\" hyperparameter set to True",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "be7338b0-6e3d-45b5-be9c-62c0467b41c0",
                              "requirements": "All models trained on Montezuma's Revenge have the \"ActionProb\" hyperparameter set to 0.25",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "1c2646cd-c049-4b90-88ff-a30f2695f361",
                              "requirements": "All models trained on Montezuma's Revenge have the \"UpdateProportion\" hyperparameter set to 0.25",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "189af3f8-0c41-4606-9375-e452b01c3c75",
                              "requirements": "All models trained on Montezuma's Revenge have the \"LifeDone\" hyperparameter set to False",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "fbaf9172-6713-4024-9c12-50c3ade3689c",
                              "requirements": "All models trained on Montezuma's Revenge have the \"ObsNormStep\" hyperparameter set to 50",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ca6edffa-53a0-4ed1-bbb5-8d3c18ee135c",
                          "requirements": "For constructing the dataset for training the \"pre-trained\" baseline for Montezuma's Revenge environment, 500 trajectories are sampled from a pre-trained PPO agent with RND that has achieved an episode cumulative reward of around 7000 and has been pre-trained from scratch (not using existing pre-trained weights)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Data Processing & Preparation"
                        },
                        {
                          "id": "728b9b1a-2798-458b-a679-67b09c94a1a1",
                          "requirements": "The knowledge retention methods have been correctly implemented when training models in the Montezuma's Revenge environment",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "a6ed1e61-c7e6-49e7-ab24-cdc6fa3d947f",
                              "requirements": "Fine-tuning models in the Montezuma's Revenge environment using behavioural cloning (BC) has been correctly implemented; an auxiliary loss is implemented as $\\mathcal{L}_{BC}(\\theta) = \\mathbb{E}_{s \\sim \\mathcal{B}_{BC}} \\left[ D_{KL} \\left( \\pi_{*}(s) \\parallel \\pi_{\\theta}(s) \\right) \\right]$, where $\\pi_{\\theta}$ is the current model, $\\pi_\\star$ is the pre-trained model, and $B_{BC}$ is a buffer of the 500 trajectories computed by the pre-trained PPO agent with RND that achieved an episode cumulative reward of around 7000",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "92c44d7d-4163-4951-8ca4-8d5fd4bf3de2",
                              "requirements": "Fine-tuning models in the Montezuma's Revenge environment using elastic weight consolidation (EWC) has been correctly implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c37de5ab-6e92-445f-b4a1-a50c3b07dd45",
                                  "requirements": "For Montezuma's Revenge, the diagonal Fisher matrix can be computed as $F_{ii} = \\mathbb{E} [\\Delta_\\thetal(\\theta)_i^2]$, where the expectation is computed using the squared gradients of the loss wrt. each parameter using the 500 trajectories sampled from the pre-trained PPO agent that achieved an episode cumulative reward of around 7000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "1c8fecd4-b73c-41f7-97b5-135d28466d22",
                                  "requirements": "For Montezuma's Revenge, the Elastic Weight Consolidation (EWC) knowledge retention method is implemented; the auxiliary loss is implemented as $\\mathcal{L}_{\\text{aux}} (\\theta) = \\sum_i F^i(\\theta_\\star^i-\\theta^i)^2$, where $\\theta$ is the weights of the current model, $\\theta_\\star$ is the weights of the pre-trained model, and $F$ is the diagonal of the Fisher matrix",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "4bc41c97-3296-430c-aa1c-d69d52831c9d",
                              "requirements": "For the Montezuma's Revenge environment, the knowledge retention methods are not applied to the parameters of the critic",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "21e9622d-3a74-4c45-97e0-8ba0522c0b8d",
                      "requirements": "The evaluations used in the Montezuma's Revenge environment are implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "13a214e6-97a1-48a0-92c9-c2be11afbf7b",
                          "requirements": "For the experiments in Section 4 related to Montezuma's Revenge, the average return for a method that has been trained for N steps is computed as the average return over all steps in the trajectory",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "dcff0bef-8fe9-4c37-a4de-3f5455faf10f",
                          "requirements": "In the Montezuma's Revenge environment, when starting agents in Room 7, the success rate in Room 7 is computed at achieving at least one of the following: either earn a coin as a reward, acquire a new item, or exit the room through a different passage than the one the agent entered through",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "de1df70e-cc0e-464a-a55f-1cab6b269eda",
                          "requirements": "In the Montezuma's Revenge environment, when training models, the success rate in Room 7 is computed every 5 million training steps",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "fb8ccbdb-4ade-4d2f-aa7c-0875da084142",
                  "requirements": "The MetaWorld environment, models, training, and evaluation for RoboticSequence have been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "6e7ef1e0-1814-4ad1-a619-0d315393705e",
                      "requirements": "The RoboticSequence environment is correctly defined",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "3cf52c19-88b7-4f00-b414-502c28620ad7",
                          "requirements": "RoboticSequence is defined as a Meta-World task which must complete the following sub-tasks sequentially in a single episode: use a hammer to hammer in a nail (hammer), push an object from one specific place to another (push), remove a bolt from a wall (peg-unplug-side), push an object around a wall (push-wall). If it performs these steps in the correct order, this is counted as a success, otherwise it's attempt it counted as a failure",
                          "weight": 5,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "37617d8a-54c3-4b52-878a-7650cd59ace3",
                          "requirements": "In the RoboticSequence environment, the starting positions and goal conditions are randomly sampled",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "2b588e8e-c095-4c32-baea-31e184887a08",
                          "requirements": "In the RoboticSequence environment, the Stage ID is encoded as a one-hot vector and provided to the agent",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "1b2f259d-15d1-42a7-94a4-1d037978a849",
                          "requirements": "In the RoboticSequence environment, the normalized timestep (i.e. the timestep divided by the maximal number of steps in the environment) is appended to the state vector",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "6c9f6163-b8c7-4a68-86d5-3afbd45982b2",
                          "requirements": "In the RoboticSequence environment, the maximal number of steps is defined as 200",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "4d94457b-2701-4606-8d2c-3b4d1752f004",
                          "requirements": "In the RoboticSequence environment, when the episode ends with success, the agent is provided with the \"remaining\" reward it would get until the end of the episode; if the last reward was originally $r_t$, the augmented reward is given by $r_t^\\prime = \\beta r_t (T - t)$, where $\\beta$ is defined as $1.5$, and $T$ is the maximal number of steps",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "1468553f-f209-4f42-977e-9f99c1c81d99",
                          "requirements": "In the RoboticSequence environment, the success rate during training of each sub-task can be measured",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "e63ad108-9ffa-42f9-b949-975c381157ba",
                      "requirements": "The models used in the RoboticSequence environment have the correct architecture",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "81d7289b-4160-46cd-8897-947ca8b44118",
                          "requirements": "In the RoboticSequence environment, models are trained using Soft Actor-Critic (SAC), using MLPs with 4 hidden layers and 256 neurons each are used as function approximators for the policy and Q-value function",
                          "weight": 2,
                          "sub_tasks": [
                            {
                              "id": "24ca90a0-b671-4f67-a1cb-47bae0d77f4b",
                              "requirements": "In the RoboticSequence environment, the policy and Q-value function are implemented as a 4-layer MLP with 256 neurons each",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "9e0dc336-a256-4b28-8b2b-19841db7adce",
                              "requirements": "In the RoboticSequence environment, the policy and Q-value function use Leaky-ReLU activations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "09f91c0f-88c1-42d3-b23e-35a6388a1eba",
                              "requirements": "In the RoboticSequence environment, the policy and Q-value function have layer normalization only after the first layer",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "01a729bf-31bd-421b-8057-9567fffda4b9",
                              "requirements": "In the RoboticSequence environment, the Soft Actor-Critic algorithm has been implemented",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6cb1d923-bf35-4654-a24d-62f2fa3bb33d",
                              "requirements": "In the RoboticSequence environment, for the first `start_steps` number of steps at the beginning of training the Soft Actor-Critic algorithm, the agent samples actions from a uniform random distribution over valid actions, where `start_steps` is some hyperparameter",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "819b5d8c-7bf1-4d16-bd29-3f34add3d27f",
                              "requirements": "In the RoboticSequence environment, the Soft Actor-Critic replay buffer can contain 100,000 trajectories",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "2bae6d13-5ccd-490a-8bea-7094b190976a",
                          "requirements": "In the RoboticSequence environment, when the agent suceeds or when the time limit is reached, SAC recieves a signal that the state was terminal, and bootstrapping in the target Q-value is not applied",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "8fb5f5d9-93bd-4d93-a008-040497cbf435",
                          "requirements": "In the RoboticSequence environment, the entropy coefficient in SAC is tuned automatically",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "415909bb-96be-4051-9930-167a9443a924",
                          "requirements": "In the RoboticSequence environment, a separate output head is created in the neural networks for each stage, and the stage ID information is used to choose the correct head",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "377dd263-55bd-4184-86ea-a3a9d4c98123",
                          "requirements": "In the RoboticSequence environment, the SAC critic is not regularized",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "d0a428b9-266d-47cc-b668-ca1b9186444e",
                      "requirements": "The models in the RoboticSequence environment are trained correctly",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "5f9dfb04-6792-4e95-8161-61830b0a5d50",
                          "requirements": "For the RoboticSequence environment, the training hyperparameters have been correctly implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "854e97f8-5936-47f0-b81b-5c90c00082ab",
                              "requirements": "All models trained on the RoboticSequence environment use a learning rate of $10^{-3}$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "17095f62-efed-4741-b729-9285951aa76f",
                              "requirements": "All models trained on the RoboticSequence environment use the Adam optimizer",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "8237af64-f979-4181-8958-3b68cd12390a",
                              "requirements": "All models trained on the RoboticSequence environment use a batch size of 128",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8a8f1d29-90ad-405d-a928-77d1b20fe9d7",
                          "requirements": "In the RoboticSequence environment, during fine-tuning, the SAC replay buffer its initialized with 10,000 state-action-reward tuples from the pre-trained stages using the pre-trained policy (i.e. the policy trained to convergence on the last two stages)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "4a6121d6-16b0-4e09-8d26-f130a0cb5ae7",
                          "requirements": "For the RoboticSequence environment, the knowledge retention methods have been correctly implemented",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "c9b51864-2409-436f-8814-9169d9cbc22f",
                              "requirements": "For the RoboticSequence environment, the elastic weight consolidation (EWC) knowledge retention method is implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "63316eb6-1957-4ff2-8a1d-3cb0dcde54f3",
                                  "requirements": "For the RoboticSequence environment, for the elastic weight consolidation (EWC) implementation, the diagonal of the Fisher matrix is correctly computed",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ccc41e40-5e1d-4231-af78-1caa1d293201",
                                      "requirements": "For the RoboticSequence environment, the diagonal of the Fisher information matrix $\\mathcal{I}$ can be computed as $\\mathcal{I}_{kk} = \\left( \\frac{\\delta\\mu}{\\delta\\theta_k} \\cdot \\frac{1}{\\sigma}\\right)^2 + 2 \\left( \\frac{\\delta\\sigma}{\\delta\\theta_k} \\cdot \\frac{1}{\\sigma}\\right)^2$, where $\\mu : \\mathbb{R} \\mapsto \\mathbb{R}$, and $\\sigma : \\mathbb{R} \\mapsto \\mathbb{R}$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "70f0fef8-1025-402c-8f67-f0aa7e44f4bf",
                                      "requirements": "For the RoboticSequence environment, for the elastic weight consolidation (EWC) implementation, the diagonal of the Fisher matrix is correctly computed as $F_k = \\mathbb{E}_{x \\sim \\mathcal{D}} \\mathbb{E}_{y \\sim p_{\\theta}(\\cdot | x)} \\left( \\nabla_{\\theta_k} \\log p_{\\theta_k} (y | x) \\right)^2$, where the outer expectation is approximated with a sample of 2560 examples from the replay buffer $\\mathcal{D}$, and the inner expectation is computed following the previous equation",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "bea5ee41-084b-43e3-bddd-bb8b76cd8709",
                                      "requirements": "For the RoboticSequence environment, for the elastic weight consolidation (EWC) implementation, the diagonal of the Fisher matrix is clipped so the minimal value is $10^{-5}$",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4d4773c7-db8c-48c2-8892-12c8bb57f7e2",
                                  "requirements": "For the RoboticSequence environment the Elastic Weight Consolidation (EWC) knowledge retention method is implemented; the auxiliary loss is implemented as $\\mathcal{L}_{\\text{aux}} (\\theta) = \\sum_i F^i(\\theta_\\star^i-\\theta^i)^2$, where $\\theta$ is the weights of the current model, $\\theta_\\star$ is the weights of the pre-trained model, and $F$ is the diagonal of the Fisher matrix",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "6e7fab7d-1af9-455f-ad04-d151d0e0086f",
                                  "requirements": "For the RoboticSequence environment, for the elastic weight consolidation (EWC) implementation, the actor regularization coefficient is set to 100",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5d88c498-191d-479e-a5a3-75af55c47539",
                                  "requirements": "For the RoboticSequence environment, for the elastic weight consolidation (EWC) implementation, the critic regularization coefficient is set to 0",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7969b8c7-e879-4136-9de4-2d923e8a8e29",
                              "requirements": "For the RoboticSequence environment, behavioural cloning (BC) is correctly implemented",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d77a7704-e037-4560-ab89-a0c4fb6d20e8",
                                  "requirements": "For the RoboticSequence environment, for the behavioural cloning (BC) implementation, at the end of each task during training, a subset from the SAC buffer is randomly sampled, it is labeled using the outputs of the current (trained) networks and added to a separate buffer as \"expert\" data",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "1f96ce79-377c-435f-a1ad-c101a35971fa",
                                  "requirements": "For the RoboticSequence environment, for the behavioural cloning (BC) implementation, in all tasks apart from the first and second, auxiliary loss is added to the SAC's objective to imitate the expert data; for the actor, KL divergence is used, and for the critics, the L2 loss is used (which can be derived as KL divergence between mean-parameterized Gaussian distributions).",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "13ae6f4b-61c9-4ccd-b227-47378478f165",
                                  "requirements": "For the RoboticSequence environment, for the behavioural cloning (BC) implementation, the actor regularization coefficient is set to 1",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "df3e311a-290d-4124-9bd1-be966f74d674",
                                  "requirements": "For the RoboticSequence environment, for the behavioural cloning (BC) implementation, the critic regularization coefficient is set to 0",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "101f049f-1b6b-4751-b6fc-56a4e15f70f4",
                              "requirements": "For the RoboticSequence environment, the episodic memory (EM) knowledge retention method is implemented correctly",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d7690cb7-4d51-4cf2-af8c-68c8af68d323",
                                  "requirements": "For the RoboticSequence environment, for the episodic memory (EM) implementation, the size of the replay buffer is 100k",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "c9ac831b-ac39-4645-baa2-ef5e3c5a4ba4",
                                  "requirements": "For the RoboticSequence environment, for the episodic memory (EM) implementation, when fine-tuning models transitions are sampled from both online trajectories and trajectories stored in the repay buffer",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "395a870b-8258-4e98-96a8-893c7bcc8321",
                              "requirements": "For the RoboticSequence environment, the knowledge retention methods are not applied to the parameters of the critic",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f281bf42-3bad-4653-86bc-4afdf2dacea7",
                      "requirements": "The evaluations for the RoboticSequence environment are implemented",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "47c00516-26f3-41e5-bca6-575a6505e9a0",
                          "requirements": "When a model has been trained for N steps on RoboticSequence, the success rate is computed as the average success rate over all steps in the trajectory",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4778e195-5563-45b3-b8c3-9326cae8ec3f",
                          "requirements": "When training models on RoboticSequence, the log-likelihoods under the fine-tuned policy of trajectories collected using $\\pi_\\star$ on \"push-wall\" are computed every 50 thousand training steps, where $\\pi_\\star$ is the pre-trained policy (trained to convergence on the final two tasks)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c455e8ed-8c85-45d5-99de-bf45f6a5f461",
                          "requirements": "When training models on RoboticSequence, the 2D PCA projections of the log-likelihoods under the fine-tuned policy of trajectories are collected using $\\pi_\\star$ on \"push-wall\" are computed, where $\\pi_\\star$ is the pre-trained policy (trained to convergence on the final two tasks)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "4a7478db-3563-438c-a631-e3d7b1cec3df",
              "requirements": "The results have been replicated",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "2e61a57f-9527-49cf-8782-d13221bbb527",
                  "requirements": "The necessary models have been trained on each environment",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "54b100a1-9237-4227-b560-12a5e64ee01d",
                      "requirements": "The necessary models have been trained for the NetHack environment",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2009038f-9266-4622-b14f-ac3bf4699090",
                          "requirements": "The pre-trained 30M LSTM model (Tuyls et al., 2023) is evaluated on the NetHack environment",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b51f7910-31ac-4aa3-a099-a198e7738432",
                          "requirements": "The 30M LSTM model (Tuyls et al., 2023) is initialized with random weights and pre-trained from scratch on the NetHack environment using APPO and behavioral cloning (BC) using the original pre-trained 30M LSTM model (Tuyls et al., 2023). The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "f34e4f40-2d0b-4298-a316-743b9b5844d0",
                          "requirements": "The pre-trained 30M LSTM model (Tuyls et al., 2023) is fine-tuned on the NetHack environment using APPO. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "636f6d6a-b310-4597-b1fe-7fc57a6564ed",
                          "requirements": "The pre-trained 30M LSTM model (Tuyls et al., 2023) is fine-tuned with behavioral cloning (BC) on the NetHack environment using APPO. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "64b22962-21b0-41b7-b5b8-119a025d16be",
                          "requirements": "The pre-trained 30M LSTM model (Tuyls et al., 2023) is fine-tuned with elastic weight consolidation (EWC) on the NetHack environment using APPO. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "64b28c7a-e2ba-49a6-addb-c5502ff616dd",
                          "requirements": "The pre-trained 30M LSTM model (Tuyls et al., 2023) is fine-tuned with kickstarting (KS) on the NetHack environment using APPO. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "19552c32-0a92-468b-b4f0-2bc54c512f08",
                      "requirements": "The necessary models have been trained for the Montezuma's Revenge environment",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "3b3d3de8-a0bc-4340-a437-013369856085",
                          "requirements": "The pre-trained model is initialized with random weights and pre-trained from scratch on the Montezuma's Revenge environment using PPO with RND until it achieves an episode reward around 7000",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "74684ac6-0b8b-451f-9375-5c0bcdc09571",
                          "requirements": "For the \"from scratch\" baseline, the pre-trained model is initialized with random weights and pre-trained from scratch on the Montezuma's Revenge environment using PPO with RND. The \"from scratch\" model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "402dc442-cd70-4a56-b95f-6beafa4f0da3",
                          "requirements": "For the \"pre-trained\" baseline, the pre-trained model is initialized with random weights and pre-trained from scratch on the Montezuma's Revenge environment, using using PPO with RND and behavioral cloning with 500 trajectories from the \"from scratch\" model. The\"pre-trained\" model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "832e0bdc-ffc2-413a-9f44-8db993d87b51",
                          "requirements": "The \"pre-trained\" baseline is fine-tuned on the Montezuma's Revenge environment using PPO with RND. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "9e59fb14-df00-4eba-898b-dd5723cba91e",
                          "requirements": "The \"pre-trained\" baseline is fine-tuned with behavioral cloning (BC) on the Montezuma's Revenge environment using PPO with RND. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "a7204cbc-a0d9-413f-8964-f551b8b339f2",
                          "requirements": "The \"pre-trained\" baseline is fine-tuned with elastic weight consolidation (EWC) on the Montezuma's Revenge environment using PPO with RND. The model is trained 5 separate times with 5 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "a65f9d0c-246e-4db6-bfa7-5bf72714be40",
                      "requirements": "The necessary models have been trained for the RoboticSequence environment",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "795dc510-8197-4f66-9ff2-dc0fc924af63",
                          "requirements": "For the RobiticSequence environment, the \"pre-trained\" SAC model is obtained by initializing with random weights and pre-training from scratch on the last two stages in multi-task setting (peg-unplug-side and push-wall) until convergence (i.e. 100% success rate)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "68b4ae69-d78f-48b4-aa06-fae54e63d5de",
                          "requirements": "For the RobiticSequence environment, the \"from scratch\" SAC model is obtained by initializing with random weights and pre-training from scratch on the RoboticSequence environment. The model is trained 20 separate times with 20 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "077c51ef-1a36-4e1f-b4fb-a8e689adafb6",
                          "requirements": "The pre-trained (from scratch) model is fine-tuned on the RoboticSequence environment. The model is trained 20 separate times with 20 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "9037e949-9828-4594-b5bf-32bb82df021d",
                          "requirements": "The pre-trained (from scratch) model is fine-tuned with behavioral cloning (BC) on the RoboticSequence environment. The model is trained 20 separate times with 20 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "a77dae72-76db-4f2e-8b12-e9bf65845d0c",
                          "requirements": "The pre-trained (from scratch) model is fine-tuned with elastic weight consolidation (EWC) on the RoboticSequence environment. The model is trained 20 separate times with 20 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "6dd3c5b1-a5a6-4ca9-b131-57d2e4e1a236",
                          "requirements": "The pre-trained (from scratch) model is fine-tuned with episodic memory (EM) on the RoboticSequence environment. The model is trained 20 separate times with 20 unique seeds",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9e453a32-d69d-4c6e-9a39-35437aae1a42",
                  "requirements": "The results from Section 4 have been replicated",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "e0b6b3e1-2080-4e80-b8af-57f6f7a593ee",
                      "requirements": "The results from Section 4 related to the NetHack experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "07ad38d0-dd5b-40eb-85eb-568bd0f03ffa",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that the pre-trained baseline (Tuyls et al., 2023) achieves an average return around (+-1k) 4.5k",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c6231bba-d504-491d-974d-1af400aea535",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that fine-tuning coupled with kickstarting (KS) surpasses the frozen pre-trained baseline (Tuyls et al., 2023) by the end of training, achieving an average return roughly equivalent to (+-1k) 11k",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9c5f4433-bdae-49d6-98a2-818a0ce7d96c",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that fine-tuning coupled with kickstarting (KS) achieves the highest average return at the end of training compared to all other methods",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1aeb1f08-19c1-42a2-b919-dfe45fdc2276",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that fine-tuning the pre-trained baseline (Tuyls et al., 2023) results in an average return of 1k by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7516943c-f5e0-45fd-ae07-6fd5415cf9ad",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that fine-tuning coupled with behavioral cloning (BC) achieves the second highest average return at the end of training compared to all other methods",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b9a9dcfc-69cd-4bca-93f3-41e53fee223e",
                          "requirements": "The recorded metrics for the NetHack experiments in Section 4 show that fine-tuning coupled with elastic weight consolidation (EWC) achieves an average return similar to the frozen  pre-trained baseline by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "45c909a4-75fc-4c43-94a6-9cfd055979e5",
                      "requirements": "The results from Section 4 related to the Montezuma's Revenge experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2176d442-e673-4c06-ac7f-921ea8a3004c",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that fine-tuning coupled with behavioural cloning (BC) achieves an average return around 6000 by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ca63a2e9-64de-4cc1-b6b3-dbce2f6e9c95",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that all methods fine-tuning coupled with behavioural cloning (BC), vanilla fine-tuning, and fine-tuning coupled with elastic weight consolidation (EWC) achieve an average return higher than the pre-training from scratch baseline by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "637c9dff-84db-425f-b2c8-d039e9bfc072",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that the average return converges around 5e7 steps for fine-tuning coupled with elastic weight consolidation (EWC)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9defdebd-f79f-4dc1-b5e7-335241c8d911",
                      "requirements": "The results from Section 4 related to the RoboticSequence experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "290e0d26-dd99-4fe6-b85a-46867726c2f4",
                          "requirements": "The recorded metrics for the RoboticSequence experiments in Section 4 show that fine-tuning coupled with behavioural cloning (BC) achieves a success rate similar to fine-tuning coupled with episodic memory (EM) by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "3413b8ea-1a06-4512-a074-d22f567b6d84",
                          "requirements": "The recorded metrics for the RoboticSequence experiments in Section 4 show that both fine-tuning coupled with behavioural cloning (BC) and fine-tuning coupled with episodic memory (EM) achieve a success rate higher than all other methods by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b483620e-492e-4646-a088-66f65afec59e",
                          "requirements": "The recorded metrics for the RoboticSequence experiments in Section 4 show that fine-tuning coupled with elastic weight consolidation (EWC) achieves a success rate higher than vanilla fine-tuning by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e28e4430-9d22-4539-ab35-2a8fa9c95240",
                          "requirements": "The recorded metrics for the RoboticSequence experiments in Section 4 show that vanilla fine-tuning achieves a success rate similar to pre-training from scratch by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "2bcf4f7f-f91f-404e-b558-7c63c6b6ae2b",
                          "requirements": "The recorded metrics for the RoboticSequence experiments in Section 4 show that fine-tuning coupled with behavioural cloning (BC) achieves a success rate of around 0.8 at 1e6 steps, then plateaus at 0.8 success rate until the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "80a06d8c-2407-49b2-bdb9-c2f67b61a5d6",
                  "requirements": "The results from Section 5 have been replicated",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "22f991b1-c8a5-4f01-a813-d6b1e95c5300",
                      "requirements": "The results from Section 5 related to the NetHack experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "c8dea5ae-aa69-447b-a3dc-b7bb7db7d394",
                          "requirements": "The recorded metrics show that the results from Section 5 related to the NetHack experiments on maximum dungeon level achieved have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ee8c8b60-c658-4e6c-b85f-401d69482295",
                              "requirements": "The recorded metrics show that fine-tuning with kickstarting (KS) is significantly more likely to visit later dungeon levels than the pre-trained policy",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f552f42a-8ccc-42c6-9946-995584a9aee9",
                              "requirements": "The recorded metrics show that AutoAscend is significantly more likely to visit later dungeon levels than fine-tuning with kickstarting (KS)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "6745a623-ede4-4e25-b7c5-eb40c5e39a83",
                          "requirements": "The recorded metrics show that the results from Section 5 related to the NetHack experiments on performance from Level 4 have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "46d4aab1-ef64-4c99-9c3b-47ef97551bd1",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that both fine-tuning coupled with kickstarting (KS) and fine-tuning coupled with behavioral cloning (BC) achieve a higher performance from Level 4 (average return from level 4) than the frozen pre-trained baseline (Tuyls et al., 2023) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3391c6e9-9821-4c25-98a8-c44dafe8b926",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that fine-tuning coupled with elastic weight consolidation (EWC) achieves a higher performance from Level 4 (average return from level 4) roughly equivalent to the frozen pre-trained baseline (Tuyls et al., 2023) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "60d7694f-b063-4fee-8a87-7bba5db7db94",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that both vanilla fine-tuning and pre-training from scratch achieve a lower performance on Level 4 (average return from level 4) than the frozen pre-trained baseline (Tuyls et al., 2023) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cb4c8e7f-e089-4271-8b3b-a1b7f7b952e1",
                          "requirements": "The recorded metrics show that the results from Section 5 related to the NetHack experiments on Sokoban score have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "7a1c8f49-1828-4188-bda3-da0e9a7c4d8d",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that fine-tuning coupled with behavioral cloning (BC) achieves an average Sokoban score roughly equivalent to frozen pre-trained baseline (Tuyls et al., 2023) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7921c7e8-9ef7-43ec-b716-b448998cda52",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that both fine-tuning coupled with kickstarting (KS) and fine-tuning coupled with elastic weight consolidation (EWC) achieve an average Sokoban score lower than the frozen pre-trained baseline (Tuyls et al., 2023) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "6b8bbb64-94b1-421b-87a8-a925f2727177",
                              "requirements": "The recorded metrics for the NetHack experiments in Section 5 show that both vanilla fine-tuning and pre-training from scratch achieve an average Sokoban score roughly equivalent to 0.1 (+-0.1) by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "60b05283-f67c-43d9-961b-be268f4810df",
                      "requirements": "The results from Section 5 related to the Montezuma's Revenge experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "deb0db6c-d6b5-4103-9a8b-3f1817db4da1",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that vanilla fine-tuning achieves the lowest success rate in Room 7 compared to all other methods by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c075713f-b928-4810-99c3-1e37b282c61f",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that the methods fine-tuning coupled with behavioural cloning (BC) and fine-tuning coupled with elastic weight consolidation (EWC) achieve a success rate in Room 7 lower or roughly equivalent to the pre-trained baseline by the end of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "91e46a34-9df9-4f0f-a355-464086e8d264",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that the methods fine-tuning coupled with behavioural cloning (BC) and fine-tuning coupled with elastic weight consolidation (EWC) have a fairly constant success rate in Room 7 throughout training, rarely fluctuating more than 0.75+-0.10",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b69054fc-82e8-408b-aff8-29a11c161bc3",
                          "requirements": "The recorded metrics for the Montezuma's Revenge experiments in Section 4 show that the success rate in Room 7 of vanilla fine-tuning falls to roughly 0.55 after 2e7 steps of training",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "b40dd37e-d239-4f9e-a9f7-a8ece3fdc7ef",
                      "requirements": "The results from Section 5 related to the RoboticSequence experiments have been replicated",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "7a23252a-4c95-45f3-b627-e132e7a64a38",
                          "requirements": "The recorded metrics show that the results from Section 5 related to the RoboticSequence experiments on evaluating success rate for each sub-task over training have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a8b6b1ec-47b0-4fe8-915b-7b8c0b38890e",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that all training methods (apart from the pre-trained frozen baseline) achieve a success rate around or above 90% for the hammer sub-task within 1e6 steps, and maintain a success rate around or above 90% for the hammer sub-task for the remaining course of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4870459d-7c84-4688-9167-e80f10ade926",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that all training methods (apart from the pre-trained frozen baseline) achieve a success rate around or above 80% for the push sub-task by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9586bf60-aa4e-43f0-81da-d26753840164",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that all training methods (apart from the pre-trained frozen baseline and pre-training from scratch) learn faster than the pre-training from scratch method for the push sub-task",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "463556ff-577e-4cce-997e-040c38895134",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with behavioural cloning (BC) doesn't have a success rate under 90% for the peg-unplug-side sub-task over the course of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "063cde22-1f33-4917-8a50-1efc29f9b2dd",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with episodic memory (EM) achieves a success rate <20% within 1e6 steps of training for the peg-unplug-side sub-task, then the success rate increases to around or above 90% by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            },
                            {
                              "id": "5f3570bd-9a40-4bd8-b5cb-ad43be18482c",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with elastic weight consolidation (EWC) achieves a success rate <65% within 1e6 steps of training for the peg-unplug-side sub-task, then the success rate increases to around or above 90% by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "98f86761-deff-4bcd-bd44-09e4981986cc",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with behavioural cloning (BC) doesn't have a success rate under 90% for the push-wall sub-task over the course of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c2d77e0d-1af8-41da-8512-79fbd2386228",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with episodic memory (EM) achieves a success rate <10% within 1e6 steps of training for the push-wall sub-task, then the success rate increases to around or above 85% by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "720064ae-29b7-4f28-bd99-5496e7579358",
                              "requirements": "The recorded metrics for the RoboticSequence experiments in Section 5 show that the fine-tuning coupled with elastic weight consolidation (EWC) achieves a success rate <50% within 1e6 steps of training for the push-wall sub-task, then the success rate increases to around or above 60% by the end of training",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ccb2f396-1ee4-4afe-8add-a108b6f4c47b",
                          "requirements": "The recorded metrics show that the results from Section 5 related to the RoboticSequence experiments on visualising log-likelihoods on push-wall over training have been replicated",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "18e0442a-b3e1-4871-8fc7-e70a5f3bdee5",
                              "requirements": "The recorded metrics show that the success rate on the \"push-wall\" task of the fine-tuned policy on RoboticSequence rapidly drops at the start of training, going to a success rate of almost 0 after 100k steps",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "cfafddf9-f5a1-4bec-bab3-c131ee9b3cf6",
                              "requirements": "The recorded metrics show that the success rate on the \"push-wall\" task of the fine-tuned policy on RoboticSequence recovers after around 4M steps; by 4M steps the success rate is above >0.8",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f7eb45e0-800c-4acc-92f5-7b95d6806545",
                              "requirements": "The computed PCA projections of the fine-tuned policy on RoboticSequence demonstrates that the model forgets the initial solution and is unable to recover it",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Result Analysis",
                              "finegrained_task_category": "Logging, Analysis & Presentation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "lbcs",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "79226778-ec1a-4a64-b878-f67193180d3d",
          "requirements": "The core contributions of the paper \"Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints\" have been reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "640d0bf7-ec10-4426-b0cf-55a59b05e2fb",
              "requirements": "The relevant datasets necessary for the experiments in the paper have been setup such that they can be accessed and used",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "e42431df-d224-4d47-a7bc-3ea940d49974",
                  "requirements": "F-MNIST has been setup such that it can be accessed and used",
                  "weight": 6,
                  "sub_tasks": [
                    {
                      "id": "b7f0907f-9784-4075-88bf-e0ecbd9b08e6",
                      "requirements": "Code has been implemented for such that F-MNIST can be obtained or streamed without API keys or credentials",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "678e11f2-5b55-45d3-8b90-f72c4015d1c1",
                      "requirements": "Code has been executed such that F-MNIST has been succesfully obtained or streamed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "dc8d3ae3-193d-43ac-bdb3-b1f6df1af3e5",
                  "requirements": "SVHN has been setup such that it can be accessed and used",
                  "weight": 4,
                  "sub_tasks": [
                    {
                      "id": "794e8775-9a23-4238-93fb-2fdfe275e61d",
                      "requirements": "Code has been implemented for such that SVHN can be obtained or streamed without API keys or credentials",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "86398fb4-1e7a-44cd-85dd-2e804c8ea9f2",
                      "requirements": "Code has been executed such that SVHN has been successfully obtained or streamed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "0e69e43c-f127-4590-883c-378ded29f4d3",
                  "requirements": "CIFAR-10 has been setup such that it can be accessed and used",
                  "weight": 3,
                  "sub_tasks": [
                    {
                      "id": "fc3a56cf-3dc8-4a81-be6f-7dce5d9b9878",
                      "requirements": "Code has been implemented for such that CIFAR-10 can be obtained or streamed without API keys or credentials",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "87fc7a9a-c2b8-4c0d-9470-19a083fbbae3",
                      "requirements": "Code has been executed such that CIFAR-10 has been successfully obtained or streamed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "26daae65-c335-4e4d-b82b-d7adb065d686",
                  "requirements": "MNIST-S has been setup such that it can be accessed and used",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "65fdb2a0-c7b7-4034-89f9-349ba45e498b",
                      "requirements": "Code has been implemented for such that MNIST can be obtained or streamed without API keys or credentials",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "8412c41c-9bb1-44a2-8d75-ef8d2f89ed57",
                      "requirements": "Code has been executed such that MNIST has been successfully obtained or streamed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "d4190392-7b1a-47d1-8cad-bbbbe9612882",
                      "requirements": "Code has been implemented such that MNIST-S can be formed by randomly sampling 1000 points from the MNIST dataset",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Data Processing & Preparation"
                    },
                    {
                      "id": "afd013da-3b47-4ef9-b61b-5022caee2ee3",
                      "requirements": "Code has been executed such thath MNIST-S has been succesfully formed",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Data Processing & Preparation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "a9f551b4-7798-43a6-96b9-269ff570bd78",
              "requirements": "The results of Figure 1 have been reproduced",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "91dcd283-365b-4dfe-a6cb-44caec7bd906",
                  "requirements": "Equations (3) and (4) have been individually optimized in a bilevel coreset selection loop for a CNN training on a random subset of MNIST (such as MNIST-S), and the f_1 and f_2 objectives have been measured for various values of k",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ec47f2db-70b3-45e8-9c8b-9b3c0be7be84",
                      "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented as outlined in Appendix C.3",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "856e2447-bd98-487e-8623-89b2468e27cd",
                          "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented such that it is made of two blocks of convolution, as outlined in Appendix C.3",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "485dae39-9025-43e6-9905-526b6ce79a31",
                          "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented such that dropout is used, as outlined in Appendix C.3",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c4c39def-a7dd-4e3d-9328-55374d27f723",
                          "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented such that max-pooling is used, as outlined in Appendix C.3",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "0c0a274e-1344-47f6-adcf-82b7a5d19123",
                          "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented such that ReLU is used, as outlined in Appendix C.3",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "0c0a274e-1344-47f6-adcf-82b7a5d19156",
                          "requirements": "For evaluating equations (3) and (4), a convolutional neural network has been implemented such that it matches the architecture of Zhou et al, 2022, outlined in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "b01c7e33-ecf1-41b6-8431-ad165554569f",
                      "requirements": "For evaluating equations (3) and (4), code has been implemented such that a CNN can be trained on a random subset of MNIST (such as MNIST-S), as outlined in Appendix C.3",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "00ea5742-ef4f-43ec-b1e8-751a886d9808",
                          "requirements": "For evaluating equations (3) and (4), code has been implemented such that a CNN can be trained on a random subset of MNIST (such as MNIST-S) using the SGD optimizer",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "8bbd7a69-5314-4776-9c9c-a753edd30a10",
                          "requirements": "For evaluating equations (3) and (4), code has been implemented such that a CNN can be trained on a random subset of MNIST (such as MNIST-S) using the SGD optimizer with a learning rate of 0.1",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "210a9a60-7fc2-42f6-9ee6-369ccc4355b8",
                          "requirements": "For evaluating equations (3) and (4), code has been implemented such that a CNN can be trained on a random subset of MNIST (such as MNIST-S) using the SGD optimizer with a momentum of 0.9",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "30959f61-69dd-44c1-8865-d06dca2a6036",
                          "requirements": "For evaluating equations (3) and (4), code has been implemented such that a CNN can be trained on a random subset of MNIST (such as MNIST-S) for 100 epochs",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "5a9f820a-24ab-4aa5-93b6-18a5ea36db2f",
                      "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3) for various values of k",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "56e722eb-4c84-496a-9084-66d4308f85e2",
                          "requirements": "Code has been implemented for running coreset selection using equation (3) on a CNN training on a random subset of MNIST (such as MNIST-S) for various values of k",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9e96c75f-270f-47bb-bc5b-39528a58897d",
                              "requirements": "Code has been implemented such that bilevel coreset selection (as roughly outlined in the addendum) can be run using equation (3) as the outer objective to be minimized",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "cf6679e1-f445-4c7b-a127-2edabd88fdf1",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (3) as the outer objective, the minimization of equation (3) can be done via Adam with a learning rate of 2.5 and a cosine scheduler.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "dfc8c3a3-4bdf-449b-bdb2-78449eb2e53b",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (3) as the outer objective, f_1(m) can be measured over the outer loop iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4e6b9f3b-c143-4ae9-ba05-95d18e125823",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (3) as the outer objective, f_2(m) can be measured over the outer loop iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "80ef50a8-0a7a-40f2-bb41-0eb0d6de8024",
                              "requirements": "Code has been implemented such bilevel coreset selection using equation (3) as the outer objective can be been run for a CNN training on a random subset of MNIST (such as MNIST-S)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a6f5a5d1-ccd1-44cb-9ae4-580166e07800",
                              "requirements": "Code has been implemented such that bilevel coreset selection using equation (3) as the outer objective can be run with a pre-optimization coreset size of $k \\in {100, 150, 200, 250}$",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "27887ca9-94f8-4da8-bfa6-c09d6dbdae9b",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (3) as the outer objective can be run with a pre-optimization coreset size of $k =100$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "704d6f7c-2eaf-48f2-9be5-c746157acd27",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (3) as the outer objective can be run with a pre-optimization coreset size of $k =150$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5c434a79-37e9-41bf-b17d-33dd2435b213",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (3) as the outer objective can be run with a pre-optimization coreset size of $k =200$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "3b68bd83-01be-49d4-8348-6182825680d5",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (3) as the outer objective can be run with a pre-optimization coreset size of $k =250$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f34c2040-a1c9-44ad-8eb9-384b0f766198",
                          "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3) for various values of k",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ece1c3ee-f25d-45a2-88d8-8866d02cf8a5",
                              "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_1(m) over the outer loop iterations for various values of k",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6bfb3f92-e283-4a3c-a874-4c2f4106e4dd",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_1(m) over the outer loop iterations for k=100",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3ea1e5c4-9171-4a9a-a079-cd4d2d83cf06",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_1(m) over the outer loop iterations for k=150",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "ceb84a35-793f-4a87-b919-4022fe615a09",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_1(m) over the outer loop iterations for k=200",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "65ca9b72-9459-41ff-ac9c-5b47d4764469",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_1(m) over the outer loop iterations for k=250",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "8e22e127-b9fc-446e-95f3-8476e434d703",
                              "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_2(m) over the outer loop iterations for various values of k",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "44fa4c45-835c-4fa3-8dfa-096dd6b62232",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_2(m) over the outer loop iterations for k=100",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "8bc66934-a54f-402d-be95-e5dff6a07e77",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_2(m) over the outer loop iterations for k=150",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "dba7c6fa-94ec-46f2-92aa-fcdf1cc031b2",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_2(m) over the outer loop iterations for k=200",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a0026cf7-7e6a-4fe5-a062-171c6a71aff9",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (3), measuring f_2(m) over the outer loop iterations for k=250",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Method Implementation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f16d54b4-083b-4328-b78d-31acb236f491",
                      "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4) for various values of k",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "70772c4c-3126-4a77-9215-539be68be920",
                          "requirements": "Code has been implemented for running coreset selection using equation (4) on a CNN training on a random subset of MNIST (such as MNIST-S) for various values of k",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ddfb36ef-039c-4747-ae3f-51beee652a19",
                              "requirements": "Code has been implemented such that bilevel coreset selection (as roughly outlined in the addendum) can be run using equation (4) as the outer objective to be minimized",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7fd52e10-d37c-4ea8-bd93-799006bd8341",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (4) as the outer objective, the minimization of equation (4) can be done via Adam with a learning rate of 2.5 and a cosine scheduler.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "5dcb9f87-f245-403d-81bc-a487b6fb0d4a",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (4) as the outer objective, f_1(m) can be measured over the outer loop iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f561845b-edf6-43c1-a75c-2bd9a0c65a41",
                              "requirements": "Code has been implemented such that when running bilevel coreset selection using equation (4) as the outer objective, f_2(m) can be measured over the outer loop iterations",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "69b3d16f-be28-4670-a2dd-741201117771",
                              "requirements": "Code has been implemented such bilevel coreset selection using equation (4) as the outer objective can be been run for a CNN training on a random subset of MNIST (such as MNIST-S)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "cf8ec731-0d5f-406b-90ab-62e1656d9291",
                              "requirements": "Code has been implemented such that bilevel coreset selection using equation (4) as the outer objective can be run with a pre-optimization coreset size of $k \\in {100, 150, 200, 250}$",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f550d38b-aea9-43f7-8520-5c1ee8533c53",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (4) as the outer objective can be run with a pre-optimization coreset size of $k =100$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4fbc2162-80a0-4b25-b9d3-e2a5a86cf132",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (4) as the outer objective can be run with a pre-optimization coreset size of $k =150$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "80e1837d-23da-4bb8-bb70-47062c4c27d3",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (4) as the outer objective can be run with a pre-optimization coreset size of $k =200$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "8162e837-2f82-48b7-ae8d-79b3ea3d8dce",
                                  "requirements": "Code has been implemented such that bilevel coreset selection using equation (4) as the outer objective can be run with a pre-optimization coreset size of $k =250$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "dd6189f4-f5fb-49f3-8d66-e00291a70112",
                          "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4) for various values of k",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9c736978-3326-4e1a-ad8e-4af3b2df4dcf",
                              "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_1(m) over the outer loop iterations for various values of k",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "33a3e1a2-0507-4b0a-ab82-537682396981",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_1(m) over the outer loop iterations for k=100",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b17eaa14-f08a-42ff-abbe-b1affbb10b16",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_1(m) over the outer loop iterations for k=150",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "c21f452d-2e8b-4538-ac0b-2288df4a3292",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_1(m) over the outer loop iterations for k=200",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "dbc7b8e5-7628-4b12-9d89-23ea6933e2fc",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_1(m) over the outer loop iterations for k=250",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3e68147f-d7fb-492a-8381-325498beacf8",
                              "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_2(m) over the outer loop iterations for various values of k",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4a29a0b6-1e6f-43b4-994e-9bf0682d805a",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_2(m) over the outer loop iterations for k=100",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "ba2aed1d-404d-40f8-8964-b7c1f01275be",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_2(m) over the outer loop iterations for k=150",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "c28fad3d-b7d8-49ce-a9c4-dee20298774e",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_2(m) over the outer loop iterations for k=200",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "c69bebdc-ac02-4dcb-976d-df8c32ea3003",
                                  "requirements": "Coreset selection has been run for a CNN training on a random subset of MNIST (such as MNIST-S) using equation (4), measuring f_2(m) over the outer loop iterations for k=250",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Experimental Setup"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d1989155-208d-456b-9f46-ce8c764a75d3",
                  "requirements": "The results of Figure 1 have been reproduced",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "df0108f4-f393-45f2-b655-e564006e0548",
                      "requirements": "The results pertaining to equation (3) have been reproduced",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "201ffd17-8ded-4780-ba21-07dfa41daddd",
                          "requirements": "The f_1(m) measured when optimizing equation (3) in the outer loop shows that f_1(m) can effectively be minimized, settling on values below 2.0",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1c1d7417-df01-48b4-b088-746d9f834633",
                          "requirements": "The f_2(m) measured when optimizing equation (3) in the outer loop shows that f_2(m) roughly remains close to the predefined coreset size",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "74dc1501-1cce-485a-ab54-b181a2b893bb",
                      "requirements": "The results pertaining to equation (4) have been reproduced",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "dd7a36d8-aea2-4de1-8cfa-97fe2af69a6d",
                          "requirements": "The f_1(m) measured when optimizing equation (4) in the outer loop shows that in general f_1(m) fails to settle below values of 5.0 -- or in other words when optimizing equation (4), a worse f_1(m) is achieved compared to when optimizing equation (3).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "96cf7868-f90f-4c08-a916-48eb8e49803d",
                          "requirements": "The f_2(m) measured when optimizing equation (4) in the outer loop shows that f_2(m) drops considerably.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "35beda89-9e02-413b-a2c8-d3c79c7447ce",
              "requirements": "The relevant coreset selection methods have been implemented",
              "weight": 4,
              "sub_tasks": [
                {
                  "id": "f7d8c22a-45dd-45c9-b616-80c6130fc078",
                  "requirements": "LBCS has been implemented as outlined in Algorithm 1 and Algorithm 2, with Algorithm 2 called at step 4 of algorithm 1",
                  "weight": 8,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "63ee000c-9bfc-44e2-99b0-19a0c948b129",
                  "requirements": "The baseline methods have been implemented",
                  "weight": 5,
                  "sub_tasks": [
                    {
                      "id": "14cb47f7-0317-41ea-b58a-c1761483d051",
                      "requirements": "Uniform sampling coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "61491c86-d471-465c-9210-de2f85ad9cc9",
                      "requirements": "EL2N coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "c635a069-7d6e-4100-959b-0226f2c41b4f",
                      "requirements": "GraNd coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "5d9352f6-a6a5-4767-b208-4e01d36b0853",
                      "requirements": "Influential coreset (\"Influential\") coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "58a6b0aa-7c06-4220-bf07-ef900afefe03",
                      "requirements": "Moderate coreset (\"Moderate\") coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "15a006bd-5315-4b4b-9bb7-0cf87c732d3e",
                      "requirements": "CCS coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "22483d52-1909-4228-ae6f-04ed4b3108fd",
                      "requirements": "Probabilistic coreset (\"Probabilistic\") coreset selection has been implemented, as outlined in section 5.2, Appendix D.1 and the addendum",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "cac2163b-856c-4e4a-bcc8-b22106f80df9",
                  "requirements": "LBCS+Moderate coreset selection has been implemented as outlined in the caption of Table 5, i.e. in step 2 of Algorithm 1, the mask is initialized by running Moderate coreset rather than randomly. Algorithm 2 is used in step 4 of Algorithm 1, like in vanilla LBCS.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "cc5a86db-2d9a-49f8-b4c6-1c0aa6109391",
              "requirements": "The results of Section 5.1 have been reproduced",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "601833ac-a46f-4c82-8fc0-8b06211db8b2",
                  "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S at different initial predefined coreset sizes k and different performance compromises $\\epsilon$",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "2d2efde8-bd0a-4e37-9306-da9ab5006d10",
                      "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S at different initial predefined coreset sizes k and different performance compromises $\\epsilon$",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "d9fb1ffa-65dd-4797-9602-37f12649e545",
                          "requirements": "Code has been implemented such that when running LBCS for finding the optimal refined coreset for training a CNN on MNIST-S, f_1(m) and f_2(m) can be measured at the beginning and at the end of coreset refinement",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5ffd95a1-9f36-462d-8509-d9ef553535da",
                          "requirements": "Code has been implemented such that when running LBCS for finding the optimal refined coreset for training a CNN on MNIST-S, the run can be repeated 20 times",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "4399ad7b-f264-42c9-9512-78128813f791",
                          "requirements": "Code has been implemented such that when running LBCS for finding the optimal refined coreset for training a CNN on MNIST-S, the mean and standard deviation of f_1(m) and f_2(m) can be measured across the repeated runs",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "258a9296-800f-4802-9787-8be0e14d248a",
                          "requirements": "Code has been implemented such that when running LBCS for finding the optimal refined coreset for training a CNN on MNIST-S, the CNN described in section 5.1 can be trained on MNIST-S",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "9693ca83-3006-49aa-94fa-f952c51c2d52",
                          "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented as outlined in section 5.1",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e44839ec-b242-4831-9679-1458dab74784",
                              "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented such that it is composed of two blocks convolution, as outlined in section 5.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7162dc4d-c74d-4cbe-9497-60f05de8ff6b",
                              "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented such that it is employs dropout during training, as outlined in section 5.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "d84a8cba-27c6-44c1-88a5-21e4c72f2159",
                              "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented such that it is employs max pooling, as outlined in section 5.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "053af4e8-0b58-4415-92db-28ab7c935228",
                              "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented such that it is employs ReLU activation functions, as outlined in section 5.1",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "0c0a274e-1344-47f6-adcf-82b309d19156",
                              "requirements": "The convolutional neural network (CNN) to be trained on MNIST-S for refined coreset selection has been implemented such that it matches the architecture of Zhou et al, 2022, outlined in the addendum.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "99c1a1a0-6a5c-4d78-a67d-928ff1437f18",
                          "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 200 and different performance compromises $\\epsilon$ various performance compromises",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "8aaf15df-d092-430f-9272-f43dd879c5e6",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 200 and a performance compromise $\\epsilon$ of 0.2",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "7723ca55-64d8-4488-9be8-559ab0641319",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 200 and a performance compromise $\\epsilon$ of 0.3",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "c45b3f06-e979-4c0c-acad-32757518c7ff",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 200 and a performance compromise $\\epsilon$ of 0.4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "56c5ead8-0c31-4d7c-86ab-24141308bb40",
                          "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 400 and different performance compromises $\\epsilon$ various performance compromises",
                          "weight": 3,
                          "sub_tasks": [
                            {
                              "id": "70f2299a-61bb-4b42-a980-98e8857696d3",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 400 and a performance compromise $\\epsilon$ of 0.2",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "a78cd20e-6f40-448b-ad4c-538b100006f8",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 400 and a performance compromise $\\epsilon$ of 0.3",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "939b0cc5-716c-41bf-8ed4-1949cf47a65d",
                              "requirements": "Code has been implemented such that LBCS can be run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 400 and a performance compromise $\\epsilon$ of 0.4",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "c2ae9a0b-cb01-4c0b-a9e4-812addf87523",
                      "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 200 for various performance compromises",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "33255c05-5059-4bfb-b1ec-4eb1d2336d3c",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 200 and a performance compromise $\\epsilon$ of 0.2, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "59b52eb6-8309-4726-a6e6-cd578844a8f7",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=200$ and $\\epsilon=0.2$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "42279a41-9f85-44d8-8af3-f5d19757538c",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 200 and a performance compromise $\\epsilon$ of 0.3, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8e4d64af-2e46-43c7-8599-2d28b802f28f",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=200$ and $\\epsilon=0.3$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "dbb32fa8-5f2d-457e-b1b4-3d0f5a81f915",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 200 and a performance compromise $\\epsilon$ of 0.4, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "5ca0d99e-1e62-4fa7-822a-379f189647ab",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=200$ and $\\epsilon=0.4$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "dda94f12-2655-4457-8a0b-a22a91ae883f",
                      "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size of 400 for various performance compromises",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e7fe9f64-b931-4893-90c7-696b0a3cc257",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 400 and a performance compromise $\\epsilon$ of 0.2, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0e72e89d-c1bd-4978-8b5d-8b93744b1f0f",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=400$ and $\\epsilon=0.2$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "bcbdc185-2d7f-4498-b6c4-c6e6d08323ff",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 400 and a performance compromise $\\epsilon$ of 0.3, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "c655de7c-2f0b-4be5-b33d-404905852d8f",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=400$ and $\\epsilon=0.3$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "70cf1904-b2a1-4293-a2b1-e5d71edc4c7c",
                          "requirements": "LBCS has been run for finding the optimal refined coreset for training a CNN on MNIST-S with an initial predefined coreset size k of 400 and a performance compromise $\\epsilon$ of 0.4, measuring f_1(m) and f_2(m) at the beginning and end of the LBCS process",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "938c9740-72b3-4383-af1b-b0737e6ed905",
                          "requirements": "The LBCS experiment for the CNN trained on MNIST-S with $k=400$ and $\\epsilon=0.4$ has been repeated 20 times and the mean and standard deviation of the f_1(m) and f_2(m) metrics has been recorded across those 20 repetitions",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a3a3cfa0-6ab9-4cb6-a5a9-9b001b0a90f2",
                  "requirements": "The results of Section 5.1 have been reproduced",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "6a2c4936-cf41-4205-a4a4-30988e95980d",
                      "requirements": "The measured f_1(m) and f_2(m) show that throughout all tested configuration settings, f_1(m) and f_2(m) are lower than their initial measurement after running LBCS",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "61aadf18-4bf0-4a32-ba23-70da4bd3ae56",
                      "requirements": "The measured f_2(m) show that larger performance compromise values result in lower f_2(m) after running LBCS across all tested coreset sizes k",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "42fc1312-a959-4560-b504-3edcda58ae68",
                      "requirements": "The measured f_1(m) show that larger performance compromise values result in larger f_1(m) after running LBCS across all tested coreset sizes k, for large enough experiment numbers",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "828c131d-b0eb-4ca9-9543-aaef4373cd00",
              "requirements": "The results of Section 5.2 have been reproduced",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "c48278a0-8ce5-4b1b-9798-e75fc0d1fbd1",
                  "requirements": "Code that is agnostic to the predefined coreset size and benchmark has been implemented",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9f16dd06-fa26-4f29-8be8-2bd6edfdeaba",
                      "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the appropriate proxy network can be used",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4b9c1614-b110-4266-b790-a38d62f3765e",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST benchmark at a given predefined coreset size, a LeNet can be used as the proxy network used for coreset selection",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "e33454a1-96be-43c5-9c1c-c07d71fe4b82",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark at a given predefined coreset size, the CNN in the left column of Table 7 can be used as the proxy network used for coreset selection",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        },
                        {
                          "id": "4720bf5d-e987-41f3-9ec6-294b2182b8ee",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the CIFAR-10 benchmark at a given predefined coreset size, the CNN in the right column of Table 7 can be used as the proxy network used for coreset selection",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Experimental Setup"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "21ebce23-d1cf-449a-a1d3-272d26a94580",
                      "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 at a given predefined coreset size, when training the proxy network for coreset selection, this network can be trained using an Adam optimizer with a learning rate of 0.001",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "4400d8b6-f567-4196-9a4f-87cefb814016",
                      "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the appropriate network and parameters can be used for training and evaluation AFTER coreset selection",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "f728be43-9b1f-4eca-a892-2ebff1227f0e",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST benchmark at a given predefined coreset size, the appropriate network and parameters can be used for training and evaluation AFTER coreset selection",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "91128d33-ac3a-470e-9eb9-eb5f89d5bd12",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST benchmark at a given predefined coreset size, a LeNet can be used as the network trained after coreset selection on the selected coreset and evaluated on the F-MNIST test set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "c887b213-a774-47d0-ac4f-10b64fa866cd",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST benchmark at a given predefined coreset size, when training the LeNet on the constructed coreset, the LeNet can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a9ced9f3-9cd8-46e2-a6c8-030f88a8f49b",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST benchmark at a given predefined coreset size, when training the LeNet on the constructed coreset, the training can be run for 100 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e46272fd-fae5-40f9-aac7-21a0c261e40a",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark at a given predefined coreset size, the appropriate network and parameters can be used for training and evaluation AFTER coreset selection",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "49010e88-19e2-4155-980c-ffd60b9a23f9",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark at a given predefined coreset size, the CNN from Table 7, center column can be used as the network trained after coreset selection on the selected coreset and evaluated on the SVHM test set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "d9fef6da-92d9-47ab-944d-9c0313566485",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark at a given predefined coreset size, when training the CNN from Table 7, center column on the constructed coreset, the CNN from Table 7, center column can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "066f4dea-9ae9-4194-8201-b28974d39674",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark at a given predefined coreset size, when training the CNN from Table 7, center column on the constructed coreset, the training can be run for 100 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "5071aaa2-a5d1-497b-8584-93137e0137e6",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the CIFAR-10 benchmark at a given predefined coreset size, the appropriate network and parameters can be used for training and evaluation AFTER coreset selection",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "7852c64a-2b7c-477c-8e99-57be03a19746",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the CIFAR-10 benchmark at a given predefined coreset size, a ResNet-18 network can be used as the network trained after coreset selection on the selected coreset and evaluated on the CIFAR-10 test set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d726e0e4-a665-4e42-a87f-315fb627ec13",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the CIFAR-10 benchmark at a given predefined coreset size, when training the ResNet-18 on the constructed coreset, the Resnet-18 can be trained using an SGD optimizer with a learning rate of 0.1, momentum of 0.9, and a cosine scheduler.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "631a8052-395e-4017-bf09-b691a316e664",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the CIFAR-10 benchmark at a given predefined coreset size, when training the ResNet-18 on the constructed coreset, the training can be run for 200 epochs",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "7272acea-7aa8-4304-97ed-8a21b645cfea",
                      "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the test accuracy of the model trained on the selected coreset and evaluated on the benchmark test set can be measured",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a8b64156-202c-45d0-ae04-ced11538ccf7",
                  "requirements": "The results shown in Table 2 and Figure 3 have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "5660973a-bc2d-4211-96d7-4e62f117686a",
                      "requirements": "LBCS and the 7 Baselines have been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "425851c2-780d-468a-ae15-803153bf1852",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the test accuracy per coreset data point of the model trained on the selected coreset and evaluated on the benchmark test set can be measured",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8051df14-b42c-467a-93bb-12fe3363938e",
                          "requirements": "LBCS has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f7f7e8d6-75a2-4cbf-aaea-2bda425c9511",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the final coreset size at the end of LBCS can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "82eb4f38-01ac-4ee6-9a72-d6db11d362fd",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the outer loop can run for 500 iterations (i.e. T=500)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "b9c8e4ab-6683-42e0-b71e-8764911f24de",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "0bad0fc5-0a0e-4baa-8eb9-f7fe5b854583",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7bc4536f-a5ed-420e-9217-91cb86fa74fb",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "42a59dfe-33f0-4cc6-9779-c2ea5d8c0a70",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ed93fb00-0d41-4848-82c3-04b8d55e06c2",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d8fdfd13-ad7c-41c0-a537-f4d405a6c932",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5d7e83dd-dd4b-412f-85e4-c4207d7337e3",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "11a49e4e-c141-4c89-a58b-f7d08da3ee33",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4a7a77b6-5841-44e9-8583-b967554ed35e",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d45b3b32-d7fb-4d11-a578-d09d23174c65",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "be8db4b0-933f-4857-9462-6fa163cbdaff",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "75e256f1-cd66-47e7-9b70-91a71a02d5e6",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "64abb1ad-2a91-482f-ad8c-a859ecae9093",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8f7044af-dd36-4b27-bfbc-6a3bcf9a325f",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b056bd7f-3721-4601-8abb-d3475697eddd",
                              "requirements": "LBCS has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "55f7e485-04c6-41df-9d43-40f79aa33b59",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4a0a2e1f-c80e-49f8-b3e2-cab8163d4e0b",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "1e62b66c-641f-4262-88c2-f47e7dc5fb14",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "7f7bcf76-a2ae-41f4-8467-79bc57240561",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ad00f370-4eb8-431f-9430-9b7a78201cd3",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0484fceb-e3b8-4ffe-9f0f-0cd563e6df1d",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e592bb51-2de0-4022-9510-e7baf4386919",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3f836077-184c-4441-8b8a-46f85ea42363",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "366c21d1-7ed7-481d-9c6c-7a9a39e0e129",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "57f5e6b4-ee9e-44cd-8e05-e30cd66053d1",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "743a6b10-ea76-422a-a2b8-f14d4bbe2ffc",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "21c3bced-8466-4fa2-b122-f499ccdb2d1c",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6cf72493-78ad-4df1-8709-045ebf7cdf0a",
                              "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "103aeaa5-3bd3-4d32-aa5f-dee259c8736d",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2fe7e35e-4bff-4e9e-b96f-86a3870124f0",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a38f2355-a478-4e90-83d1-bed0e802893f",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "be4bf49f-1525-4852-93bd-6c4333de6852",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a964f84c-4ab8-424a-a6e2-8ac803f60b4c",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f348dd18-a5ee-4f32-9845-d59eb52ca7e3",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c7144e12-54fa-4003-91cc-28eb1dd63920",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "66b11e89-7a31-45f3-84dd-b94f96b38d16",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e287ab0b-9112-46f8-922f-873c8f5fb7f0",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "de5638b9-abdf-49bf-8b2f-2ac109f7c780",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "42d4456d-0484-4637-8dac-4b3cb13b7f48",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4a35cef3-19cf-4c33-8119-538ffbfbdb20",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "bee2e398-aab5-4f97-8e9c-a89032e90cef",
                          "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a6c06439-876e-4cf4-98a3-64f3806ac19e",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d32b632e-7a5c-4ad8-ba71-b523263f5e60",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f58e19d8-c875-4a1f-810b-69c8d28e5fe0",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "95dc3e2e-1570-4fe6-9d46-4248cf2bfbd4",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "583d652d-e34a-4e73-acea-db71d20a8e16",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a24de89e-d186-4ad8-ad1e-5feb6393173a",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "07fd2625-f37b-4a42-b4f4-b7f782876339",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "fe9ded72-dcb9-47e9-8835-82d516fcb06c",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "22b3f642-b88e-4ee1-afba-3817b259eca9",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "afaa22ca-db66-4c1a-b57b-e4a9d3b4f278",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c72d6406-6eb5-4b73-98b5-5ace75674adb",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7f3246c5-f98c-4622-a46f-1a0bd8d05f2a",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4029e9a8-32d0-44e5-bb40-a2dca15aa5a0",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "23887de9-6f43-431c-9c4d-37ab2ab05da1",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a828995f-b5f3-4c42-a645-9786ad3b681a",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "33fce958-5808-448d-8a83-268a43f51d3f",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c64b9b79-7c9e-4b9b-8063-097fa6dfe74c",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2a8b8553-f383-45fc-b3d4-a17e9eab3859",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2155e813-9566-45f5-87b1-74a153407092",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "32aa2c8c-7472-4a9b-a184-a0834ba6b89c",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5148a5f6-5247-4efb-91a2-f9d448f9b72b",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "211f859b-8b74-4a11-828c-4e2993ac32ee",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c381f182-e22f-45c2-b187-9586d05014b2",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8e567d62-9ca6-4c49-be08-dba43fa80a20",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5c789b63-80e2-49eb-8577-9bcd1b723a7f",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "21d6932b-4269-465c-9302-21a2a08e5b83",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "aae830ef-07d8-49ef-8f7c-1b6908e1490b",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b653c2a6-c237-4b59-9f70-7d59da266e79",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "468ffc47-c357-463e-9a80-b2338f8f7d30",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "dbfa5770-5f5e-4d02-b2c8-a903344abb29",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "630d32cc-69e9-4131-8d4b-721a32f4be17",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "18d389f1-3af7-4555-9ed9-111acfe468fb",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "c7c63282-6f3e-4916-b5df-ff24ea713ad8",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "df3ef90a-06f6-4593-8779-f9186d88e14a",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ef1db506-80de-45f3-b1fb-3502f4502c50",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "abb91707-7233-4870-a95a-3bbf3d802ee9",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "adcfbbe7-0484-46e2-bbcd-bc2e478dd0f4",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ec643f32-a54e-4a90-954c-eb5f1ab355a8",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "e0a7d6d4-7856-4f3e-9f2e-6b8a0e3c75cb",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "b744a87c-76a9-4e68-9341-0c5ced5fe3b9",
                          "requirements": "EL2N has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f897c387-5649-4283-827f-e62b99db3cba",
                              "requirements": "EL2N has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f8c3b688-1ca0-4fca-878d-97a1d6ec8128",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2acfb390-023a-484b-81a0-dbd4e7450b19",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a7f0c7da-f789-4c4d-a676-831cbd877191",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c408e4bc-a38a-4ce0-9bef-d4392b25dd71",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "34b3fde9-44b9-4d2f-a54b-337617f648e5",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e6060f7e-ee13-4c23-bdca-2eb0bc8ddc76",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9f05a682-49ec-48ac-b361-3f17983fb727",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0e397fd8-82b0-4b21-92d9-c9262532633d",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "bc2f8e93-c997-4c66-980c-8c6c86f66eb6",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "eab6eefc-b630-404c-91df-8288c19d6532",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "317d6d18-c9f7-4030-9822-b64d9492edb0",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9edcf5e2-b408-4933-83dc-7f66507cdd35",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "04e62f69-77e6-4047-b8c4-a7799368e411",
                              "requirements": "EL2N has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "02bd71f5-80f7-4401-8984-2a009150bf24",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "eaf53c3d-7e5f-4ccd-b67f-e92dc1b1f6db",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a6cc043f-d244-4d00-a62e-89bb22225340",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "48f3d34a-7430-4e2b-9b17-6f7b48f2ed9b",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a7f76345-1c29-44f3-8f3d-6f844438b608",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "96699e91-33f2-4254-91a0-fb6233960b39",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8e958073-1f15-4e52-bff6-b472cbe04399",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "636badf0-a3cc-4b4d-87d9-91530050b26b",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4d648c9f-d38d-472f-bd7d-8a863a48a11a",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4437903a-3497-4efa-8080-ddcf7fae4c15",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "681f1cbc-691d-4502-a3fb-f68adb4bacce",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4fb2d690-dcc9-458d-a565-9343a00aec36",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "f57d82be-e9a6-4c80-b72d-3374d618e71b",
                              "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ae660449-bd5f-4170-a7ca-28252a186651",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e2a1063a-9e5b-4f0d-91e6-9f9457856946",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c40e6af2-6527-4ff9-863a-0d193e540710",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dd5b4764-9d12-449a-bb40-63c75274639f",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "10b059e4-f31a-4a9f-b693-b182b1683c01",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "cb9726ae-6c1f-4668-9344-9915e0e3ff2c",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f615c31d-d77d-4b2b-8a13-090d52ae6d46",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "baa2b998-b189-410f-b9eb-81e6806a0ed1",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "20b0c9f4-a457-4295-8781-cd08b984af95",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "adcb309d-db16-428f-8238-20a0bac90ce8",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f693d203-7e4a-4ed6-b809-bec1dedc0c63",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "06ae38ca-9753-4400-a86a-0fc2cb075e5a",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4aa25e4d-6c53-4ad1-9828-90dd2f312812",
                          "requirements": "Influential coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5aad6a79-d5f2-4a86-9d59-2ff37866efa0",
                              "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d78c72c6-d9f7-4778-86f4-4e6d7cb0c201",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3f98c7d1-6d23-41c0-896c-e014a085b53f",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "245f0a2a-1f4e-46b9-ad16-9fc612ff8765",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2ce6189d-0158-47d3-bc25-4d79c2b0b0f9",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "793626b6-e835-48ce-a3ff-4333822a9d97",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "da41ab0b-ef2e-401b-8046-eef7622eeb9e",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "157d8c06-666d-4b09-a350-4fc0e096dcff",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7da79c7d-9dec-4a9e-9f62-4b71ae794426",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "713b049b-cbb7-4d84-bc14-196241522817",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c1ef3a6d-be17-42ab-851c-c6f6de8bea03",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "efadbfa0-b14c-4652-9432-a1f3d6ed9727",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9a786b06-712c-4035-bc8f-96a1a387c423",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c800c3da-7ea5-4d8b-bcf3-c9364db606ad",
                              "requirements": "Influential coreset has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "da6d60a4-e49a-46d0-b060-eea5a16d8470",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e480c89f-c9c4-4f57-93e1-4c83bb9e276e",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e0db68b2-f797-427e-919f-145905fd8eff",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5dd5d898-484c-476f-b4a2-02232f9a51b7",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b19218b2-def1-4af3-8ebc-b6d8fec976f8",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6df7767f-8005-4fcf-9568-b78fa53b0641",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "df68e56b-a1ca-41f7-9ab5-474de262ccd7",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e4ec4abb-214d-418f-a5e0-a93f39d5da0e",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7b6b2e8b-74e9-444d-bcb6-8f60bbf47fe8",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "35002d90-9a4e-41ae-b193-66747cb9b7bb",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3524990e-1f2a-4085-bc8c-6223fe7cbc3d",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9fbb3804-19c8-4390-b6c5-c32175d0b6dd",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a26df5a8-e05d-40e6-b136-babb343d9e48",
                              "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "aa6b0751-1877-4c73-94a9-2298c874073f",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a8680ea3-2757-4114-9a26-9c5e1906239a",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "321d579c-ace1-4819-900c-516f97fa749d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "50631f05-0286-4b65-b70e-388722d74636",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d7647a63-b75e-4f41-ab89-b7afbeb5b319",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5ce3b9d5-59bb-43ad-a70d-af71ed17a07d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ea71f6ca-2841-4f9f-9ff0-b258f1d5afd4",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4a8d82ff-793a-4dfe-9b93-a279f3f1cae7",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f3bb4b55-b1a9-45db-a91a-afac96cc6586",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a6bcd267-cd40-4f1e-99b4-e503a96927d9",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6d2ee476-7f62-4a45-b462-978279cfa5d0",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0fd6b3bd-db02-4799-b2b9-a2a5f01136a7",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "fefe7007-f061-47cd-b566-20f493792836",
                          "requirements": "Moderate coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8eef2c06-a320-4044-a1d9-3a9e7246eeb4",
                              "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ede7dbf4-c92f-4ecb-b168-6396101c0dac",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7bdcc020-4b66-46ab-9cc7-f6c505e72dfc",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a32cf42a-8a33-494f-bbaa-5c3d3c9ffdb8",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6491b2bd-01c5-4713-b537-f83589bf41f2",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "efb4ca11-e516-44af-9ea1-6f7bf3c0d3c6",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "df44e808-b626-48bc-86f8-e92eb656181f",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "26f5bd0d-3768-4875-810a-1d10d3cb8a38",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f62220e4-ed4c-4c99-8c98-b53a459d375f",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8c4096e1-1fad-4e90-ad9c-d1178a19c80f",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "529f262b-eecb-4c4e-a446-8c8b2f7e29b3",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7fb92b85-bfc6-4780-b5b3-323f486979c9",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7fc8290b-a24b-4a1c-b376-e08f796596e6",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b00ccb06-9725-44b7-b7d7-bc50eb26841e",
                              "requirements": "Moderate coreset has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ae8abfda-edcb-40c8-a1a9-7f0bfe5b4e3a",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e0e262e5-4636-44ff-9dbc-ad068a678124",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0c991e52-a95e-4a6c-ba35-1870c4093fd0",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ceb0707c-ce3a-46f7-ae0f-26513399fd9a",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "43736dae-5231-4baf-896c-b2ddb1b55a4e",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c07e239a-327e-4ff6-89f4-a9e812faa7c2",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6a15b31d-656e-42ae-85de-87fa00f7db7a",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "91708bfe-f85f-4566-a8d3-bab761b12a04",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "82c0636f-2111-4b67-a815-2e5f3f347741",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ade1a2b8-8fbc-454f-bf42-14b2e3b16d19",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "cf3ae416-0c51-45fd-b4c1-39c148d25de1",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9431c236-82c7-41ff-b33b-2e15fcbc3439",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "211af7f2-73aa-432f-9fa8-da051525d763",
                              "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8aad790e-cfb3-420c-bc3c-c8d3abc3dc3a",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "128a6cec-98b4-4888-9f8e-71cc5dba7ced",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8f6c4611-b89d-4d80-96ae-6628712223ee",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ae4e1420-26b5-47af-aebf-9d1e5143264f",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2e19915a-db3d-474e-9a03-2aa7cad181c4",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "85541cde-cfd5-474d-8e44-159f96cc73fb",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ef7b5fec-6871-4b63-9377-66d0a4e74f15",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "354e6e2c-bf03-46ec-b3bc-2abb19275ede",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "50ebb79a-fddf-49ad-b2b1-ef54b32c7a78",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "10f222d9-57ca-4245-9d71-5774e994fee1",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2878e8cd-7112-45d9-95d8-334ea796f82a",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7c69e7bc-8130-4c7b-ab5a-e9ff18104762",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8bb51806-b093-4e71-b6bb-a6f1bd2a4620",
                          "requirements": "CCS has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e993453b-8b93-4762-b43e-b3941fb29ea6",
                              "requirements": "CCS has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "13bde73a-4d2d-4ab0-9551-de03494c0ff5",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "355eefb9-ae33-43cc-b24b-e8cc61f15ffa",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "bb827180-e0f9-415c-b1a1-4f0e0197f865",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c579fea1-76a1-416c-b76a-60cede2e7632",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "378b2380-f04d-4560-aff0-8facf8e65f0d",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "83d9991a-3e69-4751-a7a5-7b0265c265e5",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d5ffb6ca-3ef2-4fa9-8a48-f1d99f6eddad",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ddc2460f-87a9-428d-b660-9f0514a451cf",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4e2d4552-801b-4263-9ad1-aaa3ede31452",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "aa94a897-31f8-40f6-a21d-b1b52b8d859e",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "08fdba38-a36d-4757-8d81-725072fccbc2",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "64713abc-1100-41a4-a775-10cfb56e19bf",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e6de8fc0-ce69-4e38-827b-2766d57dead3",
                              "requirements": "CCS has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "811d8748-46f7-4c9b-9bab-70270a4502ba",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8d4c8e7e-bef1-460e-9cdf-986336163be8",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6061eb92-2e93-4c01-8cc6-b8d856979c01",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "88124de3-d517-49c2-a2a1-538bbcbb838e",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3c46492e-b852-4cfe-b3de-07f9ea8ea132",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4c15c69d-5b18-433d-a415-73431ceca803",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1383f10f-7252-4952-8e64-e43db1bec779",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e3136178-16b2-40f9-8d4a-9788c9378af4",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "bc3dd321-1a3a-4737-8b76-1e5b648c864b",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dd22e65a-9e08-4ad0-9198-1dacd1f3cdd8",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e8400f83-8062-4a8c-a87a-5032a65cb793",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a30042ee-13b6-4677-95a8-3f3b412c2783",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e05c1a89-b1cb-476f-aad7-05947688a96e",
                              "requirements": "CCS has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "690deeaf-b2f3-433a-8695-75ea316becb1",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b58bc074-1724-4f64-b006-b4b7cb915fb3",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f91af7b5-b654-4cc4-bb7a-67275febd73f",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "aeb0629e-c385-4a4a-9601-ad7ff4df9d8f",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "987174e6-7225-4f14-81a3-17a8e6291272",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8deb7502-e823-4461-b23b-06fad796a379",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4444a3ad-c77f-49df-ad6a-7552f05b946a",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4d560b37-9ee9-4cd8-ba76-e37de39ebf42",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b6eb340f-26cb-43eb-b0e6-c3012f472551",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "87b83244-507e-449b-af8f-45cbea2857be",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f683fc78-cfd8-4440-9ec3-ed19bff77176",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b5ba29ff-f5c4-4879-b95a-63a556129457",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "43540168-8eae-43c2-9530-7e84f5043b41",
                          "requirements": "Probabilistic coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1e19dfc2-721b-481e-9924-4aa95242a32a",
                              "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "29dc3a48-745e-47e5-9ea6-91ada1e81e55",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2d3d2db3-d500-47c5-af07-73e4a79800a7",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c53240eb-439a-4e71-8665-9f8be4f60734",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "cdd74167-5450-4c1c-ba72-eca0a4ae15fe",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5af79443-9f16-4ea3-8145-71a54fd2899b",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "926df311-859f-4f67-be27-df0e5cace85c",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c44723a1-1c22-4d34-88c1-69a021151dde",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "927102fe-8106-46fb-a6a5-3a1b609876e7",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "82f792d2-65fb-4fee-8fa1-468a414aa675",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a399e6ea-31d0-4a99-af59-804d145e573f",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3e759be8-0df1-4b75-976f-54f714269fba",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a715fead-36b8-4583-b0fb-0bee420500e7",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a783176d-db5c-4583-9c49-97cb08a34f41",
                              "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "793a9f7f-9360-4a22-b9b2-203034a8f82e",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f061c18c-88ba-4317-96f0-132e405c891e",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9de60804-d1b5-4a2d-bfe9-e7a7b4b49cc0",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a4952947-9897-4241-b997-6803104ba8d3",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0c7fede5-dbf9-4158-9518-13f43b8bc323",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e3101092-0cb8-4b91-b249-210aecafaa25",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ca923cf5-ec53-4347-a19e-b9268a3f5919",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a5c293ea-568d-4003-a1ab-34dc1f94def9",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1c16d802-1d01-4d0f-8452-cf8326cacb38",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "93d9a4c6-9362-4a64-84f7-4fa1afa298bb",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "47a311d4-ed24-4ad8-81b7-1cfa477fe327",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5d14905a-9318-45f0-a85f-b7be9c3dae12",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "56f6d51f-2dfd-4686-9184-640e90ceefba",
                              "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c6ac4308-12fb-46a1-abaa-ecd7335021d4",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ac2f207e-d9df-4973-a939-8ab53b9f006d",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "798af7d5-c124-492d-88e0-c2b51eed8dd8",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9b8959bc-2e33-4081-a0be-532c8e5e486e",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2c383f29-50f1-425b-8728-debb9746cbd4",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "803aff38-3b2a-4ca9-ad0e-5741f51450d3",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e441ac65-ab3b-48ac-96ba-f3ecd3379849",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3e5f5595-87a8-46d9-bca4-5a4c8be38406",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "399becff-bf8c-44de-9935-1a2f5acd30f1",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a9b8b9df-47b6-4b16-ae72-a78360e889fc",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "035bb845-7ef7-4fbb-aa84-5dcdde0dd822",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6e2993fb-5437-4e80-9538-e0816a137e03",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ca56b02e-4971-483d-a6b2-e109cd716492",
                          "requirements": "GraNd has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8fc0c860-99ee-4a0f-a36f-a0073f454b6e",
                              "requirements": "GraNd has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "528194df-38af-4071-9eab-20f212b851a2",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "35f966a5-86bb-42e2-9fa3-ce04d4561cf2",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "fe808434-c7dc-48ab-94e4-7b0da1c46ec0",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3e8e0fd8-362e-440b-9f26-7194432f280b",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "62f12ef7-2e67-435d-b6a0-867751e0a1b0",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3bae5722-ffdb-4e51-a4e4-806640542eb3",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "cac2ec74-bc59-464c-95de-44633ac242fa",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d43763bc-4426-4476-9bba-6f1506f1a55a",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5d4a757a-d765-42f2-9cb3-6f9d138e659a",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d5309422-21b7-4294-af9a-0734be87cf28",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "03b1e1e2-c69b-4faa-9681-96dd50541d0b",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e8e4aeb3-b4fd-4f5b-aa6b-ec09191fe352",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the LeNet trained on the constructed coreset on the F-MNIST test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6edf2c2e-c142-438d-a4e2-c9c09f78a649",
                              "requirements": "GraNd has been evaluated on the SVHM benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "902a2366-7d9c-4bef-82a6-ebefba0bd8a4",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5c655122-1359-4d1d-a1a3-9036831988b1",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "eb3bab74-5688-4c59-8b5e-915950b08dbc",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9508d6cd-1d79-49cf-993f-5a65612bfac9",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "aa8ac38e-3005-44db-a73c-55d5b10dd71d",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6be4d156-f1ab-4c26-beed-0e7ff638e69e",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b47801bd-5036-4c92-84b8-3a26a40dfca5",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e420817b-fc70-4aea-abcb-96a544fc340c",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "88f0c371-5acc-48f2-af4d-cee89d666359",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1ee31b5e-58dd-41d2-b490-c8483e368be0",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7d0f837c-ce8d-44b6-aeb8-eeecbf7e3cb2",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6c760104-cdb5-46d4-a010-6dfe6e860940",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "8fa6d8ab-092f-4fb9-af08-5f522d99952e",
                              "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "bcdf1fc0-6175-4ece-b444-042fa59adce6",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2c1f5c8d-99e2-47fe-b48f-b460790a2b5b",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "754154a1-4715-4ce3-9c99-055ed8225dfe",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "eadb6503-ef50-49ee-b51c-ecf40cab0bc8",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c6c06edc-ea40-4b05-a343-edc0fd64bec1",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e02ed25e-e826-47e2-99cb-95a35960e3fd",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5b4116c1-002d-438d-aec7-bbb6880eb8d0",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2de234ca-22d1-4d29-83b9-9cceeb9822aa",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "68ed3b1f-e1ca-4a75-bcd3-f7953b61832d",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c115d7e6-6223-48bf-a5f0-ecfcf7f0b051",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ca5125a0-cd34-4506-bcb4-203d544f8731",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size of k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "a8f68237-4bff-4aac-b565-b44addc0ec11",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy and test accuracy per coreset data point of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "34ac885a-2c25-4b03-bba3-8f15d702d356",
                      "requirements": "The results shown in Table 2 and Figure 3 have been reproduced",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "e45b1b5f-8513-4d05-9e87-a9d89ea853ca",
                          "requirements": "The measured test accuracy on the SVHN benchmark shows that LBCS outperforms all other methods across all tested predefined coreset sizes k",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bfa6ce7d-0c3f-4fc1-aca7-4a0b2c016543",
                          "requirements": "The final coreset sizes measured on the SVHN, F-MNIST and CIFAR-10 benchmarks show that LBCS always leads to smaller coreset sizes than the predefined coreset size across all tested predefined coreset sizes k",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2912c726-a3f5-4404-91e8-c4ce5527a8cc",
                          "requirements": "The measured test accuracy on the F-MNIST and CIFAR-10 benchmark across the tested predefined coreset sizes k shows that LBCS outperforms all other methods most of the time",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "eb07a367-3c62-4325-840f-3c6eb3a0284f",
                          "requirements": "The measured test accuracy on the F-MNIST and CIFAR-10 benchmark across the tested predefined coreset sizes k shows that when LBCS does not outperform a given method, it remains competitive, i.e. within the error bars",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "03dfa769-293d-4d03-a7a9-685af76a7250",
                          "requirements": "The calculated test set accuracy per coreset data point on F-MNIST, CIFAR-10 and SVHN across the tested predefined coreset sizes k shows that LBCS always achieves the highest test set accuracy per coreset data point.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "e3a19145-2061-457d-9828-91ed79f66c94",
                  "requirements": "The results shown in Table 3 have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "2545850b-d9aa-4457-8f24-78bc1e67bfa6",
                      "requirements": "LBCS and the 7 Baselines have been benchmarked on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "75e61828-11dd-4ed8-8c41-86fedaf8d8d7",
                          "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the test accuracy per coreset data point of the model trained on the selected coreset and evaluated on the benchmark test set can be measured",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6406c546-dec1-44b3-86e3-d171208a71e6",
                          "requirements": "LBCS has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "18aeea81-718f-4919-a8af-f04fdfa3d9f4",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the final coreset size at the end of LBCS can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b47ab927-5272-48fd-aa88-02ce4c2e30ab",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the outer loop can run for 500 iterations (i.e. T=500)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "01c2dd15-d4ac-4fd5-ba0d-4963d2dd348b",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST, SVHM and CIFAR-10 benchmarks at a given predefined coreset size, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "ed677556-a9a9-4c04-9cfe-716c9cce765e",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "de3648d0-31bc-4764-81f3-ffe537d670f1",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9a613e0c-dce8-4cca-94ea-568cf0c04ebb",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8de96cdd-923b-455c-a202-2cf8be7406e6",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4b529926-b492-4a4b-aaad-67c3c419f5a7",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "cfda7061-e1aa-493c-ae8d-31e73abecedb",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "eab3ebc1-64e4-4fbe-84fb-2ba5cebce4c8",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "bd3921f4-94db-4759-849b-a64e99f5b423",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5a301133-75f8-4355-8ef2-82e70254133c",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "db95f95b-e780-4b96-ae18-97fad8842887",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9844d00e-a6ce-4efb-8af7-dfea6fc9a4fa",
                                  "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4381924f-40ea-49c0-b66a-b009b1d47b62",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d031341f-373b-4cc5-882c-40b7f4284ece",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6265cf57-c4b7-449f-bc2a-63316a4c42f6",
                              "requirements": "LBCS has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9c43a389-d106-4d6f-a9c7-5a1ef9dd63ba",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "46477a73-7ec5-4632-b741-9d6f4b3f5fdb",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "04c557c7-1694-4c7c-bfc7-8d0aa33f0b1c",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b5b57cc2-83e1-4db9-a2ee-652397c5b839",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5df3b450-c55a-4334-be6c-9e72e9124002",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9684d342-d950-4fe6-98e5-c6ae13f144fe",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6e5f39b7-377a-4051-a36c-12f6806a752e",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3da631c1-1522-4f19-a5e3-44aa9466e8e9",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6bae4760-d892-4886-91be-916e8ceada69",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d6877b1a-680f-4f8f-adab-6da547c1b648",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8e54a56b-7948-499c-a4f9-fc219c043e96",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "67caeb7a-4d3f-4976-b0d3-82507ca6baa2",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "5d12a24a-23da-4e40-9cb7-0e6b8826e08a",
                              "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "00c56a83-2925-4bb8-93a7-8675a91f3dd9",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f89b0faf-c4b9-44ea-ae75-9a97946b4861",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c157bc1c-b264-4a7f-8252-e0d316695fab",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6800ed2d-94b0-4154-993d-e596b1d0c32e",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "61e8dc11-1a23-4f00-992f-84130d19a1cc",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "899b59d7-1d89-4b65-b9ed-30080b50dc25",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f81ba357-c433-479d-b9b6-7d989c0740e6",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "91444d99-0b0d-4a79-99be-805c07c60cc2",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b7498965-a1f1-4f2a-887b-d049003e6c64",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "7dffa509-ac98-4880-9788-1100f8ec4c26",
                                  "requirements": "LBCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "954393a0-9d5f-4573-8d36-9a6f8bbab8b8",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0f349e84-fb6a-47d7-9845-c453afb7056f",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set and the constructed coreset size have been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d28bae74-083d-47af-a834-3e17ad60d3a8",
                          "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "234d4644-cfb1-48a6-9ed8-01bc03a27ec9",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c59df777-a70b-4811-a57a-5c64c366701e",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5f4dcab4-d72a-4130-a88d-0041229ccf9a",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "0a486be5-a392-4223-b551-21f1e91c1790",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2a5944f3-bd5d-490b-a44a-b39b794c4eb6",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5dca7b9f-1851-480e-9c47-dba75b292e85",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "74cadad8-bfe3-40c8-a86d-e383c6f893db",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "093913a3-a22a-4a59-9443-1b845e1271fd",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f2a3a257-043e-43b6-930c-49ac1afca943",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d8296643-7cf3-45d3-b25f-b99c741c7b95",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "505adbef-b1ba-4622-a845-a93eec17a482",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "76c30862-ef21-4b89-86ef-645e46bcda54",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8e369550-6423-4b07-a9cc-bf7ca547c86b",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "58421a09-94c7-49ac-8a79-d812cbfcb649",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a5e9da49-3e14-4756-9d07-210f1c238308",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7ac41ee-2852-46a2-a146-5b3a7f2b9429",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "1a38e79f-3bbf-4424-9fad-9b179431ece2",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c188cae2-5b78-4918-bfef-f757f06487b4",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "287b8cb9-e772-4f86-a545-82db5c18a2b9",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "edf29af8-37fa-4e0f-9a31-79376089e35e",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "75c6ac1f-0dd2-4436-861d-ce1f17b00402",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c07029c4-5223-419a-932c-a8ce07e17d05",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1c5be0d9-ba03-42db-930c-caeb2ff503a9",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b941b8f1-07c9-4149-8582-cc304f61b2d5",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6bd2f8d9-c627-4a99-b1ac-1c9fb4c0d2eb",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "cabd4283-b621-4aff-ae9d-8e9163d24047",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "a4454e1d-dbf2-4c27-a067-8bdc2e9fceb0",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "2b57b0a9-0411-43c1-846e-21c3353cd427",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "dc3ce96c-90b3-4dba-b464-0ed4d614c648",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "462b84fa-f0dd-42c9-b0a1-13ae023a2ce8",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "aaa02fed-95f8-4483-887c-30ae30b6a5f2",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d06710ac-70aa-4e11-811a-2d6401b416dc",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "65db6bae-15cd-4f00-a5f4-0a5cf1084d59",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6ac5dc41-6ae7-45cf-8040-077e7fb0cd88",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ad358c29-f62e-4da7-8144-603d97b8f13e",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "82f1bede-7a23-409f-adf9-0df034a54dc8",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a833cfb3-6430-4285-bb9d-82b83f8d93ec",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4efc3b8c-4382-4e28-8029-7aac13432dc5",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "72f3cce2-6256-4a38-b799-40800aea5a6b",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "ad350a09-500e-4720-90f7-92261d518cc3",
                          "requirements": "EL2N has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "edd32e7e-e04d-4221-a1e9-497c4477e14b",
                              "requirements": "EL2N has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e36138a7-dad4-4a32-b34a-54648eec95d2",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0d6c882c-eab1-4ef6-8857-ede72f882369",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "682f47e9-d11f-4eb2-9f3c-6e6bdc99d436",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0f87fea7-d8b2-4968-baf2-88cf12c51127",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "00f95f57-2655-42b2-b4ba-fa8ed5a68a26",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8a7d019c-036c-451d-9249-a55e36de67c4",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "60e4681c-46b2-4519-a508-c1c6aa639ca5",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0da44fba-a2bc-4905-bac0-10d9fdeba950",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9c68b7ec-59cb-4541-9f10-693801c85fd2",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3bce58ba-4615-4a49-ba85-7189938ec27a",
                                  "requirements": "EL2N has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "081f01dd-f9c7-4caa-97d6-cc09bacfc85c",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4860b2d4-63cc-4a37-9878-c76516d242fc",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3ba4ff30-b249-4a5e-9937-fd1a98d5c1cd",
                              "requirements": "EL2N has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5b31b6f8-9612-449d-9a5c-f6984bbc858a",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e5594d57-cbc7-4f4f-9a29-3048a0943587",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b5c9c0d8-8c41-41f1-886c-163477e9cd97",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b95b804c-435a-420b-9668-cf320e3861ee",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a058818f-b340-4e60-bf04-1a9263ef7143",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "480a4e54-814f-466c-bcdd-5ba704e298c9",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b5b6f7c7-68e2-4e72-b262-8264f53946a0",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "bbe1c458-016d-4e1e-829c-1009b0ad5fc5",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "437b1225-b6bb-4905-b9c5-a705545a6190",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4f8b51fb-5962-462e-93c2-d9ff3609b853",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5e81d480-542f-4c17-aa49-caec23de5250",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c3e74bbc-f903-4c22-9ea7-ef3ce6485d71",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e2427ea0-ff07-419b-8267-25314057aa48",
                              "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "905b3445-7781-484c-8345-ff817dac003a",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "121a1efb-f46e-4b74-926f-c92c426ca645",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "186d9610-faf5-4c02-b40f-92b2202925d7",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "cd55bb8c-7f2f-440a-a2dd-970cbc320480",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ff259fd2-1722-4bc5-8057-c8659dd20f5f",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c81c61bf-5396-4d6c-ae5e-498dfad05847",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8a8d01b8-a9f4-4f41-bdee-c14d54fa117f",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c1e61bd5-a3f8-4934-b9e6-f13e5ac939d8",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e878b270-e068-4b28-9f3c-5df04c1c7180",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a08e9757-b57f-4c3a-824e-a06eece2ea66",
                                  "requirements": "EL2N has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ec91d43f-a0e1-4ee3-a8be-7cab31ca683c",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5700cfc9-d800-490a-b907-6e598c30599a",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "822807cc-fd67-4ed9-ad30-226ee01e8263",
                          "requirements": "Influential coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e48868a4-a8be-46b4-92f2-60b124ac11df",
                              "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "91a2b60a-738a-40d2-9dac-ec1ff7bfe242",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6b670c16-ba50-4a4f-bf52-b3bc1a141642",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c6219484-8bca-4b5e-9900-0a61096ee417",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "65d0cd5a-0dbe-4439-b6e2-d933d34f4eac",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "dd6a161e-8da6-41f5-9706-e8315453b891",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "19cf5847-263c-4c39-8cd0-d7a2c0e6e102",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "24a19386-62b9-4768-9c0d-9fd5ad2a9432",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8deecc68-9ab7-48d3-a7b8-327d9c7187df",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "fae89989-f9d3-4de5-ad0c-320b95b61b0a",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "55d8515d-b5d5-4597-a226-8e526d8b485f",
                                  "requirements": "Influential coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "03ca2658-eb63-4599-a275-5f3ec53f6662",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "32d7fc17-e872-470d-a82c-3d202995e413",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7ee0140e-0035-4b7a-af68-dee5ee532629",
                              "requirements": "Influential coreset has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d3533577-4f38-4811-9ade-147ad15303ae",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "89381dc3-6f3f-42b2-bc57-47ed70679150",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "6e16ea30-345f-4e8b-b9a9-b379dbd6e1eb",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f156de9d-6d94-450a-a8e7-5c675f6b7da1",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9c543b00-cc3f-4d8f-8e17-637217535e00",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f39380a0-5109-4c1c-a41f-7ad6cf1ecbc1",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c11c2aab-827f-4e0e-b432-4a9a4d2be145",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7472c76-3947-474a-8bbe-d3e70ea9f0c6",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ffa9db76-1630-4026-94b4-36394b477cc5",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d72deeeb-0de3-458b-bba6-91d27b3c8c51",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "628b7126-48fa-41f7-b497-e7d921aabfdf",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "69d84bdb-7351-44ce-ac5d-ed28ea3b1fb7",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "f1822468-4b30-4918-8749-a00db456461f",
                              "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "62e5c7c7-a286-4843-bd0e-567aea41472e",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "fbbab2c4-6068-462d-b35f-1664f6998c97",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "502b358e-6510-47cf-bc27-0e38eb00b923",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "415ccec2-8d93-45fe-b95c-a2f1db8f5249",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b4fa2099-bffd-4c5e-b884-94d949eeacc5",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "cbf1888f-e9de-4fbe-989b-c32896747957",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d40be831-349f-4c2c-bd57-a7fa226b076a",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4c20174d-e28d-4355-99dc-0c49bc44fcc9",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0b3aba70-ec29-4cc0-9f4f-da662791c853",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1b735a13-5c1e-489d-ad1e-5a39eff70be3",
                                  "requirements": "Influential coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "12372c2e-9c08-4157-9484-1c9d4ac4e342",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9887e5bc-fdf4-4fd9-842b-81db3fe9d57d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "61cd2e6a-a6b4-4b06-a755-afa3905d3c2c",
                          "requirements": "Moderate coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "e2b354a1-0b11-4de6-ba97-1edbe28291a4",
                              "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ef443100-b140-499f-92c8-b3b393308846",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "06f1c687-6898-4366-97e2-774d1bf7fe12",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "acf1548c-2ed3-4931-bee0-374201b6801b",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c76a9cd1-be54-4d2f-b2f1-c606f0a697e2",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "86e7f93a-11ba-4165-a4e9-ccdfa14260d0",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d87f7fe1-39c5-4b40-a97a-1e479e034d17",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "66e358c2-e6a8-4f8f-8537-5688c5f3bf4e",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3d9643a6-5911-4ac0-801f-76b377b9e520",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "87ffdee8-c3cb-431d-bff5-20c1c3b31c40",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e4df6682-e111-4cbd-9856-4057e9fdf76a",
                                  "requirements": "Moderate coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e1ccba61-db0d-4e31-b34a-c0afa1da4854",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a6706334-2df0-4835-8684-c7fe99435127",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6eb85703-0c42-4194-870c-536f54ee0b32",
                              "requirements": "Moderate coreset has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "58dcd492-3f8f-40c9-8782-38cb5256f0bd",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4358ac88-0dc9-4013-abf4-cf1863046c01",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0d43ccee-d08a-4c3c-8940-1a3df0d84e0f",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8eaca93b-3fd3-4784-9c10-ddb2aca14d7e",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3293eac8-be9d-431d-91f0-ea082a549bb0",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3ac205ae-f429-4de2-9304-7d355cd9ae90",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "07a0a495-60c4-4db9-bb54-f354d2269474",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c5a8c47b-1f05-4283-83e9-f93212f3bb1b",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3de829b6-8705-457f-9e15-33494db2d454",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "272a176b-375b-42da-9096-138e2478ae52",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c78e4d3a-a187-4311-ac87-c809fba9582d",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2280f5ca-810d-4397-8ead-cc9b85a7975d",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e87bd591-2942-4c6d-a617-ca8f358229e1",
                              "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "837a5109-81ef-4693-964a-b1d73fd50ace",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "29d20351-65c2-41fd-a4e3-12416932a989",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e2e13a3b-562e-49df-b363-0599bacac407",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9b5b40da-a3e4-488b-852a-1ea0a599c836",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7bd14b3-3836-4957-b84c-432641a5c855",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d7ee3643-6223-42e0-8152-39309fc71263",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d9cd9034-7338-4cfb-aec4-fff41727107a",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "62ad8c3b-96cb-4f49-9ec7-9f60b4d6bd08",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "fc07691d-13ac-4584-a7ce-9738514c882f",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "a355bd40-a157-4916-b7c8-ddb59ff6c919",
                                  "requirements": "Moderate coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5070e67f-f511-40c6-be60-b6009482eb0e",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7bd1d53c-1ecd-4ee9-a9ff-ba3eb2b7d0bf",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "5c56bc1b-fe70-4a17-b528-202340462c75",
                          "requirements": "CCS has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "605c9797-e90f-41a2-8080-69b96b0a1288",
                              "requirements": "CCS has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "84a57728-ed59-4aa3-94e4-74dbc2016e0e",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c913c920-33f6-4a2b-8555-7b48dd9fe383",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "61fc4a1a-8831-4397-9f0e-ee6a57f20c32",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "420e0bc3-212d-4b90-bee2-3c4c3d10e947",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a99254a9-b0d4-43f5-bea0-06bb6aa4e93e",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f93b2b3f-e410-45b4-9a29-4a12545901bd",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4eee1305-f977-48cb-8c99-b432378c0076",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ffa06f72-a383-4e6f-9b01-eb753952e16c",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3a69540b-e5cf-4ad2-8e6b-c31d8a5b73e3",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "242d3571-66b8-4ad8-8e63-fb4b7e58507b",
                                  "requirements": "CCS has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "76e42189-d9f2-4326-8535-63b39fbcae1e",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "459c59fb-e233-4f91-8299-3d4bdf539d81",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ac7419d6-d2df-4de4-8b6c-1df015b5e5a8",
                              "requirements": "CCS has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4c3498e3-22fa-40cb-80f6-994ebc2095bd",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "477c5ffa-9439-484b-ba83-1ea96b5a01c1",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3ef3106e-cb72-459d-aeea-68c36a5820c1",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1ed9dbfd-0570-40cf-8fcf-95d24c2f0192",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6402623f-1109-438f-9b6b-102223d44e15",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d5de5dae-8a95-458c-942c-489fab4d79ec",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c75c969d-f104-4251-bfd6-f81b5384f80d",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9778b54b-b65a-4984-ada0-a506fffdd913",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "aad3e802-d521-484b-9b94-9384dd9bfea7",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d90e0a15-b25c-4d82-87c5-9d040591240b",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "265a8d42-4927-46c4-8afe-89516d9fb3e6",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "f47a428b-dc86-434d-929f-38ce713596d9",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1a36a3e1-0dfc-4651-8c4b-abf7e0a7f844",
                              "requirements": "CCS has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b46d9d7a-903b-4785-be3b-37986817576f",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f0ffd55b-af30-42ca-abe1-3af30bb9213f",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1461a0b8-867d-453a-a5c6-33fa920d3961",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ae712417-8f21-43a8-ab02-b35cde2326a7",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d855e37d-5ee9-4804-8077-e2377ec97a29",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "63f289a6-6980-4e26-8b40-42a4250cc8dc",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "22ec045f-bc4a-42bb-a7bb-6636145676a9",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "20e16c58-e5fa-4368-86d2-d1a6a03a93a9",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4a7278ee-0912-4b04-b0bf-1dddf7312767",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9ec86221-970a-4076-a7c7-3cf0891c2a8d",
                                  "requirements": "CCS has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e7f82a22-f584-4a7b-b021-f2cb667e2738",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4520ea08-7792-46cd-a3f9-ec4d5d4243d8",
                                      "requirements": "CCS has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "82c3c09d-aa49-4410-93f1-412dc0b04a5b",
                          "requirements": "Probabilistic coreset has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "eb62a912-9ebc-4b8f-a734-c2abd91025f7",
                              "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a9d718f9-4000-45b6-8908-0f0b31b810be",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d8eb1158-ecc7-45ee-b24f-f54165f5989e",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7f0ef7db-9a06-4854-aa49-4bad7a072064",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "376a7bc6-419b-40f2-a7d7-c53b5f95a074",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9a01611f-29c5-472b-a42f-39ade402d912",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1318a497-1720-49d6-aeef-a6cf00cd4afd",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b3920e5b-38ff-47b0-a2fe-281fa19a15b3",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "551e7429-148e-493f-a4aa-dcee44137250",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "1a36f526-b290-4cc5-9e57-6a3095e956e8",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b2fbcaa6-54f5-475f-a4d2-2a9418f90fe5",
                                  "requirements": "Probabilistic coreset has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "60ecf0ee-cb31-4212-926a-52dd1eded42d",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "29edc8f4-14b8-4346-ae67-9245e09568fc",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "82e908f0-a719-4044-b106-12b580392ed1",
                              "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "45507166-f05d-4a45-99a4-406a42ca12eb",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "781dc49c-9e2a-4233-8416-bd322f7cb4d3",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5dc16ab3-b324-46fc-b401-8163e66dc09d",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9c47e7d2-7942-4773-86e8-099f23b40a3c",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a5c9e5df-80e9-4009-aaee-a3d9ccb7ac2f",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "cb02bb53-8873-408e-8aaa-b7cb6208859c",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "36f32e7d-08ac-487f-89e0-0a0bd88d1f82",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "92692b1e-7f8a-477e-8a1d-03997c0edae0",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5514295d-5993-4527-a5bc-329df17a9a65",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b97d4d57-6b52-458a-ac55-323dea601736",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0ba93f7e-5840-41e0-b178-af4dc2784636",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "964e31bf-da23-4020-9ce2-0b6d3db4d081",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "4ff0a9c7-e176-43da-a949-f2b6e846078f",
                              "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e226ce10-9363-4ca0-8bc7-990ffa837068",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6eb2e184-7c6c-43dd-9bb4-ebc86d602702",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "666b9ca8-8f4e-446d-afc1-89f1373c1dfb",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "96eb047c-2489-4f7a-a2f9-5f6395db0c03",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "61de7b17-b2ca-4240-800e-dd47740c5902",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "b32d1344-5e81-4f4f-9416-dca570a44431",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1316ab86-29fe-4934-b6a4-0cc47af26006",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5af9c653-2325-4afc-b3cc-871ba0e5a7cd",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "86d5ad22-1c8a-49cf-9dc7-651f64d4fb2e",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c5318533-26a1-4d2f-a53f-7d205b2b2dc3",
                                  "requirements": "Probabilistic coreset has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c0521ee2-3200-49da-87d1-124315a2543d",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d33701e1-d028-4513-b24a-ac343c008e8b",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "0b0db965-8e0b-49a1-8743-4942a8ea4701",
                          "requirements": "GraNd has been evaluated on the F-MNIST, SVHM and CIFAR-10 benchmarks at various LBCS-determined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "078cb0c1-bd41-4a61-bb48-63bdaf6057e3",
                              "requirements": "GraNd has been evaluated on the F-MNIST benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c87bfd32-49c9-43e1-aae0-aca73a32af50",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b3f9dc28-cb83-44c8-a840-829677f8f5af",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b2f1f048-92b9-4621-a422-f9a09c4c443e",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ae7080a5-3dcc-4359-af7d-24bf868f44de",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "520d9ec8-2e25-4976-b5c8-21e216c04de0",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "bd3a1d57-45f8-4160-bc02-304e83705c9e",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "23addaa4-916e-4cb3-af74-26978746f35c",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "058262ac-9a67-4c42-ac65-6c9bbc9af40e",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "dfa291c7-cfed-49e3-bba7-d1b3dee86ff9",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "00739dd4-7cb5-42d6-9848-c7b6baed3f87",
                                  "requirements": "GraNd has been evaluated on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c402d4f6-ea03-4604-9529-acc1d42685e5",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a78f5ad0-3d78-4db9-a56f-ae50db44fb1a",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e96880df-10e0-4073-9b0f-a686229aa096",
                              "requirements": "GraNd has been evaluated on the SVHM benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b2443791-ca7c-4d07-b591-1253dde5978d",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a9427a4c-6480-4ffc-949f-e00c67df430d",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "141eca20-37ae-4c3a-a0f3-0b2048fef39c",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "78692c69-2cc0-4b11-955a-887b3b4bebac",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "98740f1c-81a9-462e-a8d6-24f6290f676b",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2eee5971-fbf5-47aa-a175-e8cacefa3d8f",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5b80a315-d38b-499c-b674-aece5b90cf8b",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7b75d0c7-9cc6-47d8-9a67-ab64feea28c2",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "cda85483-3d49-4fc8-b0f0-324488d31074",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "08cf33f2-b2b9-4fee-af82-4e5ea135c5c3",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7a2017f1-b839-4baa-a041-1503d13ddeaa",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9c5d7f4f-89cc-41e8-bad4-2c0726130d0a",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the CNN (Table 7, center column) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1162f5a8-9819-42ff-abc1-cf5f30ec96f8",
                              "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark at various LBCS-determined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ebd699de-2dad-4b51-9d9f-3d95c9976ad7",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c7a139ee-a238-4f46-8f27-d0d670f1be28",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b798b6fe-c2aa-4cac-a071-2287f01b6aca",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=1000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4b1a9e46-4c41-4b47-b2d2-498bb67db7fe",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ecec41aa-82c0-40bb-9658-325bb5964336",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4d7d69b6-c9c8-43a7-8089-dbb19f2f77d7",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=2000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8c3ab7a0-61ae-42a8-8b82-383912d256e3",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "71026622-9a5b-4d81-980c-fbe71058d786",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d1087175-f59b-4f4c-aedf-0e1207ef37a4",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=3000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5f1e7615-6ea2-46c4-a15a-0bdc0a7b03e0",
                                  "requirements": "GraNd has been evaluated on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "069c454a-02cc-4c8d-b5f7-787bccbbeb65",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the CIFAR-10 benchmark with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2f84d0f6-25a1-45a2-9fed-99685250b490",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size equivalent to the coreset size found by running LBCS on the same setup at k=4000, for constructing the optimal coreset for training a ResNet18 on CIFAR-10. The CNN from Table 7, right column was used as the proxy model during coreset selection. The test accuracy of the ResNet-18 trained on the constructed coreset on the CIFAR-10 test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9740542a-f9d4-45b8-a464-3872d7f4cbe2",
                      "requirements": "The measured test set accuracy on the F-MNIST, SVHM, and CIFAR across the coreset sizes achieved by LBCS show that at these sizes, LBCS either outperforms or matches all other baselines.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "a94a0ffd-bd45-4d54-8acd-3c9d56c77b79",
              "requirements": "The results of Section 5.3 have been reproduced",
              "weight": 2,
              "sub_tasks": [
                {
                  "id": "c10241e2-9884-4a34-bfee-89766eaffd0d",
                  "requirements": "The results shown in Figure 2a and Figure 4 have been reproduced",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "1c8f023b-4113-43bb-b8c1-f117c508d848",
                      "requirements": "LBCS and the 7 baselines have been evaluated for selecting the optimal coreset to train on 30% and 50% noised F-MNIST",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "78fc3eea-086e-4108-93a3-3df3af977dcb",
                          "requirements": "Code that is agnostic to the predefined coreset size and benchmark has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "82a75f42-a920-4c22-a101-b15b52ad1969",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the noised F-MNIST benchmarks, a LeNet can be used as the proxy network used for coreset selection",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "cf00c488-ba7f-4538-8811-3cb34543dcfe",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the noised F-MNIST benchmarks, when training the proxy network for coreset selection, this network can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "a9bad17f-eabf-4f9d-8173-ba34f4028ff5",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the noised F-MNIST benchmarks, the test accuracy of the model trained on the selected coreset and evaluated on the on the vanilla F-MNIST test sets can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "a20ef457-cdd6-41b9-9412-5cb9a4ec0283",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the noised F-MNIST benchmarks, a LeNet can be used as the network trained after coreset selection on the selected coreset and evaluated on the vanilla F-MNIST test sets",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cc85453d-68a3-4b07-8c8c-81ebc6d0e093",
                          "requirements": "LBCS and the 7 Baselines have been evaluated on the 30% noised F-MNIST",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "4ffcff0a-f8a4-4d4d-83a9-dbdd514dc5d0",
                              "requirements": "30% noised F-MNIST can be used for training (while testing on vanilla)",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3085bbd6-700c-428e-bf87-d207ae2ea45c",
                                  "requirements": "Code has been implemented such that a symmetric label noise can been applied to a random 30% of the F-MNIST train set (the test set is kept vanilla), as described in section 5.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Data Processing & Preparation"
                                },
                                {
                                  "id": "4be70e99-34b3-416f-8ba8-7fb4dd34002a",
                                  "requirements": "A symmetric label noise has been applied to a random 30% of the F-MNIST train set (the test set is kept vanilla), as described in section 5.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Data Processing & Preparation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b7f7180b-6fc3-4188-b1d4-c14a1ec044fb",
                              "requirements": "LBCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "fc762cbf-ab4e-4f09-94ee-f7b4c50874d6",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the 30% noised F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the outer loop can run for 500 iterations (i.e. T=500)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "678c3022-a475-457e-ac65-f0d5650af85c",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the 30% noised F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "fc64eedf-c360-4c16-9e61-726ae5383f62",
                                  "requirements": "LBCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "943fb93f-d041-478e-8006-ce70d20a2a6d",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=1000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "736b8af7-24bf-4a42-82e7-1c5421dc8d7b",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5b340c99-42ee-43a4-a2e1-9a61bef323aa",
                                  "requirements": "LBCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "21086ad4-4659-44a0-a54a-1f663d390ba4",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b25bf7e7-27ad-4860-b2c7-df51c9e624cb",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "fc7495d4-dd4a-4154-a08a-c3fda8eda7cc",
                                  "requirements": "LBCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "94c7d92b-dd04-4d07-b81a-cfe8c0f15a45",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a6be3583-fbcf-4af6-b905-42f4ab7b5834",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "040e4678-c9e9-4cb2-b717-6aec8000e422",
                                  "requirements": "LBCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d7dc7903-6f04-4110-9987-a2681dbc9729",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "54e36f77-ba7a-48a9-955b-ba26225afa89",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c66a1ce4-d82f-4808-a37c-4f161d9b83fa",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "031c10d1-c4e7-4b7d-94b6-4f71da9719dc",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "67f81a5f-7d86-465f-bb76-18e4c0494aa1",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "50f6c386-d6cd-4196-95ec-2b77f1dff2de",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f8735c0b-6d99-40c1-a0a7-45fead901a1a",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7e762a8c-07db-4a4c-8537-ed41c02fd374",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8acf217b-aac8-419e-b4b2-6d017e179b6c",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5f55e92c-d0bf-4fbe-8da9-3bfa72b1b7ee",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "244ceabc-c1e5-4cc9-948c-eff45bbd3232",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "c55c4c82-7d3c-4583-80fe-be097be2d887",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e140928b-dd78-4ccb-a18a-ff3fd8d18c2c",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1a25433c-a7fe-4128-b03c-8bffda668c42",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "068a8abb-5a6c-4d56-91c4-56f14ac266d3",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c473137f-e7ad-4570-94ee-61d14166b815",
                              "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9b88fd2d-fdf5-496a-b5b8-982063164dd8",
                                  "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "dcdb20e3-99f7-433d-b987-d722779f816c",
                                      "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3ffdd605-d339-45f5-8bd0-d683eb4f5b9e",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "458fa16b-e881-4b92-8874-f370185910c4",
                                  "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "691ade63-c0a0-48b6-84a0-a32df7aa0390",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d6088e9f-d45f-414a-bcec-d98eb4546fa4",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "dc07e603-9be7-4fda-8a8b-4374b42d229f",
                                  "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f65c5db9-5478-48bc-a595-ffed9b192164",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "58146277-0af5-4f1c-bd47-478b69dd0642",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "36fb7b9c-4fd4-46b4-a424-2c926c856cac",
                                  "requirements": "EL2N has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4c3b3501-87fc-4577-aa35-92fedf3c947b",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "34625f66-2bb7-4911-a1b0-2f4d26e1e6a3",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "c5e9bfc6-a945-411e-8230-293715b04d06",
                              "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7ccf3160-2ae0-43b3-9899-6bd4f5037f0b",
                                  "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ef81e7aa-4430-4d4f-9008-10add11133e3",
                                      "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "b01e10cd-89b2-4149-ad54-3e66a92a70bd",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f7d1caa8-c7dc-4a40-bd8e-6d4d82f8d3c0",
                                  "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "37c65907-3de6-4a2e-a506-1c99ca71a58e",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2e97e6f1-7dbd-4e40-94bc-755181319278",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f5f80cb3-f93c-4f5c-a77c-662c1a779a7c",
                                  "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8eb04e99-ad2e-4bbc-aaeb-973645a44655",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "d912014c-9c9f-49d7-81d7-65adfddb39ef",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d03f7da4-0e1e-48f7-9625-9d014f69c5c1",
                                  "requirements": "GraNd has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1e7e5b48-51f8-4b74-acb0-995e928a751b",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "d1219e14-b194-49be-b66c-25697dcce27e",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6225d8b3-bcc5-4f80-ae93-2c232bc9858d",
                              "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ce8cb9b1-84e5-4056-8a16-ce7811bd0428",
                                  "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9e285e26-7538-42c7-b510-b18d343f3fcb",
                                      "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5e052530-9ffb-4843-864c-2dad4c83956d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0f2d513d-e1c0-45b8-a6a6-bfe9a7168cde",
                                  "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c27488bd-c1cc-41a0-8d90-ce3ef097bfde",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "59e857e3-42d6-431e-bacb-bb57f159bf8f",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "81a144e6-c16b-4f5b-9cf8-83de7e89c84e",
                                  "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7b80a579-5bf4-42fc-b2eb-9308b3e976fd",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c9652e26-60d9-455a-af79-4e7c7c8a9210",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8e751fbc-f2fb-4e00-affc-ce4600083336",
                                  "requirements": "Influential coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0bf8083d-c7a0-4b9a-98e2-88a9f52e0b20",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "799ed8e8-f24d-4984-9c7a-7bafbf75930d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "bb3c8af2-f758-4955-b8e9-7b4673d45a0c",
                              "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6a750b1e-5cbf-4a7b-acd1-2846ab884ff4",
                                  "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9449d7d2-ac9f-4fe9-81ab-7fbb1777561a",
                                      "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "db68ceb7-79e9-43ed-a286-d1ebbe6666d4",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0b5f731e-f07b-4d72-b447-86b66a086d92",
                                  "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "71ea56ee-bad7-45ee-839e-08d6a2823ec1",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "51902606-7b69-4ecd-b054-d2524d4684b3",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "39974ea2-4114-441a-8244-d1d9c5851543",
                                  "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2e5c496b-d522-442b-95c4-def786f61710",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "166a30c5-90f4-4f24-afbb-530fc4939d6a",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "84b09ebf-254d-43d8-bc6a-f2c4e8bd0de4",
                                  "requirements": "Moderate coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4ae5466d-67a1-4c81-addf-05d252e86811",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "88a9adbb-bb70-4281-8a5d-c74bf38c5686",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "63a75dce-e6d1-4eb6-a3bd-ca99293915e6",
                              "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "badb21a7-9484-45ef-8641-38bd8fbe481f",
                                  "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "29b133de-0fd0-4f98-aef1-16d8644d97e1",
                                      "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e2c0b7f9-3fb9-460f-afec-95fbd0c6653d",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c2ed997d-66c9-4f04-bc03-766446f1e12c",
                                  "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ede91c5f-fe32-4a82-91ba-8b0fb83e7636",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "84be3b2a-82b5-4ea3-a2ff-f810470143ce",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b2badf23-2a99-4d94-925d-243b389462e0",
                                  "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8245a7ad-b2f9-4eb0-834b-028dd505feca",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "0b44736a-afa9-484a-ac8b-c6e749603d32",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5d704be7-1986-4a21-9713-a31d0ffb3df4",
                                  "requirements": "CCS has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "af129b6b-05c4-43e6-8676-4431783ebf44",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f6cb645f-75b2-4bc4-bb68-5538a2e04d79",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "be3d6356-9792-40b1-8f68-9b9a512e3abe",
                              "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d88ad4ee-dcdd-4edd-8175-1dc6509d909a",
                                  "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f83a4cec-51c4-4a33-8544-9ab63d84cd6b",
                                      "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "7e3dfa20-b248-4798-b48a-872169374fce",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9c2196e7-7c72-41e8-a8d7-b099a1699aa4",
                                  "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a59a3a7b-90ea-464b-a6db-667b047a44d4",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "446f3c8c-58ef-4936-9335-d3661cac1b97",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "82b5f5f4-2799-49cc-b564-e15542dd8c30",
                                  "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "12afc425-5be6-4238-8e73-efb17104d1c5",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "db0e9914-e1cb-484f-a2c9-d2731780991d",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c6e7ea41-11e4-4455-8867-e9375ca8a2d7",
                                  "requirements": "Probabilistic coreset has been evaluated on the 30% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d45436ce-cf41-487a-844b-ee4e6c5172a4",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 30% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "6101343c-f5d1-42d9-9948-43baeb85c79c",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 30% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "efe1afe8-2fc1-4370-9dbe-fe0e3d3e3311",
                          "requirements": "LBCS and the 7 Baselines have been evaluated on the 50% noised F-MNIST",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "70b3897f-2feb-4e41-b4f7-afddb5579839",
                              "requirements": "50% noised F-MNIST can be used for training (while testing on vanilla)",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5c8e319a-01b6-434f-a0b9-1dd9878511a7",
                                  "requirements": "Code has been implemented such that a symmetric label noise can been applied to a random 50% of the F-MNIST train set (the test set is kept vanilla), as described in section 5.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Data Processing & Preparation"
                                },
                                {
                                  "id": "57e0a4b1-ed05-429e-875e-c11e9c2c66f8",
                                  "requirements": "A symmetric label noise has been applied to a random 50% of the F-MNIST train set (the test set is kept vanilla), as described in section 5.3",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Data Processing & Preparation"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "463b9602-00f8-497e-9f63-5388c93ed5bb",
                              "requirements": "LBCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "500e30ac-f8fc-4642-9d68-5ace86220493",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the 50% noised F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the outer loop can run for 500 iterations (i.e. T=500)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "233f95ed-0dd1-4324-946d-a694493650f9",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the 50% noised F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "bf61a2bc-30b0-4bb5-be16-aaa63a177cc4",
                                  "requirements": "LBCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6d750071-552f-4170-b704-991dd14102cb",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=1000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "2e3feb65-7da1-4649-b98d-c16f931d60f7",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "7c462f6a-3f21-4a6d-b98e-4060a93ae0c4",
                                  "requirements": "LBCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3448fa35-b052-4fb4-a35a-4b35a8ab28f4",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "3f4cf387-39aa-4efb-9023-6a64c930281c",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "078fc064-37b9-4226-94d0-845852f5f43c",
                                  "requirements": "LBCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4a5ee741-11a5-414c-a6a8-2dc467717b37",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2d39547b-f4a2-45b9-9b1f-7ba8f35f55bd",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "44061f6b-d27a-44d4-a0e1-ee54e76b5fff",
                                  "requirements": "LBCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1b5983a5-acd8-426d-a676-b7ba30110d86",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "8ee30d01-dee3-48d3-93b0-5c94b14c432a",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "403a27d2-4945-43c8-9f6c-3f93e6d4de69",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "860e5d73-4e1e-45fa-a1f4-a78b5505681e",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "103062b4-dcdb-4d03-af02-89bf10a2c572",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0d523955-e08e-40ab-945b-8628ea515fca",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0f2a0c11-735c-49f1-b016-711c7379c268",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f2ee66f5-f3a5-4320-8b29-90eb423693a9",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "e8ba2910-027e-4526-a17e-881375008c16",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d996c5ea-f1f1-4044-b46c-c97b8a7990e9",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5a46ae65-ee7c-4a20-ac4f-2a8891edee1b",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "c3bc62b6-b6d8-41fb-94f2-c1380eaa6487",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0e3a1171-029f-431e-83a3-1e964a7f4072",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2366a8f2-1f00-4774-a28a-6627e57c4bf3",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "24892231-0b7c-4a51-bf9f-f23ea77a0e84",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d1bfc396-d50c-45cb-b181-d169d4606afa",
                              "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6587a5ca-7b50-4e46-820a-c0ea608ea0f1",
                                  "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "bdb095ab-3c03-4a5d-a795-97fe67959b0f",
                                      "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5c73f767-53d2-41f1-a70c-77393bce3aba",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "fd248848-02cd-4bd8-b5d0-ba3bbabbd7ac",
                                  "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5ce0a003-5d23-46fc-acad-e8258dc891b8",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6b73941f-1057-498d-b29f-509b2cfdd72e",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c2c15701-2c19-45c7-af0c-16c1829fd9d2",
                                  "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "752d41f2-5c24-42d2-9970-22df8ceffd07",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "cb995cf0-fada-45d7-b9bf-76edfbe26469",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1c0001b8-7449-46a0-ac45-57182e02cab9",
                                  "requirements": "EL2N has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "787ae1c0-7a08-4707-8e4f-6a2d50817d53",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "057b9dae-73c4-4326-9322-9c20ef9ae1c4",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "98c57f57-f9cb-41cd-bc94-30b6153a53fc",
                              "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6589a202-bd8c-4b36-b15f-a23c8f28fbc8",
                                  "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "11b21b8e-ae74-424b-a549-245f7c14161d",
                                      "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a7c8d395-de2c-4c30-a4d5-57c9b365983e",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "5ccdbc15-a36f-4451-a481-8492579bd4e1",
                                  "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "67b6b631-57d0-49f9-99c8-22b8279b93cc",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4c33ffd1-e447-4fd8-9767-e09ad5738399",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "4b604959-8669-4d44-9fe5-369a3d2998da",
                                  "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c3d1aa8b-3e5e-4a0c-ac12-b3485b0d3562",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f13c3637-8af6-48e7-ac77-2117da6b4096",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "432f0f3f-0b2b-4f90-a557-cf119c38b3a2",
                                  "requirements": "GraNd has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a8c595a2-e90a-410c-a6bb-2a6c6b458db7",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1a18ce10-59b9-41f7-943d-d933b38e5b16",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "42feb4b0-bf0d-4450-bc63-db37e0291013",
                              "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a6f17f14-3bc8-4876-984e-c049d2489117",
                                  "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "0bfd491c-525d-4715-9ed9-bdc21f62c422",
                                      "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "d2a60206-82f9-4499-9f6d-c7341f8f5b51",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b52ca55b-3406-4db4-b651-e2919dc2f280",
                                  "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c72831e5-67f6-4f9c-8d61-938a20345295",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "72296674-a1f7-4f2d-b30b-634f30f663f6",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3236b3c8-2445-4938-a1df-1a8da73543b5",
                                  "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1c1fc13f-6056-4fcc-b215-cbccd7bd6ee2",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ea484399-2dea-4c85-8391-cb5445861134",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1df1ab38-902d-4bd7-b75d-4477d96bc870",
                                  "requirements": "Influential coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9cc0d46f-a5c6-4bea-85d5-d493dbad1a37",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4f8d7a9e-7eab-4b38-b403-e90b80f46e4d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9d38da76-86d9-4976-a496-e0e170f1f787",
                              "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a6a012f8-68c9-4dab-8476-4559b85318fe",
                                  "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5cd46f4b-411a-4bee-bd05-1e6179736f90",
                                      "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a57ca522-0f8d-4c49-9fee-866842816f4f",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "13d77db0-9b3b-4ff7-b9d5-b564d861ec30",
                                  "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4a416604-23c9-4de8-88b6-3b43f31157ad",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1c30b5df-af3a-4f93-bc76-317e6f1f5f08",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "49651e37-a029-4c45-98d9-99138f7ebea7",
                                  "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "714c54d1-bafc-4799-b65a-d0dd1bd49b08",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "345fb151-5c85-4432-94a7-cee155f7a96a",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "24cf4172-7986-4d07-af3c-1cb1c53c76ce",
                                  "requirements": "Moderate coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "77c0b36f-a362-408f-a159-a8f8294c1558",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6ca9df48-2bed-453d-b667-5863cef271ec",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "34c7ed45-5a21-4eb0-862c-e1a79b16527e",
                              "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "187755aa-d987-4731-83b7-dd24dc717e6c",
                                  "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6ec4dc6c-02e6-4458-821a-24d31821ce86",
                                      "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b75e2f7d-6aeb-4fb1-abfe-9c2688a97cfe",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "72fa19e9-5470-49d9-b0d9-f0d5033bcbcf",
                                  "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "7423d197-91f4-48f6-89be-ddc98ef19b45",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e3a47d91-4015-497d-bd1b-a35d89ad038f",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "761abc5d-d28f-4fea-aa37-3a52cfed711a",
                                  "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "aaee9ac6-2108-4ce9-bc7b-9ac68d821a90",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "62ed9509-a6a9-4373-9303-0bfc2ccf3fbf",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "6911ca7e-0b7f-4f38-a4bb-a99a8515dca4",
                                  "requirements": "CCS has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d0f59c57-95a6-4174-a3e7-654d95140541",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "9c0c70a6-ac03-46de-9e71-575de4373c9a",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "33dbd854-d161-4173-9a65-057c54025ba6",
                              "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6451062d-c746-4796-8530-722d9a4bffb0",
                                  "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d3c4ec39-463b-4950-9108-383656ba67f2",
                                      "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ea3cc1ab-010c-4e14-8d91-d98941cb63cb",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c900f8bb-b096-4543-85eb-86abd6b004e7",
                                  "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "166bc445-f6da-4695-b7d4-e2b3c704e380",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "20ab4170-d43d-4e24-8b17-113d44cfa81b",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2b05677a-5970-49fc-976d-21634ffd248d",
                                  "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "261ee630-f9fd-49e1-bd1d-43ba783cc6fc",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "df1de2be-fbaf-4a21-a1bc-3493b731a73d",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "63309546-a2f4-49ae-9fd5-1403ae4d5cc1",
                                  "requirements": "Probabilistic coreset has been evaluated on the 50% noised F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d00b5219-1fd3-4ea7-a375-e87113c00215",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the 50% noised F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3cd15aaf-ec75-456e-8da5-164abe050f90",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on 50% noised F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "3873966a-1fe5-47cd-9f3c-f7d4760e6220",
                      "requirements": "The test accuracy measured on the 30% and vanilla F-MNIST test set shows that across all methods and predefined coreset sizes, the model trained on the coreset selected via LBCS always achieves the highest test accuracy",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5170b55e-2ac7-4e6b-9d66-ef17665bcbd9",
                  "requirements": "The results shown in Figure 2b have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "f747fada-ca11-4abf-8313-5bf6112b956a",
                      "requirements": "LBCS and the 7 Baselines have been evaluated on the class-imbalanced F-MNIST",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ac5c415c-a648-433b-8990-10772bdf7c57",
                          "requirements": "class-imbalanced F-MNIST can be used for training (while testing on vanilla)",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "930a8e27-8816-4a03-a71b-d1da50d16a7c",
                              "requirements": "Code has been implemented such that a class-imbalanced version of F-MNIST train set (the test set is kept vanilla) can be constructed, as described in section 5.3 and in the addendum",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Data Processing & Preparation"
                            },
                            {
                              "id": "2f267f5d-3940-4dff-99c7-ae9e7263cece",
                              "requirements": "Class-imbalanced versions of the F-MNIST train set (the test set is kept vanilla) have been created, as described in section 5.3 and in the addendum",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Data Processing & Preparation"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "1cd19b9c-d2c8-4c7c-9be5-a0a8300ede86",
                          "requirements": "LBCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "513aed24-c9d4-4fbb-b234-30afd6695e1b",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the class-imbalanced F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the outer loop can run for 500 iterations (i.e. T=500)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "258784e2-2e44-4596-ad10-19ccc320fc5b",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the class-imbalanced F-MNIST benchmark at a given predefined coreset size using a LeNet after coreset selection, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "d1cbc1a9-48d4-47a1-b5de-ded24e4fb149",
                              "requirements": "LBCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "25fbbf63-c0e0-493b-bb63-413dcbecf8ed",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=1000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "3f4635e9-4523-4241-b911-0b99345bd5db",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "28ea1410-6ada-4d06-afd1-0b68ab6abb89",
                              "requirements": "LBCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "99b3c8c4-a588-4fc6-911b-91d70970c06e",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "2500121c-fd63-40ed-adef-2a882043d993",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1992b73b-773c-4aed-95f5-1ec598be8ddd",
                              "requirements": "LBCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "54620b7e-0cfb-4648-b74d-cc744cb3caa0",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c8446f48-9746-409b-88d4-4c07dda2a105",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "63f879c4-c8b9-41db-aa20-dc283e825391",
                              "requirements": "LBCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "41bf54af-859b-4a65-99d4-f87f5d771659",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "95dbdcf3-9e8d-40e9-9868-22a61e0e9ed3",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a277915b-c45e-42d9-bcc5-0e8bbfb30843",
                          "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "64daf93b-aa57-468b-a8a1-b9e0e8ab2ad7",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4638e9e2-e048-4874-9cb0-26233368e485",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "4028cb4c-9150-4355-97b2-57ed0fef2a3f",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "af81e6b2-f4c3-4643-a2bd-b1b1a9439c36",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d777ee74-d13b-447b-bd08-041724846d8e",
                                  "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "5e6f2524-912c-4b59-9473-57de15b3084c",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "3b2b8d67-610e-4894-813e-e3ceeae92ae7",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0fd2fe83-5e04-4f97-8d73-4491487a007f",
                                  "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "a39df9b2-0ce3-48f7-8bf0-78f0a4a23631",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "80039129-d7e7-40ec-9358-bc35ecd8bef2",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8e343793-5bcd-4536-8b11-f9be08699bf1",
                                  "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "835a2adb-f9dd-43f4-aab5-b60fa0cadd97",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "98a0ae26-0eca-42c5-8a57-ddcd9d099716",
                          "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d6f3f4be-4676-4dda-a232-1b30ea8ce1a7",
                              "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "947be243-6155-4a23-929d-ef70f269f569",
                                  "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3f3dbe50-bd5d-48a3-9bc1-9ffb87f56b52",
                                  "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "45e40270-13c8-4b47-853c-6fc4417af5b2",
                              "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "464cff24-9d62-4677-984c-47751e397a6f",
                                  "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c200d688-130e-4d37-a256-33bb6f86b57d",
                                  "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "342247a1-35db-48dd-a065-7df5a503b2d6",
                              "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0564b2f0-436c-49dc-bdf3-811628ea6443",
                                  "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "c5ac458a-1592-4198-98e0-18291f57815e",
                                  "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e1d3c148-9682-443c-a038-cc70cd21c353",
                              "requirements": "EL2N has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0c386c7a-ffa5-40b5-9c2b-4129ce443e95",
                                  "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "cccb4461-092a-487f-b51f-7cdbc39fdd0f",
                                  "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8788bac4-8f09-4fa1-b224-81604ecbd0b7",
                          "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "7db87bd5-774c-4e5f-a5b9-9b68e1401e92",
                              "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f29ad235-8048-4613-b4dc-9d8ed632fd27",
                                  "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "5ff66795-921d-418c-8ddb-2527bf802944",
                                  "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "afc3bdf1-8332-4099-b07c-5eadd83400dc",
                              "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d0b1c40c-9d94-474a-8e6b-172176b96826",
                                  "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "87fcf7f9-ec29-422a-ba8b-da7996e83493",
                                  "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9ad82027-71d4-4ae4-b654-5134330bf78c",
                              "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ffd15c79-7e89-43ff-b95a-f530329b0f2c",
                                  "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "ed0afabf-4bf3-4267-83c9-0361c7cd367f",
                                  "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "081b8da7-7c34-4d49-abf5-9f1a26aeb8ee",
                              "requirements": "GraNd has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "b9ad4349-5ca7-4bdc-972c-33ea0d2d56cd",
                                  "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "a13d07d3-a0c4-4444-9be3-2a16b37c688e",
                                  "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a1742c98-379f-43dd-be06-649bf6722a05",
                          "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "11b64403-4df3-4cef-acfc-441130dc9f96",
                              "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "62887b49-2388-4816-8705-de0411f55b9d",
                                  "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "1481a490-e2bf-40fd-8c06-d04ac715ae8f",
                                  "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1041b70e-d13d-4b27-a436-bc2c66dee776",
                              "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5d8bcaa9-b0f7-43ee-8b2b-33e0041b5671",
                                  "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "78f8babb-ae3d-4762-932c-c608a654ef3f",
                                  "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "81737a9e-bbc5-46f3-ac35-a94252fe3a3a",
                              "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "53997471-59d9-4b1b-b688-d2fd78ae653f",
                                  "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "00d40179-e45a-435b-ac19-267d3a95e093",
                                  "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "0b2437e1-8eae-4c62-abe1-4b3b376232b7",
                              "requirements": "Influential coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3df589f7-5769-4ad4-9d64-33d95b99f4ff",
                                  "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "19ff6624-d843-4439-a730-741ed16d69b1",
                                  "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "8a643331-d1d3-44cd-a312-edd0fa290a24",
                          "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "2c505dc7-8022-4999-8d7c-8076461d3a03",
                              "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "93bdc5c6-8501-4ec5-a2ea-48d515ef8651",
                                  "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "8d91803b-ef13-435b-b5c0-ad2f669a4db4",
                                  "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "1a4ee946-ad80-4c64-9415-8b90d6fc1b9a",
                              "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "516d3b43-0f68-4d64-93c2-41c5eebb30aa",
                                  "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "8c79bb94-a5d8-40f6-a36d-3017d3c71ca0",
                                  "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b7a95b5b-5241-4216-9fdd-bd9d32379b94",
                              "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ca61d3ed-8c78-43d0-b255-624a251574ae",
                                  "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "04f9e827-f7fa-46a5-9c76-5649160171ba",
                                  "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "89819da7-6a3c-45b6-8291-2c42d1be2b6a",
                              "requirements": "Moderate coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a5e308a7-6223-46b5-b6b6-df7efd9ecc22",
                                  "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "64d67d8f-223a-4a5c-bf33-74cb0b754f68",
                                  "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "9e2bac7a-07a2-442b-adee-0872c3780821",
                          "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9b706e61-48c3-4c95-ba80-b8f61a33b358",
                              "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "276ceb61-6288-430f-9b8c-3a142b9cab15",
                                  "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "375c0c18-8a97-47c8-a800-95aaf0d63aeb",
                                  "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b114fabb-ece1-43a1-bfcd-458ed0600146",
                              "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "1a39c5b7-4b04-4301-bfad-e8597531a079",
                                  "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "3d2b2c72-935d-443e-820d-b5d94709d0b7",
                                  "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "64905c07-14bb-47ad-9866-a2507e543ac5",
                              "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "6b845394-4022-49cd-843f-b24865303e64",
                                  "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "112d98cc-ea46-4229-beb5-d6822624da3f",
                                  "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "0fba0f5e-63e2-4a31-86ea-bb4236788a53",
                              "requirements": "CCS has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "2739a340-b573-49eb-9b59-57cb03f6919a",
                                  "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "328b084a-4eed-4159-857d-1626a6df8182",
                                  "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "726b95ca-a2f7-4954-a0f0-a6fc1712790b",
                          "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8d496c4f-2c67-4988-8897-c0d8c077bce8",
                              "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ca3e414b-941f-412f-bead-649db50aa7ff",
                                  "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "b4cabd86-bcc7-4198-a63d-6ae61c97acdd",
                                  "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e9301dd8-b194-42bd-922e-eccd39dc0786",
                              "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3f17d3d5-6b9a-43a9-8065-9afe6561e08b",
                                  "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9aca04ea-e434-4158-8b51-1551003b1b69",
                                  "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "26879888-8cd1-4035-8cba-431555d36b7c",
                              "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "925b0684-3038-4966-9712-aa953ee07e91",
                                  "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=3000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "663d6f90-4e6c-445a-b0a6-e1fcf2e3dab7",
                                  "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "676b6878-2a37-436b-875e-a8d1a36d1ba8",
                              "requirements": "Probabilistic coreset has been evaluated on the class-imbalanced F-MNIST benchmark using a LeNet after coreset selection with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9f51191b-e458-4427-8dda-a6042540d1fe",
                                  "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the class-imbalanced F-MNIST benchmark with a predefined coreset size of k=4000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "16096984-1dfd-4353-a9a4-f4cc3e79e369",
                                  "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on class-imbalanced F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of a LeNet trained on the constructed coreset on the vanilla F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "a5326cbf-f961-4067-aeb7-9ec8958a3ac0",
                      "requirements": "The test accuracy measured on the vanilla F-MNIST test set shows that across all methods and predefined coreset sizes, the model trained on the coreset selected via LBCS always achieves the highest test accuracy",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "052205bd-5ae0-4e4b-992d-2fd90fb0596b",
              "requirements": "The results of Section 6 have been reproduced",
              "weight": 3,
              "sub_tasks": [
                {
                  "id": "0a1a0526-702e-4348-8c56-2cdc94e39770",
                  "requirements": "The results of Table 9 have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "4193972e-c772-432e-839f-c3b10bb6eb9f",
                      "requirements": "LBCS has been evaluated on F-MNIST at increasing search times (i.e. number of outer loop iterations, T) values, at k=1000 and k=2000. The final coreset size and test accuracy have been measured",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2686a92a-050c-451f-810a-adb66b47bdf5",
                          "requirements": "Code that is agnostic to the predefined coreset size and and search time has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a684b3a9-1503-4cca-9da0-44e77485524e",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, a LeNet can be used as the proxy network used for coreset selection",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "048d126e-8111-4bca-8b99-68d7f5ea6426",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, when training the proxy network for coreset selection, this network can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "006eb509-27e6-4a52-a6be-bc0d98262038",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, a LeNet can be used as the network trained after coreset selection on the selected coreset and evaluated on the F-MNIST test set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "1465d976-1ca1-445f-b5ff-841be5fa8c60",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, the test accuracy of the model trained on the selected coreset and evaluated on the benchmark test set can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5e856e01-f270-4917-93d4-0bddaa7de547",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, the final coreset size at the end of LBCS can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2fbe75d2-6546-4ac7-a91f-d9069990520a",
                              "requirements": "Code has been implemented such that to evaluate LBCS on the F-MNIST benchmark at different search times, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "32eb329d-0c9b-44e0-b305-f7d14af6aee0",
                          "requirements": "LBCS has been evaluated on F-MNIST at increasing search times (i.e. number of outer loop iterations, T) values, at k=1000. The final coreset size and test accuracy have been measured",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "02768271-7a77-470a-9c9e-8801c989f8aa",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 100.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3a774b08-ecb4-40ee-9b72-67626d257749",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 100, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "03172991-43c0-4d99-aa95-87dd02b9ccf8",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 100 for constructing the optimal coreset for training a LeNet on F-MNIST.  A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e4e27a1c-f7a5-4dac-bf0b-7794c4b63ed9",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 200.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "06748d42-3ff8-4ed1-b3f8-793daeae54bf",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 200, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "68257fc1-b32f-45f5-ab8c-bbf4c3e69c4b",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 200 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "65c22473-09b0-4abb-97a7-549d9aa35f12",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 300.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "7e52b162-63e9-438a-8113-5bb64f38548f",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 300, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "de023211-56d6-4b96-bcad-9585f8fd65e5",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 300 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "05ee557a-4fa3-42c1-9f15-b0284592536c",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 500.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "360df93f-20f3-454a-bdb8-8e93d81e65e5",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 500, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "07780070-7254-49cb-a68b-c25f6f1816a7",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 500 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d86e0e16-4a12-4f56-9be9-5a6eaa8556a5",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 800.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "00ebd352-4b48-4c1a-bc7d-ed67bde8703c",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 800, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "28be3c4b-b948-44b4-b3a6-ec7fdda9d1fe",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 800 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "51e855ca-818d-42af-8ac0-09357931274f",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 1500.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "c4290c64-c9a9-4472-9014-3762c5f9e822",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 1500, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b7f2fa7a-9cba-403d-a291-b877dc55b4f1",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 1500 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d8025af5-fe80-43c8-a715-d79dc313c86d",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=1000 and a search time of T = 2000.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4b1292d8-f63f-421a-aa5c-1658c46f7f09",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000 and a search time of T = 2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "4eb8aa86-bd31-4278-8869-6b92f9b32a67",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 and search time of T = 2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d4188c88-15d8-4cd9-8131-db429b42633f",
                          "requirements": "LBCS has been evaluated on F-MNIST at increasing search times (i.e. number of outer loop iterations, T) values, at k=2000. The final coreset size and test accuracy have been measured",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a110bae4-311b-472f-8abf-b93c70c9957d",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 100.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "a8386a42-a2ae-4bd8-8bff-fee977653863",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 100, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "5aded0f0-2d75-4be1-8261-508cc04f985a",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 100 for constructing the optimal coreset for training a LeNet on F-MNIST.  A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "ae208364-1d44-4b66-9421-718a130a23b7",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 200.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ee06987d-790a-4a86-89bd-5fef44909257",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 200, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "a54e60d0-8c21-462d-b56a-3bc4aeeb722d",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 200 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "98f33abd-7966-48b1-afbf-efbd18fda61e",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 300.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "9a1437f5-2f53-4d72-b734-3b3e6d9ff1e2",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 300, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9eb2fa4e-eac0-4fe1-9497-dfc2f08e171e",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 300 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "135b8ac9-4860-4657-bcbb-1ea4962f76ec",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 500.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "5982a7b3-fd48-4ccb-9fbe-24d890e7779b",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 500, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "1f5efdbd-d821-403d-b87f-b53237c3a0b3",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 500 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "0101086c-c831-46bd-af7f-362852b1abb1",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 800.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "ac415b95-b72e-41c9-b06e-5a92746905dc",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 800, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "483d8469-f3d6-40ac-872c-b98b47e514b0",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 800 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "8a59e063-ce0f-4577-a105-885236223f82",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 1500.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "888be93e-d881-45d3-859a-50288664a66e",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 1500, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b33c473b-4f3e-49f7-a0e3-bcfe76937930",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 1500 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "568db59b-b973-4f6e-abe7-ab1571e22bca",
                              "requirements": "LBCS has been evaluated on F-MNIST with a predefined coreset size of k=2000 and a search time of T = 2000.",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "f396f0ea-862f-406d-9334-185cd5f484ab",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000 and a search time of T = 2000, using a LeNet after coreset selection",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Method Implementation"
                                },
                                {
                                  "id": "ddb4cb7f-f48d-4f4a-9a78-b915843fc175",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 and search time of T = 2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded. The coreset size selected by LBCS process has been recorded",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "cedc2923-c691-4e7b-84c7-14b5506ff5b7",
                      "requirements": "The results of Table 9 have been reproduced",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "c6d42b4f-cb8e-4448-a01a-ea7f8986fb22",
                          "requirements": "The measured test accuracy over the various search times shows that as search time increases, test accuracy increases before eventually plateauing",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4b6fc77d-cfbe-4e91-832a-85e64123f803",
                          "requirements": "The final coreset sizes recorded over the various search times shows that as search time increases, the coreset size decreases before eventually plateauing",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "28408d11-c185-4f76-8641-0ac4d42fbc91",
                          "requirements": "The final coreset sizes and test accuracies recorded over the various search times shows that as search time increases, the coreset size decrease plateaus after the test accuracy increase plateaus. In other words, we can observe further reductions in coreset size after the maximum test accuracy has been reached, until coreset size also converges",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "fdd60619-2185-4b5f-882d-bd0f4861e26d",
                  "requirements": "The results of Table 5 have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "10a2793f-c528-494c-90b1-655ccfc056e9",
                      "requirements": "LBCS and LBCS+Moderate have been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0425beab-8188-45ba-a1fe-d0e8fc0b30b4",
                          "requirements": "Code that is agnostic to the predefined coreset size and coreset selection method has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d3d922c8-c10b-4911-993d-6000fb145c3c",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST benchmark, a LeNet can be used as the proxy network used for coreset selection",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "851244dd-fd31-49a1-9ef2-fdd81d8d6eca",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST benchmark, when training the proxy network for coreset selection, this network can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "317c6539-9700-4e66-bfd7-142a0ae2e463",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST benchmark, a LeNet can be used as the network trained after coreset selection on the selected coreset and evaluated on the F-MNIST test set",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "71db6074-9a6d-414d-88dc-5e4b27f27e5b",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST benchmark, the test accuracy of the model trained on the selected coreset and evaluated on the benchmark test set can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "aa53806a-0ded-4b2e-97eb-c05fb0b9c68c",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST benchmark, the final coreset size at the end of LBCS can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "10731700-5392-4ca9-9460-ebbb4f62cc4b",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "e08b118b-1aea-4a28-b97a-60bc3a4fb85c",
                              "requirements": "Code has been implemented such that to evaluate LBCS and LBCS+Moderate on the F-MNIST, the outer loop can run for 500 iterations (i.e. T=500)",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "dfbed6ce-e186-4cfb-8004-21d49e0a7b0b",
                          "requirements": "LBCS has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "335d73bd-1a5a-4397-b9e1-ce65ea4eb64f",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "73eb3ef1-4039-4e33-a348-f84bc0e86829",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "819e1cb5-d904-4b3a-9fdd-a21a4a427b85",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9a7ba67d-f940-462d-8771-5bcd7a0e816a",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8b9d17b8-1b51-44cd-8063-4bfef223b097",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "dde6bb9c-5a85-4228-9af9-7acfaa1c6895",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "6244f3c4-d902-4d06-b3f7-91b1fc3f3f5c",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "cd09db17-d148-4909-8fc4-aba6f652cd71",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "9ec3bfe8-1fd0-484e-912d-2773ca2b643f",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "2a25a5e3-617d-4afb-8681-effef9568bdf",
                              "requirements": "LBCS has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "0750d144-6172-4fac-90e2-6b2b43b8c4d5",
                                  "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "cd6e343e-e2c3-4ad5-8b97-b8e8e4094b73",
                                  "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "326d7bdb-50ca-451d-af81-818d31fb8406",
                          "requirements": "LBCS+Moderate has been evaluated on the F-MNIST benchmark at various predefined coreset sizes",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "fe601b7d-c9fe-4ee9-bc8e-27e341bd6b33",
                              "requirements": "LBCS+Moderate has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=1000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e23baee9-0c30-48be-aa59-74eb435ef900",
                                  "requirements": "Code has been implemented such that LBCS+Moderate can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "de6d64cd-a66e-4531-b902-4c91458ac00b",
                                  "requirements": "LBCS+Moderate has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "9df326a2-45b2-4de4-99c5-7693e8e7ba07",
                              "requirements": "LBCS+Moderate has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=2000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "d57b2411-af36-4a4b-a857-d8055b7f1082",
                                  "requirements": "Code has been implemented such that LBCS+Moderate can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                },
                                {
                                  "id": "37dd1b0c-a1df-4521-857f-b1a2d6b045bb",
                                  "requirements": "LBCS+Moderate has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "b97b7abf-b8bf-4f65-9d05-443a523b7e0f",
                              "requirements": "LBCS+Moderate has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=3000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "28cfc788-2c26-4167-9af5-f3b4bae9c983",
                                  "requirements": "Code has been implemented such that LBCS+Moderate can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "b767a3a7-0397-4f57-bf7e-0a91b1a45d01",
                                  "requirements": "LBCS+Moderate has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "64746167-1eb1-4526-b784-f02ceb419ce7",
                              "requirements": "LBCS+Moderate has been evaluated on the F-MNIST benchmark with a predefined coreset size of k=4000",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "136efe47-8225-42aa-becf-7dd03efeb222",
                                  "requirements": "Code has been implemented such that LBCS+Moderate can be evaluated for coreset selection on the F-MNIST benchmark with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "73526f6c-3a96-4e23-9633-4392ddb77c15",
                                  "requirements": "LBCS+Moderate has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a LeNet on F-MNIST. A LeNet was used as the proxy model during coreset selection. The test accuracy of the LeNet trained on the constructed coreset on the F-MNIST test set has been recorded.",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Execution",
                                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "27eff4f5-35db-4771-96c5-64c3f95a20d1",
                      "requirements": "The measured test set accuracy on F-MNIST by the LeNet trained on the coresets selected by LBCS and the coresets selected by LBCS+Moderate shows that across all predefined coreset sizes, LBCS+Moderate achieves the highest test accuracy.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "0808a52d-3935-4e08-a04c-5e1567ed67f7",
                  "requirements": "The results of Table 6 have been reproduced",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9270db2c-e23c-45b8-9078-b9e04e65726b",
                      "requirements": "LBCS and the 7 Baselines have been evaluated on the SVHM benchmark at various predefined coreset sizes using different model architectures after coreset selection",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "6cf8e5ac-123f-4dc7-9aef-a3bfec2d7c6b",
                          "requirements": "Code that is agnostic to the predefined coreset size and evaluated model architecture has been implemented",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "15fa61e5-85da-4571-bf8a-002fa0f61631",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark using different model architectures after coreset selection, the CNN in the left column of Table 7 can be used as the proxy network used for coreset selection",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Method Implementation"
                            },
                            {
                              "id": "6bf53170-7227-46ac-8b39-6a42423dfc50",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark using different model architectures after coreset selection, when training the proxy network for coreset selection, this network can be trained using an Adam optimizer with a learning rate of 0.001",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Experimental Setup"
                            },
                            {
                              "id": "dc278f5a-25d5-44ce-81d5-37cb5e62b140",
                              "requirements": "Code has been implemented such that to evaluate LBCS and the 7 baselines on the SVHM benchmark using different model architectures after coreset selection, the test accuracy of the model trained on the selected coreset and evaluated on the SVHM test set can be measured",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "bbe5ff71-223a-4507-9a7d-486524c13fe0",
                          "requirements": "LBCS and the 7 Baselines have been evaluated on the SVHM benchmark at various predefined coreset sizes using a ViT-small after coreset selection",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "c844703a-bf49-4098-ac34-1c624c448056",
                              "requirements": "LBCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e8496a0e-4d4d-420e-aacc-f9687efc5cb4",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the SVHM benchmark at a given predefined coreset size using a ViT-small after coreset selection, the outer loop can run for 500 iterations (i.e. T=500)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "fe3aaa7c-5ff9-44d1-8dbe-350deac38853",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the SVHM benchmark at a given predefined coreset size using a ViT-small after coreset selection, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "6005590d-4533-46a1-8144-17ecdaec00e8",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "c39b2d71-96fd-467a-8ff2-3113047133de",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "042dc190-d166-4afa-ab5c-5bc0d70b8a7c",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9c5c30a3-3f0f-4252-a069-f2172e4e0499",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "3f192c34-fb54-4745-9d22-140bd1db2039",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8ad03b9c-60b4-4da3-98e4-7054cdb3e164",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "961021d8-0569-43ca-b488-b18b89bfde51",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ec712d88-3cae-488a-a829-0bb678843b92",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "dc0a9a11-37b5-4a9f-9db6-c431da4c1fa0",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f5510bd0-c1ff-45a7-bcae-45269fa50b44",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "314ac60d-894b-46be-af10-369951b4d698",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "afdd82ff-9941-4d7c-9035-17bd007dbfbd",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "5d7edcdd-4eff-45b4-9a05-ad45736d5c0d",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "2e5ad0d6-e79f-4512-bb94-88e69c051e4d",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "493683be-9cc0-41b5-aa2f-c9a6cec40e33",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4f5a5efc-bb7f-4c6d-881b-fa1f3dc2fcf2",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c35fd061-13ad-42bf-9d2f-254b417aa468",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "621b8e74-e301-4ec8-83d2-0e3e02cbdf34",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "1f9323f4-b3fb-4a22-905c-31b0e0739e1c",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d50b980a-143b-4867-b16f-20b6c1758a84",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e927811c-939c-49bd-8287-15677a171951",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "4a00328d-6535-4b78-b0d2-13d0e44ac382",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "abc316cd-f6be-461d-9c87-5435c00eb5b6",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "cb281b54-c77f-4965-b430-a977844cde85",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "77cf4b44-452a-4c45-8412-4ff4406a324d",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d445abf3-5af9-48e3-912c-138ab91ff208",
                              "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e7b50198-8a47-476c-a67f-66aaf372f1aa",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f504b203-69c8-4fb4-bbe4-6c7bcf328ea1",
                                      "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "33c906a1-b004-482d-9c5d-961a6bb49d19",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0c2017cc-5463-4ae8-93a9-3368e861c5ac",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2ee604b1-c348-45d3-ba98-78c1e11f1121",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "6a5dd2c2-a504-4c86-ae9c-bdcd48bf63df",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "53634e64-de17-4ad0-8b8c-2ba24bc87375",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8a236880-c104-4378-93c5-5f12ab82cc0b",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7eaecd22-0bb0-4b8d-85dd-d11ff41edf2d",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ce9fd142-fd0c-431d-ac1d-32527e129bcb",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "47e00313-636b-40fb-a5ca-1586965e7abd",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b780dfae-c2c1-404c-b8a9-bb1346c632e4",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "24c66506-0e8b-4ceb-b26d-28201c600175",
                              "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "bb2d719f-81f2-44b4-b976-1604b5adb0b2",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "15339279-ece3-4bbb-bc3e-ed71d6da51e8",
                                      "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "683a4c5b-3782-4397-83da-075ef81eeb67",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3000e00e-3a39-424a-b2af-3ec70b6ff635",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "84db21e6-e77a-476f-89ff-02fd3d93e58e",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "ae339c2e-88b3-4ad6-a295-74b3753e1211",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2cbb8498-5038-4191-bf79-55fe26d5e092",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "35b3ce48-a060-4d2a-bb14-a844e34e3537",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "023ab642-6324-471d-a7b7-99234619bef2",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f39a7fe0-03c5-4b47-b366-bc6827ab964b",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1e1033e9-2a2e-41d3-896f-e05bc1832582",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7821fed1-bb86-44b9-8ae8-9e2b482e3bf5",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "28d762fc-2c48-43f0-bf85-89168b5c0ad6",
                              "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "3e1689be-a3c0-4f56-bb2d-eb500f79b6c8",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "887261bd-9878-410d-b42e-e95dbd4780ce",
                                      "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3d75d9fb-88b1-4195-80bf-a82d1254eda5",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f51ea453-aadd-41e2-8905-e02316e974b9",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8226e421-848f-48a4-8740-c0dfbb458ad0",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "df62bc66-d762-45b0-8809-0ca295ba57e6",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "407ba4d4-89ee-478b-88af-1449466db8fb",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "00bec2bd-cfe3-47b0-b30a-d981638777ca",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9171e7b2-7e9c-4c53-9cde-1e73879177aa",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "00cc7857-f378-4395-a2b9-39e09585ced1",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "db4a838a-5d95-484f-a2db-5e793cd0e680",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "5f14fa97-1bca-415e-a6a7-34d551e99d45",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e9f80776-659d-4d0c-8c6d-24d7176b4c13",
                              "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "92b22565-3f6c-4d51-9882-040ae5298f56",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2aad894d-f614-4325-937c-71ecb02be3cc",
                                      "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "4f7b3e46-47bc-4714-b7fb-fc6021a6158a",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c0149567-fed7-424d-9eac-f58f24932e37",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a8c081cc-b6be-46de-8217-ecc966286d57",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "1ab3f9f5-0fe1-4df8-a095-f79e232ef5c3",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "611c4979-94b0-4ae6-8818-53e70fdf5d2c",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "5154eb03-023f-4e98-b6fd-978d2d930070",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0f2116c7-1c88-43f9-8e6d-18f4c5152c74",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "77509adf-522f-4255-8307-e911bfd434b8",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "2becc98f-7385-45da-9f0d-0036700a3c3e",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "07d02c05-fe9e-4651-8b9a-dc68ee2468ee",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "e7adb4a2-a3bc-4976-8d74-4fa6973c9692",
                              "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e04285a1-1f7b-42da-bb7c-cb74481a7e77",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f94221e9-622f-44e1-83d4-118d806ab115",
                                      "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "cc221b9d-0ea7-44cf-bd9a-753415b21daf",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ef270645-8000-48f1-b0c0-1de28cbb7b81",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9865100a-05f2-4d4e-baf6-b3dd02c41dc3",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "19efa63e-63a8-4e7c-b2d0-102effe8a0cb",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "eb9185a2-b51b-43ee-a1e5-53588f4c1b1e",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6e5dc902-14f8-4ee6-ae03-2b980b798501",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "8d6e7a81-c43e-4077-8e3d-837acb6ea8c8",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "f8dc56fb-73a4-4260-9538-a4705adf0830",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9edf04e4-c3c7-48ac-ad55-ef1c5e7db632",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "46317804-5f19-4e37-b4a5-dc40b35faddc",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "0c6f0b62-2fbe-4f0a-bf8b-25a81a00e24a",
                              "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8c1fec4c-0cd1-4355-90cd-b33245cfe4fa",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "b269c648-5975-47f7-82ca-c299b978c724",
                                      "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "f271d0ca-9a3e-48b6-bd9f-e94c4ad5a3cb",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2cce5838-a505-496a-9ef2-0f3271866f58",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "686a3c1d-1f14-422d-ad92-7ae021aaaa2b",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "639100a0-5d86-4e19-bf03-af9ed13f1805",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e5957c23-2ac3-4dde-83a5-a26a9403096a",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "27c0ff56-8efc-4981-8d93-af3a0e577105",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ca946417-90fe-48cc-9ad3-119d4525813f",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a ViT-small on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d3f29ff1-97a3-4305-9e2c-cdd6fce2d9a2",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a ViT-small after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "85e7ac35-92a7-4c08-b3d7-63e9ad94c654",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a ViT-small after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "eeb676bf-5ec4-4e02-b59e-6f35a08aee35",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the ViT-small trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e2a3d11a-23ab-490d-bb3d-2e960d958822",
                          "requirements": "LBCS and the 7 Baselines have been evaluated on the SVHM benchmark at various predefined coreset sizes using a WideResNet (W-NET) after coreset selection",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "51a4b0d4-485d-4c01-9fbb-429c43710fd1",
                              "requirements": "LBCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "4e0f9f64-8acb-43b3-a62c-3c30e4272981",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the SVHM benchmark at a given predefined coreset size using a WideResNet (W-NET) after coreset selection, the outer loop can run for 500 iterations (i.e. T=500)",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "187944a9-89db-4011-94f9-26c5ec834562",
                                  "requirements": "Code has been implemented such that to evaluate LBCS on the SVHM benchmark at a given predefined coreset size using a WideResNet (W-NET) after coreset selection, the voluntary performance compromise can be set to $\\epsilon=0.2$",
                                  "weight": 1,
                                  "sub_tasks": [],
                                  "task_category": "Code Development",
                                  "finegrained_task_category": "Experimental Setup"
                                },
                                {
                                  "id": "1c7399a9-e345-4163-b389-cc981985db4c",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "d87a61e3-f3d3-47ff-9343-b4b96da56112",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=1000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "0da37014-db30-4f62-9a6b-d973bdda082b",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "66cd949d-2954-48cd-aa45-ac07058ad78f",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "994bd16c-00e8-4672-9d0a-c8ad346d5094",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "2ab54b6f-ca63-44fb-bc11-75025498525d",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8f5749c2-b4c8-4348-b9b9-fa813005f3fe",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "6548b549-5fcf-4f82-ac6b-728c327768fd",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "fbc659f0-13fa-46a6-820b-cc3a39d53d4f",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "d0191cfb-f74c-42fd-b27c-2c287d8a7056",
                                  "requirements": "LBCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "52998e12-7645-4d82-9632-626d89716840",
                                      "requirements": "Code has been implemented such that LBCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "03128495-e405-4d1c-b069-14aa4fc77f1f",
                                      "requirements": "LBCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "4a6e18bc-c5e1-40b0-a55b-4beb9cd63bd8",
                              "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "8db6f281-466c-4693-bbf3-c1993b78c988",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9cfb83b0-d23e-4de7-8edb-91b4ca191de9",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "7db29f0b-bb4e-46a1-9acf-81045ebf7c44",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9423e82f-7a0d-4909-82dc-ed5c791dd191",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "4435987a-c13b-43ea-b52a-68d85f26a1fe",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "93720b12-464b-43f3-9ea5-591bf97b4f74",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "75a0e6ff-09c2-4260-8327-d9d52b887ea2",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "1fed0985-b628-4891-8b52-9a9c3b9af5f4",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "74a7b202-678a-4a2e-9ac2-41f43a43e613",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "c9b9db60-9f6d-4783-a5d9-b51fd5a6dc91",
                                  "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "66aab0c5-f7fd-41c3-9a4b-f912a391d7e1",
                                      "requirements": "Code has been implemented such that Uniform sampling coreset selection ('Uniform') can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "7a306cd3-8ead-409c-beb7-a62e816db9f3",
                                      "requirements": "Uniform sampling coreset selection ('Uniform') has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "de59b0dd-551a-4bfa-85bc-4b8632f89c74",
                              "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "85590fd3-5df1-40fc-b94d-2c84b87e8a36",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "8c0bbba2-cc84-445f-8832-b1929ac2c00a",
                                      "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "08173690-ca0b-47bf-a9a7-8ee1ab92231c",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "79a04e0b-a33c-4443-aeb0-4aff1cff9420",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "eff46c1c-69ec-4ac3-a730-0ea0e1b6497e",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "e01f23a7-f8c8-455f-8a5b-67b4c95d95b1",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "98bfc7d8-f88f-41eb-8277-ae715edb9c41",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "719b5dc5-512f-42b6-b6b8-259c21a0f12d",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a2bf273c-1299-45ae-94d9-6d22b89aaf4c",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "ffb6cb9e-d719-425f-b8d4-04f24929a809",
                                  "requirements": "EL2N has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "866a4613-586e-4ce6-bb7d-a1c7e99c986d",
                                      "requirements": "Code has been implemented such that EL2N can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "aec0ab30-8253-468b-9991-d1e382a601f0",
                                      "requirements": "EL2N has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "340f05a8-fb56-4ec1-82e9-0b1907a1ebf1",
                              "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "15d827fc-a2b1-4459-b5ea-cf7c3ffda4f7",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "856f5198-7b5d-4689-bdca-79696dda6c30",
                                      "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "38600193-fcfa-4c9e-81ca-286c9adcb1c9",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9841133d-402f-457f-b44e-f46eb6d955bd",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "770cc40f-892a-4161-9c88-1b85a7f04fe2",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "23f1ed75-d9a2-47df-a4d0-a3f90c9716f2",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "0e4e35f3-b74f-495c-b533-b7a7ea07037b",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "75111a91-8741-4ba1-a9d7-67eacb24850e",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "08f579ce-1091-4bb4-8b25-37a6b9e7e8ee",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "3c055705-ac4c-47e6-bc0b-1d638f601896",
                                  "requirements": "GraNd has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "9e8b9c7b-c911-4837-b3ca-8ff05f8faa28",
                                      "requirements": "Code has been implemented such that GraNd can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "27ce5067-768c-49ce-bf68-a7fda473ddc9",
                                      "requirements": "GraNd has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "7f65060d-ef6e-4719-96a3-c525b2b838b6",
                              "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e8dcb47b-9a07-4cce-90fa-eff9d564cf60",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "da6c61f5-a220-4bbd-930f-55669021ecea",
                                      "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "3aa52714-51ae-4cb0-897b-67dddb793670",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "1df51206-62b0-45a1-b180-37080e084122",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ad02f78f-563a-496f-af7f-bb2928294a0f",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "02543486-a36d-488c-b97b-a4ece9aa57e1",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "8e25fcd8-c90f-47f0-bcce-599205ce554e",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "83a59a74-8add-4b82-9d02-774c929764d7",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "440022c4-9cfa-4a6d-8a2b-3468800faa58",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e977ab32-ce44-4e6e-9bbc-3530e2ae217a",
                                  "requirements": "Influential coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "196adc5d-0ee7-469b-bb19-070f91bc02a4",
                                      "requirements": "Code has been implemented such that Influential coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "ea692f08-05cf-4c6c-91e3-b948b33e940d",
                                      "requirements": "Influential coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "13c5abf7-18df-43b8-9d45-638391557eb1",
                              "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "e846d387-83bf-42b6-9f71-159ec6829dd9",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "53d4e311-a415-421e-96dc-b96767b9d155",
                                      "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "faa71e91-4535-4573-a19e-71c1ae6fcc81",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "2e832188-2bd2-41e0-b84c-5c32aa89546d",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "71adba71-c3ea-4561-b5a8-49f8ba1fb638",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "b2c8a304-7d1e-4d60-9958-12ec06d7c003",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "9f8ce9fa-c169-4d9a-b066-86d29202c651",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "a5145277-aa76-432a-b75e-0e75dcae1ef3",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "49336672-f24e-46f0-972c-766285803548",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "911aaa0d-bd92-4308-9c5c-18de43c805d5",
                                  "requirements": "Moderate coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "eb2db30a-cd6f-46a9-8884-4ee5f00818dd",
                                      "requirements": "Code has been implemented such that Moderate coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "8d6cedc1-8471-46e4-96bf-29d300d39247",
                                      "requirements": "Moderate coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "38d32153-0cb3-4594-ac2e-063f570e0045",
                              "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "70ee0c2d-052d-4641-ae36-364d856c44be",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f54b6601-7951-4141-b5e1-01677df52fbc",
                                      "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "60a50f6c-1a59-427b-8a06-1f379ff1fe26",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b5e8dcc6-bfa5-4728-9d0f-b01bc7aa5e99",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "f0de89ab-89a8-4032-8f93-cb4c854a6951",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Experimental Setup"
                                    },
                                    {
                                      "id": "988b0836-9eda-4b8a-886b-e519a6c490cc",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "e3eef60f-4d00-4d2f-975d-143f33db2f66",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "24959bd4-fe35-42c6-ad2d-5f7c42ecce19",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "6a2e65d1-3624-41ec-a3e5-d09652babfac",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "b20d659f-3911-4db6-b1c9-d6b4820ebe74",
                                  "requirements": "CCS has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "991de362-e1ab-47f9-98b4-e7c418fef81e",
                                      "requirements": "Code has been implemented such that CCS can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a634d65b-9853-44d1-ad83-c6bde500f6e4",
                                      "requirements": "CCS has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            },
                            {
                              "id": "d7b5c211-5c9b-484f-9480-dab6f45e172c",
                              "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection at various predefined coreset sizes",
                              "weight": 1,
                              "sub_tasks": [
                                {
                                  "id": "52e70b91-6496-4383-8cf0-2fc965abc618",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e4ffb484-4673-42dc-9f22-6f20919f77fc",
                                      "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=1000",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "9859684c-16d6-4025-bdfd-40b4819fea7c",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=1000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "df390a00-5e1f-4bbb-817d-a69b5604b315",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=2000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "ee9ebde6-03e4-41a1-92f8-76e94f3046f9",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=2000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "13f4ef00-4b55-4852-9bc3-4a905ac9bd4f",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=2000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "47844eec-c815-42f0-9e67-271eb720af7f",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=3000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "13460f4b-622e-4542-974f-2e8fb18dd60f",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=3000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    },
                                    {
                                      "id": "a0ae5f01-c835-4ebc-b868-8e877318aeee",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=3000 for constructing the optimal coreset for training a WideResNet (W-NET) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                },
                                {
                                  "id": "cf5346c5-774a-438d-b178-4f218013e6de",
                                  "requirements": "Probabilistic coreset has been evaluated on the SVHM benchmark using a WideResNet (W-NET) after coreset selection with a predefined coreset size of k=4000",
                                  "weight": 1,
                                  "sub_tasks": [
                                    {
                                      "id": "e06b61c0-0651-47b4-a514-7c2da16405bc",
                                      "requirements": "Code has been implemented such that Probabilistic coreset can be evaluated for coreset selection on the SVHM benchmark with a predefined coreset size of k=4000, using a WideResNet (W-NET) after coreset selection",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Development",
                                      "finegrained_task_category": "Method Implementation"
                                    },
                                    {
                                      "id": "2e6c0a7f-4f64-4069-bb4c-d82022e778f9",
                                      "requirements": "Probabilistic coreset has been evaluated with a predefined coreset size of k=4000 for constructing the optimal coreset for training a CNN (Table 7, center column) on SVHM. The CNN from Table 7, left column was used as the proxy model during coreset selection. The test accuracy of the WideResNet (W-NET) trained on the constructed coreset on the SVHM test set has been recorded.",
                                      "weight": 1,
                                      "sub_tasks": [],
                                      "task_category": "Code Execution",
                                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                                    }
                                  ],
                                  "task_category": null,
                                  "finegrained_task_category": null
                                }
                              ],
                              "task_category": null,
                              "finegrained_task_category": null
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "86e03fa2-da88-4776-919a-482ecf0a1f60",
                      "requirements": "The results of Table 6 have been reproduced",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "92c3bf8d-59e4-462c-a2b4-6e42fcc3ec84",
                          "requirements": "The measured test set accuracy on the SVHN test-set achieved by the ViT trained on the coresets selected by the various coreset selection methods shows that across all methods and all predefined coreset sizes, training on the coreset selected by LBCS always achieves the highest test set accuracy on the SVHN test-set",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "069c26fe-8b36-475d-9b49-e8dcee725a04",
                          "requirements": "The measured test set accuracy on the SVHN test-set achieved by the W-NET trained on the coresets selected by the various coreset selection methods shows that training on the coreset selected by LBCS achieves the highest test set accuracy most of the time, and when it doesn't the test set accuracy achieved via the LBCS-selected coreset remains competitive with (i.e. there is an overlap in values when considering the standard deviations over at least 10 repeats) the best performing coreset selection method",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Result Analysis",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "lca-on-the-line",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "a6aab8b8-9f09-4580-aef3-9fc79ab73b43",
          "requirements": "The paper \"LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies\" has been replicated.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "525020fa-cc8a-4dc5-ba5f-aca602ddc4d7",
              "requirements": "The LCA distance has been implemented, as described in Section 2.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "4fe131d4-617e-4407-9aeb-fd4c9ee71939",
                  "requirements": "Code has been written to find the lowest common ancestor of two nodes, $N_{L C A}\\left(y^{\\prime}, y\\right)$.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "5caeb163-1384-45c1-930c-ff08994fa730",
                  "requirements": "Code has been written to compute the information content of a node.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "b78b143f-cd83-43ef-a578-9b36e31ef873",
                      "requirements": "Code to compute the probability of each node in a given class hierarchy, $p(y)$, has been written. The probability of a node is computed by summing the probabilities of its descendants where leaf nodes are assigned uniform probabilities, as described in the paper \"Hierarchical classification at multiple operating points\".",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "54f426ad-c2c8-48d1-83c7-911b447095f7",
                      "requirements": "Code to compute the information content of a node, $y$, has been implemented via $-\\log_2 p(y)$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "339d75bc-44dc-454b-8ba3-876955340d44",
                  "requirements": "Code has been written to compute the depth of a node $x$ in a tree $T$.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "00438d76-0175-42b3-848b-a2f799e5d5d6",
                  "requirements": "Code has been written to compute the LCA distance between two nodes using information content, $D_{L C A}\\left(y^{\\prime}, y\\right) := f(y) - f\\left(N_{L C A}\\left(y, y^{\\prime}\\right)\\right)$, where $f$ is the information content.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "c7bc93bd-2786-4613-a563-d6d2fdd74938",
                  "requirements": "Code has been written to compute the LCA distance between two nodes using tree depth, $D_{L C A}^P\\left(y^{\\prime}, y\\right):=\\left(P(y)-P\\left(N_{L C A}\\left(y^{\\prime}, y\\right)\\right)\\right)+\\left(P\\left(y^{\\prime}\\right)-P\\left(N_{L C A}\\left(y^{\\prime}, y\\right)\\right)\\right)$, where $P$ is a function which retrieves the depth of node $x$ from a tree $T$.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "ca51e156-4e6f-4859-94ed-6db53ea1d978",
                  "requirements": "The LCA distance for a model on dataset $\\mathcal{M}:=X_1, \\ldots, X_n$ has been implemented as $D_{L C A}(\\text { model }, \\mathcal{M}) := \\frac{1}{n} \\sum_{i=1}^n D_{L C A}\\left(\\widehat{y}_i, y_i\\right) \\Longleftrightarrow y_i \\neq \\widehat{y}_i$ where $\\hat{y}_i$ is the predicted class for sample $X_i$ using the model, $y_i$ is the ground truth class for sample $X_i$, and $y_i \\neq \\hat{y}_i$.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "0d75d2ca-407d-454d-89a7-f83ee253f406",
              "requirements": "The LCA alignment loss has been implemented, as described in Algorithm 1.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "4337ed0c-25a7-496d-8b13-a63bb8337e89",
                  "requirements": "Code has been written to compute the reverse LCA matrix by subtracting the given LCA matrix from 1, as described in Step 2 in Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "9e88cced-9020-4b4d-8127-a83839d76e1d",
                  "requirements": "Code has been written to compute the predicted probabilities from the logits by applying the softmax function along the correct dimension, as described in Step 3 of Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "378d49a1-234b-41ad-9b04-f42dc4b1ef5a",
                  "requirements": "Code has been written to one-hot encode the target labels, as described in Step 4 of Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Data Processing & Preparation"
                },
                {
                  "id": "fdebcd06-4561-4139-a083-51765bfb49cb",
                  "requirements": "Code has been written to compute the standard cross-entropy loss using the one-hot encoded targets and the predicted probabilities, as described in Step 5 of Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "8580ac2c-ca66-4df2-bf28-aeae62f74d46",
                  "requirements": "Code has been written to compute the conditional soft loss as described in Algorithm 1. This should select between computing binary cross-entropy (BCE) loss or a version of cross-entropy loss on the reverse LCA matrix, based on the value of 'alignment_mode', as described in Steps 6 - 10 of Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "2f544cf5-d8ff-4531-90a8-2a992dbae74b",
                  "requirements": "Code has been written to combine the standard loss and the computed soft loss with the lambda weight (e.g., $\\text{total_loss} = $\\lambda$ * \\text{standard_loss} + \\text{soft_loss}) and return the mean loss over the batch, as described in Steps 12 and 13 of Algorithm 1.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "71af47ab-a153-403d-8512-bc68f0639595",
              "requirements": "All 36 Vision Models (VMs) and 39 Vision-Language (VLMs) are available to be queried.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "4aa5179e-5849-49d4-a970-b5eca22883a3",
                  "requirements": "All 36 Vision Models (VMs) are available to be queried.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "89178dc1-4c91-4420-a5a1-ba844f28384d",
                      "requirements": "All 36 VM architectures in Appendix A are enumerated in code.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "da446952-be3f-4055-8fa1-5d55c6a4fdc2",
                      "requirements": "Logic to load the checkpoints of all 36 VMs using the `torchvision` module has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9ab7f2cc-a902-48bf-9d55-fadb11e4a86e",
                  "requirements": "All 39 Vision-Language Models (VLMs) are available to be queried.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "a5e2feb0-ea72-4611-bbe7-c8b04884441b",
                      "requirements": "All 39 VLM architectures in Appendix A are enumerated in code.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "83e9d518-be11-4315-842b-434512252335",
                      "requirements": "Logic to load the checkpoints of all 39 VLMs using the `OpenCLIP` (https://github.com/mlfoundations/open_clip) and CLIP (https://github.com/openai/CLIP) modules has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "73b78d79-28d4-4d50-b96f-d8dc85eafed7",
              "requirements": "The WordNet, in-distribution ImageNet and out-of-distribution ImageNet datasets are available.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "564e124e-11ee-495a-b0af-d1ba420cf9a2",
                  "requirements": "The WordNet dataset is available.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "04800542-0742-493d-bb7a-9dd1618bc4b4",
                      "requirements": "Code to download the WordNet dataset has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "dc47354e-58c6-4124-98ff-3eb78b2d1953",
                      "requirements": "The WordNet dataset has been downloaded.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "364d1ae9-83fa-4202-99f5-b18a07a99521",
                  "requirements": "The in-distribution (in-distribution) ImageNet dataset is available.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "baeb4283-0ea1-4285-bdad-348ae6b47711",
                      "requirements": "Code to download the in-distribution ImageNet dataset has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    },
                    {
                      "id": "5ed585a4-a860-4449-95b1-98f82119e943",
                      "requirements": "The in-distribution ImageNet dataset has been downloaded.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Dataset and Model Acquisition"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "fd568527-e70b-42dd-b078-71e06165b548",
                  "requirements": "The out-of-distribution (out-of-distribution) ImageNet datasets are available.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "56cae509-efed-4b99-841c-77bd89ec688c",
                      "requirements": "The ImageNet-v2 dataset is available.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "99095d00-4cb3-4883-99ca-c2b0c4f4a9ce",
                          "requirements": "Code to download the ImageNet-v2 dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "fed38aad-ecb2-4657-8e5f-c3e2a74c4e69",
                          "requirements": "The ImageNet-v2 dataset has been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "42e4ddfb-55f2-4db9-b4a0-0c9eb9f987c1",
                      "requirements": "The ImageNet-Sketch (ImageNet-S) dataset is available.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b526562e-66e2-442a-8d2f-e03ab022f443",
                          "requirements": "Code to download the ImageNet-Sketch dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "a01f454a-719f-45d4-a46d-20da7f6b6c0e",
                          "requirements": "The ImageNet-Sketch dataset has been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "052ce59d-69e6-4fc4-a195-014d44efb230",
                      "requirements": "The ImageNet-Rendition (ImageNet-R) dataset is available.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "a0691fc4-f8c8-4363-a35c-ecacb8e9b09b",
                          "requirements": "Code to download the ImageNet-Rendition dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "4727aa07-853b-4838-bff8-da8694c39f3f",
                          "requirements": "The ImageNet-Rendition dataset has been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "629f7d3c-2704-44d5-8c70-e822e11c78d9",
                      "requirements": "The ImageNet-Adversarial (ImageNet-A) dataset is available.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d9235995-2ba1-4218-af85-4d6db32b0508",
                          "requirements": "Code to download the ImageNet-Adversarial dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "d3b10c98-dc0e-426b-ab8a-02e42c2c7c08",
                          "requirements": "The ImageNet-Adversarial dataset has been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "1dbc5253-6b29-40dc-b370-22c8a56b0488",
                      "requirements": "The ObjectNet dataset is available.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "a0698105-e5de-42e6-b32d-0605485291c1",
                          "requirements": "Code to download the ObjectNet dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        },
                        {
                          "id": "53bb5699-ed93-4f13-bb0a-4ee168893599",
                          "requirements": "The ObjectNet dataset has been downloaded.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Dataset and Model Acquisition"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "9c32e046-e874-48f4-9f82-58499cb741bc",
              "requirements": "All evaluation metrics have been implemented.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "db79b149-e8a7-4b7a-b5b3-f8c3589b43b0",
                  "requirements": "Code to compute the coefficient of determination, $R^2$, has been implemented according to Equation (2) in Appendix D.1.1 i.e., $R^2=1-\\frac{\\sum_{i=1}^n\\left(y_i-f\\left(x_i\\right)\\right)^2}{\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2}$ where $f(x_i)$ is the prediction of $y_i$ from the model, $\\bar{y}$ is the mean of the actual $y$ values, and $n$ is the number of data points. Min-max scaling has been used to pre-process to input, transforming it to the range [0, 1].",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "c98a690a-0a93-42eb-bee1-f66e408b6f94",
                  "requirements": "Code to compute the Pearson correlation coefficient (PEA) has been implemented according to Equation (3) in Appendix D.1.1 i.e., $r=\\frac{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)\\left(y_i-\\bar{y}\\right)}{\\sqrt{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2} \\sqrt{\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2}}$ where $\\bar{x}$ and $\\bar{y}$ are the mean values of the datasets $x$ and $y$, respectively, and $n$ is the number of data points. Min-max scaling has been used to pre-process to input, transforming it to the range [0, 1].",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "f96bc158-7ccb-490a-bf6f-30c2523245df",
                  "requirements": "Code to compute the Kendall rank correlation coefficient (KEN) has been implemented according to Equation (4) in Appendix D.1.2 i.e., $\\tau=\\frac{\\text { (number of concordant pairs) }- \\text { (number of discordant pairs) }}{\\frac{1}{2} n(n-1)}$ where $n$ is the number of data points. Min-max scaling has been used to pre-process to input, transforming it to the range [0, 1].",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "aa18ad82-bd0a-49e3-b0ba-284ca8908ded",
                  "requirements": "Code to compute the Spearman rank-order correlation coefficient (SPE) has been implemented according to Equation (5) in Appendix D.1.2 i.e., $\\rho=1-\\frac{6 \\sum_{i=1}^n d_i^2}{n\\left(n^2-1\\right)}$ where $d_i$ is the difference between the ranks of corresponding data points in the two datasets and $n$ is the number of data points. Min-max scaling has been used to pre-process to input, transforming it to the range [0, 1].",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "db064bf8-cb08-4bcf-8cde-122c82952b53",
                  "requirements": "Code to compute the Mean Absolute Error (MAE) has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "d50ac494-aa2a-4c58-b95f-12ed16b4a7e2",
                  "requirements": "Code to compute top-1 accuracy has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "3d7f4028-6ced-4fdc-83a7-b499ff7ca402",
                  "requirements": "Code to compute top-5 accuracy has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "be1d1db2-0215-43f7-931e-f25c9651467b",
              "requirements": "Figure 1 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "d59462ba-ebe4-4a04-9319-6bab52eeb4b1",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "44bff6e1-e564-494f-99b1-8cbe1198ad93",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "87244cf3-11ae-44c4-ab82-24f572f25eeb",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b6b8e787-40f2-44ef-b599-ac5fac1cd174",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "6af3d077-7409-43ec-a46a-a3b0add614ff",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b531609e-96bf-42b3-ac96-1277c986ffc2",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e1c4f0c7-ec19-4bc3-8b4c-234761bb2340",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "442c2f1c-9720-4b26-9f9a-4f9b4273eee3",
                  "requirements": "All 75 models have their out-of-distribution Top-1 accuracy computed and saved for the ObjectNet dataset.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "7f0a2378-7b15-46c0-831e-cab45cedf741",
                      "requirements": "All 36 Vision Models have had their out-of-distribution Top-1 accuracy on the ObjectNet test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d7ff490a-dd6d-40bd-8812-a83a79e0de83",
                          "requirements": "Code has been written to evaluate all 36 Vision Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0a971622-51ac-4316-bd23-a0d6c685f8f4",
                          "requirements": "All 36 Vision Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "cd28b8a0-1b29-4083-8778-e9fa43294e8c",
                      "requirements": "All 39 Vision-Language Models have had their out-of-distribution Top-1 accuracy on the ObjectNet test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d3b6dca2-a1a8-4b8a-93de-b0fabbfc735a",
                          "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0933650d-eb24-4ea3-b19e-18341e19958f",
                          "requirements": "All 39 Vision-Language Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "16b7b5ee-934e-4fe5-8bca-92f057212804",
                  "requirements": "A line of best fit has been computed between the Top-1 accuracy on the ImageNet test set (in-distribution) and the Top-1 accuracy on the ObjectNet dataset (out-of-distribution).",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "d2777034-91ef-43c5-b4b1-462746ac6ea9",
                      "requirements": "Code has been written to compute a line of best fit between ImageNet (in-distribution) Top-1 test accuracy and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "59e3b82c-5350-480d-8258-4b28a9e9122a",
                      "requirements": "A line of best fit has been computed between ImageNet (in-distribution) Top-1 test accuracy and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "88c74548-95ec-4747-8a1b-ddc2f437e503",
                  "requirements": "A line of best fit has been computed between the average LCA distance (using information content) on the ImageNet test set (in-distribution) and the Top-1 accuracy on the ObjectNet dataset (out-of-distribution).",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "8f2c4d01-616b-4f8f-9d56-e0b886c1b24a",
                      "requirements": "Code has been written to compute a line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4910bf94-c7d6-462b-a1c0-febfc6bffd87",
                      "requirements": "A line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset has been computed.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6717c081-7d4d-4803-82ed-ed6d831e50ef",
                  "requirements": "The slope of the line of best fit between in-distribution ImageNet (y-axis) Top-1 test accuracy and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset (x-axis) is positive.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "0e58be49-2e5f-43fd-a514-e547dc3db674",
                  "requirements": "The slope of the line of best fit between in-distribution ImageNet (y-axis) average LCA distance (using information content) on the test set and the Top-1 test accuracy on the out-of-distribution ObjectNet dataset (x-axis) is negative.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "30b185c2-c5bf-43cf-abd6-ea9f18ec6ffb",
              "requirements": "Table 1 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "ffa89038-bc7e-44d5-be9c-55d59faa158a",
                  "requirements": "ResNet18 was evaluated on the in- and out-of-distribution ImageNet test sets, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "289b51ea-c946-40e0-b1e3-4ff87a4e2636",
                      "requirements": "ResNet18 was evaluated on the ImageNet test set, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "401841b7-260a-4843-a4e5-e7118b32f859",
                          "requirements": "Code to evaluate ResNet18 on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0a25d842-cefb-474a-97a7-4ef4fe2999a1",
                          "requirements": "ResNet18 has been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f8a53421-13eb-4747-b249-3f05b1946c66",
                      "requirements": "ResNet18 was evaluated on the ImageNet-Sketch test set, with the Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "0ab5de18-278b-4d89-9deb-f95250ff7bf0",
                          "requirements": "Code to evaluate ResNet18 on the ImageNet-Sketch test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "15257957-95eb-4046-8e53-b6208ae7b601",
                          "requirements": "ResNet18 has been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f493b8ff-b1c4-474f-9db4-02b723756f7b",
                      "requirements": "ResNet18 was evaluated on the ImageNet-Rendition test set, with the Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "738e0aa0-db15-491f-b30d-6bc6e22abb1b",
                          "requirements": "Code to evaluate ResNet18 on the ImageNet-Rendition test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d519e9fc-684d-4fac-bc00-a5e7a32d9ca0",
                          "requirements": "ResNet18 has been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "5c080d9b-1712-405b-8245-d0dfb4f1ed75",
                      "requirements": "ResNet18 was evaluated on the ImageNet-Adversarial test set, with the Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "31dd84b2-c2c8-40e0-b1ee-9955f62fed18",
                          "requirements": "Code to evaluate ResNet18 on the ImageNet-Adversarial test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7919518e-256f-4d8d-b8b4-e55b382097a6",
                          "requirements": "ResNet18 has been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "2502e086-56c7-4a8b-83e5-2a7abc0475eb",
                      "requirements": "ResNet18 was evaluated on the ObjectNet test set, with the Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "f88d6e71-9ad7-4aa1-a545-4104e5489327",
                          "requirements": "Code to evaluate ResNet18 on the ObjectNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e1011195-fc14-4f38-bd9c-94e804f100ea",
                          "requirements": "ResNet18 has been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "53e84f22-d308-46ae-a769-93920c69900b",
                  "requirements": "ResNet50 was evaluated on the in- and out-of-distribution ImageNet test sets, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9c76eba4-5179-4ff2-8554-02aca1d7ada6",
                      "requirements": "ResNet50 was evaluated on the ImageNet test set, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ab6c5816-f0b8-40f2-8d4b-352996cdf2b0",
                          "requirements": "Code to evaluate ResNet50 on the ImageNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9fb0c74b-e410-4216-8672-89c7b4fffffa",
                          "requirements": "ResNet50 has been evaluated on the ImageNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "e04362af-0337-4fbb-b32c-5614e452310f",
                      "requirements": "ResNet50 was evaluated on the ImageNet-Sketch test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "841446d4-dd9b-4f30-94fd-fdf5e0611a95",
                          "requirements": "Code to evaluate ResNet50 on the ImageNet-Sketch test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5ab7b8f5-efaf-4a2e-94d5-a21baf13c6f8",
                          "requirements": "ResNet50 has been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "56e9d2c1-0886-4636-b62c-0917dc397df7",
                      "requirements": "ResNet50 was evaluated on the ImageNet-Rendition test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "843cb5a0-a995-4fe3-be9d-cb6273015335",
                          "requirements": "Code to evaluate ResNet50 on the ImageNet-Rendition test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d04a001f-95de-4ad3-a58b-98247b6f7295",
                          "requirements": "ResNet50 has been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "05872418-7d85-4f58-b85c-b271aa5102a1",
                      "requirements": "ResNet50 was evaluated on the ImageNet-Adversarial test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "249ffd18-b5bf-4c04-b3b4-f0e28bf07113",
                          "requirements": "Code to evaluate ResNet50 on the ImageNet-Adversarial test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "82862f6c-42dd-43b0-ab70-5cc7a16f546f",
                          "requirements": "ResNet50 has been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "c1afb663-fb74-4118-9434-1b44d75563ad",
                      "requirements": "ResNet50 was evaluated on the ObjectNet test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2b5a251d-4837-45ff-8767-79017d447035",
                          "requirements": "Code to evaluate ResNet50 on the ObjectNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "26aed230-d5df-4f0e-b967-53727b03030f",
                          "requirements": "ResNet50 has been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c7ef92d3-2746-4557-86ac-f5f651351290",
                  "requirements": "CLIP_RN50 was evaluated on the in- and out-of-distribution ImageNet test sets, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "4a841288-fe16-4b8d-9653-6b7e3949d05f",
                      "requirements": "CLIP_RN50 was evaluated on the ImageNet test set, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "1ec4911d-64b0-4ba1-822b-f93046c628c3",
                          "requirements": "Code to evaluate CLIP_RN50 on the ImageNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8b337d0b-2c7d-4539-99c2-53f32ee82069",
                          "requirements": "CLIP_RN50 has been evaluated on the ImageNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "1bb919b9-ccec-4e8b-b0f9-474c5b1e3a64",
                      "requirements": "CLIP_RN50 was evaluated on the ImageNet-Sketch test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "1140905b-ac38-4bde-bb79-bf9a32a045bc",
                          "requirements": "Code to evaluate CLIP_RN50 on the ImageNet-Sketch test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "918b0b64-3a63-4fc3-a5ae-0b45193b4df2",
                          "requirements": "CLIP_RN50 has been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "40850a1e-f258-4bf1-ae1c-b86d48f49a9e",
                      "requirements": "CLIP_RN50 was evaluated on the ImageNet-Rendition test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "27a6f695-7ed0-45d5-a6c1-cde28f64a67c",
                          "requirements": "Code to evaluate CLIP_RN50 on the ImageNet-Rendition test set has been written, computing and saving theTop-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "3be55da7-8edb-47e0-8ed9-79df76ccd868",
                          "requirements": "CLIP_RN50 has been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "3a557aa0-9cdf-4911-a503-28fe0f6704f4",
                      "requirements": "CLIP_RN50 was evaluated on the ImageNet-Adversarial test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e0268799-7823-498e-afc1-c89a0b9c83c8",
                          "requirements": "Code to evaluate CLIP_RN50 on the ImageNet-Adversarial test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "691c0fc3-31ef-4e00-a03b-34601eccfabe",
                          "requirements": "CLIP_RN50 has been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "1b1baad0-ae0b-448a-9f7c-ecaecf094068",
                      "requirements": "CLIP_RN50 was evaluated on the ObjectNet test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d819f952-6e83-4190-a868-1eee36d083b1",
                          "requirements": "Code to evaluate CLIP_RN50 on the ObjectNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9943a161-6d65-45fa-a202-66144b15aff6",
                          "requirements": "CLIP_RN50 has been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "82468bdd-43a6-4dd9-96a9-de311e49964b",
                  "requirements": "CLIP_RN50x4 was evaluated on the in- and out-of-distribution ImageNet test sets, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "6e0db985-92fb-4deb-aa9b-60c3cd627355",
                      "requirements": "CLIP_RN50x4 was evaluated on the ImageNet test set, with the average LCA distance (using information content) and Top-1 accuracy metrics computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5ace6dff-cfe6-4c3f-906c-4738557683b0",
                          "requirements": "Code to evaluate CLIP_RN50x4 on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5f0ac033-acf0-4d37-8e22-2f671346fdd4",
                          "requirements": "CLIP_RN50x4 has been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "40b75044-2869-475b-8225-f518dc157150",
                      "requirements": "CLIP_RN50x4 was evaluated on the ImageNet-Sketch test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "724b3437-baf1-4aac-8985-8ddb18b6fdf7",
                          "requirements": "Code to evaluate CLIP_RN50x4 on the ImageNet-Sketch test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e248d48c-c2c9-4ff1-8e1f-344c35838af5",
                          "requirements": "CLIP_RN50x4 has been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9386687e-1066-46a5-967f-963dc26ff22c",
                      "requirements": "CLIP_RN50x4 was evaluated on the ImageNet-Rendition test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "8a7253db-8874-496c-a40b-e538235f0a00",
                          "requirements": "Code to evaluate CLIP_RN50x4 on the ImageNet-Rendition test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "481feda0-9c06-4cad-a6e4-ea068e39b0ee",
                          "requirements": "CLIP_RN50x4 has been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "99645dbd-c730-435d-a648-8aae17f618c8",
                      "requirements": "CLIP_RN50x4 was evaluated on the ImageNet-Adversarial test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b0244b68-af6a-47e2-a655-f866f9c06c76",
                          "requirements": "Code to evaluate CLIP_RN50x4 on the ImageNet-Adversarial test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "584c4ec8-84c0-499c-8758-08dddf0b7814",
                          "requirements": "CLIP_RN50x4 has been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "5a14ac00-c467-47a1-b6c7-a0fe34507240",
                      "requirements": "CLIP_RN50x4 was evaluated on the ObjectNet test set, with the Top-1 accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4760fce7-cbe2-46a3-8b14-6426980960c4",
                          "requirements": "Code to evaluate CLIP_RN50x4 on the ObjectNet test set has been written, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e7a29857-fe71-4534-84fe-9ad34bac6784",
                          "requirements": "CLIP_RN50x4 has been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "04131141-f096-44f0-b42a-fda87727c29b",
                  "requirements": "The saved average LCA distance (using information content)s show that both CLIP_RN50 and CLIP_RN50x4 achieve lower average LCA distance (using information content)s on the ImageNet test set compared to ResNet18 and ResNet50.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "965d31d5-1615-4b1d-b877-88b07ba47219",
                  "requirements": "The saved Top-1 accuracies show that both CLIP_RN50 and CLIP_RN50x4 achieve lower Top-1 accuracy scores on the ImageNet test set than both ResNet18 and ResNet50.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "a2a038ae-e9fa-48e4-8608-5a249da3712c",
                  "requirements": "The saved Top-1 accuracies show that both CLIP_RN50 and CLIP_RN50x4 achieve higher Top-1 accuracy scores on the ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets than both ResNet18 and ResNet50.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "bb672d8a-e88d-43dc-925f-2b21b7d7b461",
              "requirements": "Table 2 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "5f3ff8ba-c97a-4f14-8c6e-1a82f18dbe26",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "fdd8a858-78e3-4a79-8d5f-20da74663452",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "f4bac22d-0336-49c5-b7fc-214f57a8ebc5",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d3467a48-d5ba-4efa-b810-711187f2caf7",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "29c60e13-0d06-4249-bdcb-cd0018f825a0",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "c268b0f5-dc2f-48fa-9c6e-f2b2bdcc648c",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7a5f13ad-3591-4ef7-9868-9ac04334dc3d",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "08aeee4e-029c-45eb-90bc-b5058d1073a2",
                  "requirements": "All 75 models have their out-of-distribution Top-1 and Top-5 accuracy computed and saved for ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ff59872d-4e73-4d72-9887-3a71088fe280",
                      "requirements": "All 36 Vision Models have had their out-of-distribution Top-1 and Top-5 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4e9a9b2b-05b2-49b8-9401-69b090dd506c",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-v2 Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "70c02545-7ff6-45ca-bae0-07d08c713e64",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-v2 test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b1f4ba87-2d12-46e4-b89a-413e2795726a",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-v2 test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d5165617-79ba-4e28-b9e0-4c313a3196d7",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Sketch Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "40d18a6d-df02-4a3a-b57d-ca4e3f51f095",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Sketch test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "a1037484-4eac-4f29-b1cd-5e1ef3bde266",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Sketch test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "9ab9f43d-46ce-4628-ac56-2bc0e035d18f",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Rendition Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a302153e-fad0-4b11-8637-b111fd508714",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Rendition test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "8c026559-da9e-4ac3-8b91-3115200a334a",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Rendition test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c27530fd-f47b-457a-9ea8-554848839c97",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Adversarial Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "16c324bf-1902-4c4b-88e0-c46383136030",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Adversarial test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "dd329228-116b-4680-a588-d5301a2af1e3",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Adversarial test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c9b0552c-31df-49bf-9562-b0167d928a99",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ObjectNet Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "6a658efe-9b81-44f9-bf63-f022e230eaf0",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ObjectNet test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "745c929a-97c2-4cf3-955f-c3274d2740d5",
                              "requirements": "All 36 Vision Models have been evaluated on the ObjectNet test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "bce20663-529a-4979-ad7a-a826af81c0fe",
                      "requirements": "All 39 Vision-Language Models have had their out-of-distribution Top-1 and Top-5 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4048cbb1-a063-4de4-8953-77bf0ada26d3",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-v2 Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "13bea061-5e2d-4d92-9bd7-1adde9ae3cfb",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-v2 test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "db0e80fa-d4b0-412f-8c89-b725dc792dc7",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-v2 test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "6fd2b528-efe1-4847-aada-90c2eaf46e23",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Sketch Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "55c30739-d5cc-454e-abb9-74aea4a20f86",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Sketch test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "58326117-4404-42a2-b878-a926d3168df4",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Sketch test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "52afdac6-020f-4487-8391-654c8651b55f",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Rendition Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f60e5854-296c-4aba-8869-6b3540d80ebc",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Rendition test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "e3821ab3-c09c-49a0-8232-0a439e202fc3",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Rendition test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "97003c12-49ce-4e50-a20f-25a3e2eb4f92",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Adversarial Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b155c707-9b60-4a3a-bf17-71f632d723bf",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Adversarial test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ca5db5f6-2ae6-42af-8ad3-e1cc51e75d26",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Adversarial test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "084e2329-7813-4b84-bab3-bbc4f95e44a6",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ObjectNet Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d3279666-448f-452b-9845-3e15bb95f9bf",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ObjectNet test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4aa4a151-efa7-4313-8d99-68c25d8d5b59",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ObjectNet test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "17dcf6eb-5a44-4b56-969c-5e8bc3b8580b",
                  "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for each of the five out-of-distribution datasets, and the results are saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "c41f4d20-8b05-47b4-89fb-9846ec673f1e",
                      "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for the ImageNet-v2 test set, and the results are saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "002b0c16-5cb0-4a09-a48c-71a045526a9a",
                          "requirements": "The $R^2$ value and Pearson correlation between the ImageNet-v2 in-distribution Top-1 and out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "0332855c-1d8a-40e1-910c-9013ce00910e",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4f76ff6e-e88c-4f6d-afa9-c887b210759f",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2923ecc4-84d0-4265-91dc-8fecce97262b",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7b302466-1d59-4f13-a982-97c0fdd37bae",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f5fd134a-6c10-4443-9cc5-9594c2bf2a5f",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-v2 out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a747d947-34d7-4971-b8d2-0351a6db0eab",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3669f3a2-fcdd-483e-b1a0-c80b1d86623f",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3aacf358-8d91-47e0-91c2-154e1d582eb2",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b1847dea-8a98-4b66-9d55-0507ff37ca39",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cdc1eedd-5580-466a-8eb1-2067260ed116",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5e327498-3055-40bd-872c-c3aaf70cccee",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "86287685-0eaa-4fe4-bfb7-f6b9a182ae61",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "2ad910e9-f2d7-43a6-b663-744915bcad14",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "67e08fbb-16a1-40f6-9168-dad122521f71",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "063e2271-ea83-4e26-8f54-11b75562f244",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-v2 out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "71a4f61e-5f30-4ac2-a2a4-339c40d34fe8",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f4aebd24-018f-4485-82bb-402124ee23b9",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "57784005-0c7d-4307-b9c4-a0ff86aa71a0",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4f8bcb56-9848-40bd-bd88-f28791b83277",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-v2 out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "48abde6a-e2ae-4f86-88c9-9ca9609fda13",
                      "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for the ImageNet-Sketch test set, and the results are saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "35cdc9e8-b6b7-4a46-af92-03f12f096c12",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d00eb606-a093-4f43-b5df-9cbcf034ba89",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "e950c48a-6164-4ada-ac64-710f4b175445",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3b5b135f-5da9-4d49-9909-3cc59a4aafc2",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "22e488e3-3ebe-4291-9de1-58101f4b0f55",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "80ed1009-a2e7-48dc-a011-fc3f2fb3f5cf",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Sketch out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "282f58bf-4382-4b98-8804-14b81d5a4fd6",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "440494a4-cf0a-4698-8942-5ce397b36266",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "83b2d915-a067-4bc0-bf38-e83c2d81d049",
                              "requirements": "The $R^2$ value between the ImageNet-Sketch average LCA and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b9151019-d7c1-44ac-a134-d0e2c0430964",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "673c2f6b-df45-409b-84a8-f05ecd2176e2",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "4e0c7434-0e5f-4c03-afad-dc28d95901da",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5dc44cc1-7860-4e15-bb9d-dc500c2a93fc",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "73c88ca9-454a-4337-a9e3-edfcf40d7cb5",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "c7bf9fb2-7f16-42c4-92e8-dc931e8fe241",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "7407bb1c-3b1c-438c-b75d-eeb4ca30b7ab",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Sketch out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b21d8ce1-8bcd-4cfb-988c-9f3ba5565553",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9b1eedfd-0d0f-4daa-a46a-2dc249a7d149",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7ce6f02b-36a3-4719-81e1-e4faf7f4b0d4",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "d023dc98-4471-4618-86f6-2aad233f3cd7",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Sketch out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "f4c7db36-519f-4b1d-9b72-f1bfd7be11a4",
                      "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for the ImageNet-Rendition test set, and the results are saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d027bb29-f0d2-4037-b4ad-17c005dc841c",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "1b72e3de-4b8a-4291-97fc-4f345e891d63",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9a213c9b-00fd-4e7c-b3b8-381b0648819b",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "95c0937c-a07b-4f6d-b20d-a45b5afaf50d",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "847b49e3-2f28-4a51-9e21-fdbec2c2023b",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cd5d7eff-97a5-42ef-82f9-d351014c3037",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Rendition out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "7676b570-1cfb-48b3-8761-56bb100f358f",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "07923b7f-000a-4825-b5e0-3637b1c90fd5",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "07a69338-6552-426a-9f9a-9c698d13da5c",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ba161222-be80-4fbc-b534-1c99c58f61cb",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "574675f2-943e-4479-a3b6-4f43e285f05a",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ee76060d-d855-4c2f-a4a6-088f7928ac27",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "31d405c0-0e4d-4409-8fb8-def418dcee7d",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "0ff719d4-eeb2-4749-bedb-0ad2154c4029",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "bb603e8d-a98c-45fc-b606-cc02074ea1b1",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c16923db-14ec-474d-82c9-5f457cb3b643",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Rendition out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ba5d3333-d4aa-4e95-b72b-65769bb23b90",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "4b69f61a-d860-4afe-a8fe-7e0ec4c1562f",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "24a02286-bb9a-42c6-88a8-030c9d62b359",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ee7c00a5-3473-4cb8-87b8-0cf89de8cf0d",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Rendition out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "b29785c1-825e-4cd9-b8ce-1cbedbd3e497",
                      "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for the ImageNet-Adversarial test set, and the results are saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "80dc0f19-4043-46a1-81a4-be6663e47030",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3dbb5283-3780-4326-8a24-4c89e5daffa8",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "cb4c10fb-92c3-4915-8f36-40ebbb32004b",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "bb05661c-0344-4471-a5a2-ac7e5738f038",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3c99273e-6d58-4804-99d4-f9e33cd3ed4d",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cc1f4985-131a-4fa8-813b-ad3adbd99553",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "49b3bf31-8204-4374-b512-0f76a7325dea",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "e7aa5124-1c8f-4bf0-b0f1-9764ba844178",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "8c9b559b-7435-486f-b803-b2261d3d6d45",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fb9098cd-5f3f-41ea-b818-774db9803806",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "3127a9a3-c899-438c-aab5-2a4d557f16a1",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "ad9dd112-5378-4cd1-be88-78bd2b6bf588",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "6a89546e-d9fe-48c2-b90e-4fd6ca3b35e8",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "03fbe707-cf73-4ff7-82f8-64c168aad180",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "8bcb208f-9922-45b4-a819-8f79987bc172",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "d8921dec-8bb5-4dd0-aeef-47f83e705113",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "fd0b8d4a-0fd1-421d-9a94-75da9673847b",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "143d4e7a-676c-4ffc-890f-2f3f2f208a5a",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "300c67ad-053b-4caa-90dd-2a33d91d05c8",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "550173dd-cb22-4df0-9078-ef769a069190",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ImageNet-Adversarial out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "1b5b45f1-02d6-485e-b9f4-9813cb56a650",
                      "requirements": "Correlations ($R^2$, Pearson) between in-distribution metrics (LCA distance (using information content), Top-1) and out-of-distribution metrics (Top-1, Top-5) are computed for the ObjectNet test set, and the results are saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "589c66d1-d29a-49b6-89d6-8962376bcc23",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b24885db-5e8d-4558-8ca8-e215a4dfba55",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "260cca63-4cdb-473f-98bd-386faad3c455",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "18e743e8-e443-4542-bc26-a126c440b844",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fe5195a8-51df-4816-86c7-90130023733e",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "4f4f9197-b2b5-4925-8741-0a966431e13f",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ObjectNet out-of-distribution Top-1 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "13696a22-3f32-48ab-b30e-c85c7e5ed84b",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "65ba607f-0902-45d7-bcce-df6d2cf62872",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "0d8d4993-f2f0-4165-81f9-cd983b46ec59",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9f84cfcb-7a54-40bc-af96-34a224d35557",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ObjectNet out-of-distribution Top-1 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "830fe5b0-1eba-40b9-b5c7-0c15d8169f37",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d437e229-aafe-4326-9322-24d44e0b3e55",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution Top-1 and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "72c9ba79-598d-4400-ab4e-3aadd5ff2056",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5f822a88-fc79-4ab2-a01e-9c7a3c93fd9c",
                              "requirements": "The $R^2$ value between the in-distribution Top-1 and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f6e85aba-e26c-4740-bd57-ac067ab2c699",
                              "requirements": "The Pearson correlation between the in-distribution Top-1 and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a28fd28d-1c37-419d-8e63-b7fbe4fe1eb0",
                          "requirements": "The $R^2$ value and Pearson correlation between the in-distribution average LCA distance (using information content) and ObjectNet out-of-distribution Top-5 test set accuracies have been computed for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "36ac7f1c-8769-45bd-b94e-c59b53d27e1c",
                              "requirements": "Code has been written to compute and save the $R^2$ value between the in-distribution average LCA and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "81b8cf17-8529-4198-b647-62aa944e300a",
                              "requirements": "Code has been written to compute and save the Pearson correlation between the in-distribution average LCA and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "16f99a17-0128-45b0-ad0f-bfe97326afcf",
                              "requirements": "The $R^2$ value between the in-distribution average LCA and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "70dae064-432b-423d-a95a-a910836d0bba",
                              "requirements": "The Pearson correlation between the in-distribution average LCA and ObjectNet out-of-distribution Top-5 test set accuracies for all 75 models has been computed and saved.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "3bf0c5ba-14e7-41ff-879e-3a7bdd0de95f",
                  "requirements": "The saved results show that $R^2$ value of the in-distribution average LCA distance (using information content) and out-of-distribution Top-1 test set accuracy is higher than the $R^2$ value of the in-distribution average Top-1 and out-of-distribution Top-1 test set accuracies for ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet, but not ImageNet-v2.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "4db03667-be04-4c0b-9853-b1ce86d67123",
                  "requirements": "The saved results show that the Pearson correlation between the in-distribution average LCA distance (using information content) and out-of-distribution Top-1 test set accuracy is higher than the Pearson correlation between the in-distribution average Top-1 and out-of-distribution Top-1 test set accuracies for ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet, but not ImageNet-v2.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "a20a080a-06d5-4d02-bea2-1f433635d2ec",
                  "requirements": "The saved results show that $R^2$ value of the in-distribution average LCA distance (using information content) and out-of-distribution Top-5 test set accuracy is higher than the $R^2$ value of the in-distribution average Top-1 and out-of-distribution Top-5 test set accuracies for ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet, but not ImageNet-v2.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "07b41f38-31e8-4070-856a-c6a5bbf549d2",
                  "requirements": "The saved results show that the Pearson correlation between the in-distribution average LCA distance (using information content) and out-of-distribution Top-5 test set accuracy is higher than the Pearson correlation between the in-distribution average Top-1 and out-of-distribution Top-5 test set accuracies for ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet, but not ImageNet-v2.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "c55905fb-3d79-47ad-81ca-d708a9aa9400",
              "requirements": "Table 3 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "5d4c06e3-88f4-4e0e-aa9f-8e08c9c293d0",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "b9bc72ca-9dd3-4e73-a3d8-2db1d88de9ed",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "93bebe9c-0323-4d23-b73a-5c91ba1a56e8",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9d75ccf9-4cc1-44c4-ae1a-ca0520d65d2c",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "409ac137-412a-4d20-a0db-dfea0d7efab3",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ac4a60ea-7cfa-4ab5-9185-aa776e3177ba",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7ba8b97b-4753-490e-92c7-d08ac6f2a5d1",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "2d894683-179b-45ec-acfd-01e697b094bc",
                  "requirements": "All 75 models have their out-of-distribution Top-1 accuracy computed and saved for ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "84ddab97-46d0-42ca-8548-4bd026632eb6",
                      "requirements": "All 36 Vision Models have had their out-of-distribution Top-1 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "07e13744-7026-4c8d-a6eb-c986dd0178c9",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-v2 Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "eb5a8b52-a4fb-4c0c-87cf-953e8ea68bae",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "a9f568ad-24b1-4420-ab64-bf7244c7930e",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "63ead37f-d0f0-4d8c-9dd9-209a956c51db",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Sketch Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5e8197b5-3f54-4a6f-897f-979302e0a00f",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9be85329-160a-4628-b800-b7d1502ff8a0",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "76c7c811-274c-47ff-a6a6-f22320b535db",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Rendition Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "b20798f9-66aa-4f01-956a-004ff0e1a316",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fa388189-b1b5-423a-9f5a-0b190bc0ee0c",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f48dbf58-4223-48f9-89ca-a2a377c55934",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Adversarial Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "33a19c4d-fb59-4d55-9b9b-377046940f21",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "19850e16-a6fe-4479-9eae-d2bee59766cc",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e38127f4-2def-43a9-91a1-415f2a4a035a",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ObjectNet Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "be7734a2-a2ef-4387-9416-50065311d0f7",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "3c2990b8-1cff-4c91-b9a2-9937a52372ed",
                              "requirements": "All 36 Vision Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "0b360e4a-e9b0-47cf-80d6-5e70178ba758",
                      "requirements": "All 39 Vision-Language Models have had their out-of-distribution Top-1 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "fb10f25b-431e-4751-b645-4dd716c804c3",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-v2 Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "22e6afc0-2bea-4c90-8bf9-8a7e46796206",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5d89c239-df5b-4b96-8694-ad79cc569204",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "44ab5a5f-dd0f-4fc9-a4d8-2d73a2358a0c",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Sketch Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "2e961d54-83ef-4437-bf91-49dda015cc10",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b48abe19-07a5-4530-8d98-0a5ea587c70b",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "db2c11da-91aa-4188-90c6-04926afe561b",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Rendition Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "30380729-007a-4d86-95e0-17776b33c7a1",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ea2efe7c-912e-476c-941c-a084df46543e",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "fd0e6699-da2a-4a63-b9e5-cf999da04edb",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Adversarial Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "51d82d14-8b8b-4280-a3f8-062ebb21bb4d",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7eab65f5-d4d7-4d54-8da1-ba15b80401ec",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Adversarial test set, computing and saving both the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "0b84e16e-0ca8-46f3-b1f2-dd769857b4a1",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ObjectNet Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "353c344e-a629-4698-b892-1c023ec9825b",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "118d6f66-5077-4096-838f-09febb1eaf37",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "3300f0b0-5449-41cb-9e6a-629ead397222",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average confidence computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ae1b0053-1813-485f-a3b8-1f0fc4948d3a",
                      "requirements": "Code has been written to compute the average confidence $AC = \\frac{1}{N} \\sum_{i=1}^N \\max _j P\\left(y_j \\mid x_i\\right)$ where $N$ is the number of samples, $P\\left(y_j \\mid x_i\\right)$ is the predicted probability for class $j$ given input $x_i$, and $\\max _j P\\left(y_j \\mid x_i\\right)$ selects the highest probability for each sample.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "df1818bb-f682-4ee4-a9cb-726c89c54524",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average confidence on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "9d13df03-190e-4ad6-9fef-1cd693feb1ae",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the average confidence for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bf1d880f-74d2-41b5-8ffe-d9351de731fc",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average confidence for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "a1aed3f7-e180-495b-ae56-72845083891e",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average confidence on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "209edebd-fd66-4e67-8e2f-3b3a9530ef0f",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the average confidence for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1841ce5a-760f-4ac8-ba4f-7ae5ea2ae433",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average confidence for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "09657d60-82ac-4369-8326-7bda273bee86",
                  "requirements": "All 75 models have their in-distribution (ImageNet) Aline-D computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "06bc4d7e-ba54-43ed-8999-e31d7f7057a5",
                      "requirements": "Code has been written to compute the Aline-D, as described in the addendum.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "297937f2-c440-4149-88a4-80777ce65f20",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) Aline-D on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4eb27873-495b-4d4c-a4d7-b90ad281523f",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the Aline-D for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5b5c31b4-f845-421b-b501-2eabd1efaa17",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Aline-D for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "5aac9c06-1217-4ce4-9ea2-576cdb6623c8",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) Aline-D on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "a4388551-d829-477a-817c-56d1fd950c32",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the Aline-D for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7ed2677c-6c52-4ab9-a245-07d5f2077428",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Aline-D for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9bffce5e-f6b9-4b2a-bab6-392f0f20d506",
                  "requirements": "All 75 models have their in-distribution (ImageNet) Aline-S computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "6535ab8d-82cb-4bfd-a8c9-f6140d1d23b2",
                      "requirements": "Code has been written to compute the Aline-S, as described in the addendum.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4e1bce5d-1cf5-4a13-94a1-6aaf7a8404f5",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) Aline-S on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "bf0ba4b3-c50f-4e8c-a7f3-bab43991f23e",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the Aline-S for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ed4a7d32-eee1-42d5-9bf5-b59ed09e46f3",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Aline-S for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "0f4cbc3e-9201-41b9-99a6-f931ac15e5af",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) Aline-S on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "28b9ac77-dcf5-4ee1-911f-37708cc5e40b",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the Aline-S for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "bece351b-0bde-4b4e-b1ac-504ebd11f41b",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Aline-S for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9a30fa83-bdc7-440a-a223-8db21db1a678",
                  "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models, for each of the out-of-distribution datasets: ImageNet-v2, ImageNet-S, ImageNet-R, ImageNet-A and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "acbd98b8-045e-4031-a40a-ae9c995bf9db",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b16a6afc-5161-44a5-bb0d-de71ebed4b9f",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ad30eeb1-3692-423e-8201-7e51db49d2e8",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "483b6a2f-3e81-4504-8ae5-46a7dee44012",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ac7972a0-e584-4c33-9a5b-509692d4abc8",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "be01439b-9441-440b-94c6-cd9ef20edca3",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-S) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "89d79f9c-0b61-4534-a3ec-871fcf7967bd",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "cdb7675d-e01e-404d-bc7a-1764b19ea5ac",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9753a94c-8bc7-49c6-801f-608c56b37d4c",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "19d43582-dfc2-4a11-8263-d1af7f8aa682",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "91e857e2-6bb5-4c93-aac4-bc3b59650064",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-R) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "9a0d92ec-47a0-49f2-9e1a-48bc897b7efb",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5e25601d-c540-4cfc-9355-9c0bc97f7959",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "553b6972-7554-4abd-b6c1-ee5758df07c0",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c4a37593-2dbc-4a4d-9123-d893d38fc643",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4e6b5421-20a3-444f-a3a7-cd3ece780476",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-A) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2f107109-29c4-4768-8526-b7fdb29be4b0",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "89939b87-5a2f-439d-9d95-247a9ec0d7c1",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e4e6b9b0-f725-4500-ba21-62acc440277a",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ac9c6a5f-8988-4eed-ba50-ea57972652d3",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4be3ae11-4db4-4a06-945a-725bfaf0d609",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ObjectNet) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e72f01e4-af6a-477e-8d91-ea9c24dd4318",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0347b5e4-e8a9-4ca0-ad4b-9a677fc6d602",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "ca2ac54b-8228-4e37-8ea3-76a404ffb498",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8558a71c-8c7f-4be7-add6-8e2c04485a74",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Top-1 test set accuracy and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "20f6c815-08f7-4fcd-8888-635a87d3e808",
                  "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models, for each of the out-of-distribution datasets: ImageNet-v2, ImageNet-S, ImageNet-R, ImageNet-A and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "2c390006-6aad-4dfc-b003-64e7885edf73",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "1b12d6ca-a556-49a0-9acb-c3a3d59aa762",
                          "requirements": "Code to compute a line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "008e179d-e778-416f-b56d-df85836711fd",
                          "requirements": "A line of best fit has been computed between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "220726d7-10c8-4df7-81a3-52ef56fd9249",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "07338db4-6359-4425-8627-b6d2a46b9f2e",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "249063fa-f1d6-4c31-a006-c2530fbec85b",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "eb805cee-ac9e-45cb-8055-9a5458f5fa72",
                          "requirements": "Code to compute a line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7c157751-d0c0-4af0-ad8a-8fb6eb89c603",
                          "requirements": "A line of best fit has been computed between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "54a1374e-2f5e-4b77-aa70-ed782e637e82",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b45866d0-6bd7-4523-8756-3c8d518b58ef",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4d2596f4-5e98-4797-932f-c27168e76dcf",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "823cc3f0-e360-4ce1-98ec-7f7f81c7fc10",
                          "requirements": "Code to compute a line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9310569e-d06a-4eba-9dc8-172cdb07b040",
                          "requirements": "A line of best fit has been computed between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6329ce6f-fe76-47c3-968d-86ed261babcd",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "839e3757-6e1c-45db-a63e-fc3031eb39e5",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "107947ed-fa47-419e-9b2c-ef82fafa85b8",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5e7110ab-16bb-4203-97bc-8d36b894ba8e",
                          "requirements": "Code to compute a line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "781254b0-a22c-4e37-9e94-9c2017bd4239",
                          "requirements": "A line of best fit has been computed between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "3b981ee9-ee07-4608-a09a-d40a1e889bd8",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0ca220fa-2fe6-47fc-b81a-a820a5d6d452",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "0a501441-ca21-4187-bcbb-c7c633ebecd9",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "258dd0fb-f3da-4de0-b50b-0c2a8eca482b",
                          "requirements": "Code to compute a line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5120723d-419b-44fc-8867-ccb2bcbb5c4a",
                          "requirements": "A line of best fit has been computed between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e5289fbf-f792-4269-8d50-ce82284e7efe",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "377b7ce7-3dcd-4138-8726-b5e2d108e2b9",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the average confidence on the in-distribution (ImageNet) test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5f126b06-4bf6-45ba-9e33-25d5744b4686",
                  "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models, for each of the out-of-distribution datasets: ImageNet-v2, ImageNet-S, ImageNet-R, ImageNet-A and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3815bb7f-03ff-4354-928b-d24550e16a01",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2fdb2674-10df-41de-b41c-b7436a5dd43c",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "a605126b-e2fc-46a8-a22f-a44a0249712f",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "afbcace8-ff6a-4db7-842b-4590ab73e6c0",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "3ad9a26b-b494-4d02-82b4-a73cba32e1a6",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "830476e4-9d45-4886-8e66-0fd1fdff6999",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "34081763-d14c-41c3-adc5-69d6e0b4cc86",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "a06e0923-9bd8-4aca-8d26-b2268a40b718",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5d105cc7-844d-42d9-a50e-0c14e659e147",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "20c16021-83b0-4805-80e4-d094fdaaf22c",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "6359d358-ddcc-49c9-a1db-4dd47914e5f8",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d89103f1-6a6e-4e5b-8396-f3918bd5c155",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2fca8305-ac20-41c7-a0f8-3ff60a8d9e51",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5058f446-c98e-43ee-86cf-a845ea1d8dce",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "77f92272-aaf6-4fab-8314-54af8e24149c",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "4ed7c388-f1bb-4537-b3db-692d73455724",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "24d04008-f3d5-483c-8f62-44c8b3c2b7c1",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "cd987ebd-e29b-4311-86d7-8ecced5fb668",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "4a61c7c7-4602-408c-aee7-78ab898b037e",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6c6d3906-64ef-4323-ac6a-140513d82e9f",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "592854ff-729c-4284-aca2-3d9ec5e8b171",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "a6cdc1a3-b554-4550-9d61-1c940b25b01a",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "373c0ee5-29fe-44c2-913d-5aba9bd7fbb7",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "a36852a6-8e52-4fcc-adaf-cdb1351ef42e",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b3bc832d-13e1-48f2-a3ff-0fa44278abb7",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-D scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "8fc5472a-c2aa-4ee2-93fd-562eb4ec4b3a",
                  "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models, for each of the out-of-distribution datasets: ImageNet-v2, ImageNet-S, ImageNet-R, ImageNet-A and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "df530c12-9c97-4b17-8002-b18283dda359",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e6c8e561-b885-4b32-9d1b-d6bcf3876257",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8fa35782-9ee8-43be-9385-45d4f4f917ff",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "f25ffbe7-7b6e-4bf1-9873-22a3baeac6fc",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "21db3d0c-8d8b-4ef4-8dfc-947fe0e47085",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "e5021ec8-392b-43d3-b9de-4320ea0f6ab1",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b7097b9c-c34f-41e5-a081-446a0d460f7d",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8f4263fa-0a54-4a7d-b752-074b72c883ab",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "31922376-ffb3-422f-a792-e494126065f3",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "0c84cffd-56ba-4cbb-97bb-8ba8c3fc5df4",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "666440a5-2bd7-4da6-931a-fdc488e4dafe",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "b5262219-8f1a-4d43-a542-2e01bd18600d",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "a4a712c8-4ac7-49d4-a7f8-3c81845d0a03",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b54ce732-c95b-428a-9b1b-100c8adfba6b",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c4676214-9eff-4c31-9d90-f4982a7bbb5a",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "479ff4d6-ab5a-4692-b483-56385a42e96b",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d213a9bb-f33d-413d-ace1-cac900ee49bd",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4c3e8582-595c-45fa-b502-f9c92861e611",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c84af08d-7d03-4457-bd9f-fb675e7336df",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b33b298a-f4cc-4218-b597-48f81ee79943",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "a4f7c261-a47b-4dac-8c10-7267b27fe33a",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ed20e611-8aac-47db-b996-7668d0c00be0",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d2d49485-47d3-4dda-ae3b-ce553acc65b1",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "f9922947-2052-408f-bc1b-c47edad12830",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c5ada85f-1980-4187-a36b-0e31736277f8",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) Aline-S scores on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "24f079a2-4cff-4169-8d3e-a922b5316cb3",
                  "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models, for each of the out-of-distribution datasets: ImageNet-v2, ImageNet-S, ImageNet-R, ImageNet-A and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "f0d08dad-c36c-4104-8053-4ea234d3a5a2",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "799e8e0b-a75a-4a8e-b7cb-272f610b60a5",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "5a33082f-20d6-429e-8f46-aa72e4744a3a",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d07938f7-8284-4eb2-9d54-42444372fd27",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9891533b-9d09-4120-95d4-032f05a0777d",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-v2) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9d39e8de-3760-4aab-8801-a04bd16a8fa9",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "86ce67b1-05a2-4fa5-aa97-25fd36bb33d7",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6fe1a978-bb1e-4eac-a0db-1595eae5c5c3",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "7e287ec2-e698-450d-8ce5-584677b8d7cc",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "85322084-e513-4d42-a6e4-ebcad665131e",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-S) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "493ef42a-77bd-447f-b174-1c00f2c7b947",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "11918fc5-b833-4ed7-9bcd-fd5e9080d181",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7cce8201-881c-454e-a305-a774e33e4855",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "4a18db61-3c4b-4bdf-b0c3-e833ae8ded16",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d8acae09-5640-4898-af72-f2e5e0776f11",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-R) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "49650f07-8ca2-4180-b0e3-252b15c5ebb6",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d311fe91-1fbb-480a-b307-c8e662ffb933",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e2897fb8-c5ba-42df-8126-da845d454fec",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "a397cd66-3a01-46d2-9210-200daf442750",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d0a3178f-45ee-4a9e-9778-891f5569743a",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ImageNet-A) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "fdde6947-642b-4dd0-a782-a29732ccaf37",
                      "requirements": "The mean absolute error has been computed and saved for the linear regression model fitted to the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy across all 75 models.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "3a3c7dd5-1a7d-4778-9e0f-19639794df0f",
                          "requirements": "Code to compute a line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "df65cd5e-50f4-4205-aafe-868d98607304",
                          "requirements": "A line of best fit has been computed between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "d1c37b75-852c-47d3-8d3c-924f6dd8f332",
                          "requirements": "Code to compute and save the mean absolute error for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "701223e9-3bdd-4954-b552-3b2ea4a6bfcf",
                          "requirements": "The mean absolute error has been computed and saved for the line of best fit between the in-distribution (ImageNet) average LCA distance (using information content) on the test set and the out-of-distribution (ObjectNet) Top-1 test set accuracy for all 75 models.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bb0e5670-acc2-4022-9afc-e6727c6e6d9c",
                  "requirements": "The saved mean absolute errors show that the LCA distance (using information content) achieves the lowest error for the ImageNet-S, ImageNet-A, and ObjectNet datasets.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "14eed445-f0c6-423b-892a-a639405b309a",
                  "requirements": "The saved mean absolute errors show that the LCA distance (using information content) achieves the second lowest error for the ImageNet-R dataset.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "579e6b41-9074-4a66-86eb-fa2e35a23050",
              "requirements": "Figure 5 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "552d83c3-8db8-4f74-8791-bae9ab484171",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ea35e4b2-91d2-43c0-9166-a4c843648ab4",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "47eca1cb-f9e4-45ee-be00-b27b095fa780",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "927dfd2c-243f-4df3-b1ab-a2c56db05f0a",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "82103716-e4f5-4ad3-bde7-80910f7162f0",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) and Top-1 test accuracy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "8fd14ac0-2ded-4cf6-bdc2-3c06d491ecde",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "2a8d0f0c-9432-4701-9664-9a3c688ef025",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving both the average LCA distance (using information content) and Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "97e8298a-b4f1-47cf-9973-130c8b50e0aa",
                  "requirements": "All 75 models have their out-of-distribution Top-1 and Top-5 accuracy computed and saved for ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "dc749608-296f-4392-a6c9-39df01fcee66",
                      "requirements": "All 36 Vision Models have had their out-of-distribution Top-1 and Top-5 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5ba26a2c-49e0-45db-a013-7a80b3ab1804",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-v2 Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "cee3b961-fa71-4279-b396-f5abedd44c08",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-v2 test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "5349908f-47e3-40fc-b050-e20b8f01b1b9",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-v2 test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "b8370bb8-1da6-43ee-aaa6-ffdf8e38ed36",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Sketch Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5b37ef1c-6a35-4f95-a35c-69470b9c9253",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Sketch test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "f5fb76a4-7046-41bc-8e2d-6653a1f2573a",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Sketch test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cf2d6a5e-9cd2-42b7-bf2c-82944ac938bb",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Rendition Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "69e565da-765a-456e-aaef-84b980d7eb0b",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Rendition test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "26a3fb49-dbd6-4da9-a743-99b9d1c9ca7f",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Rendition test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "203980a0-0c5c-4b74-ac8f-10c5451f5e8a",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Adversarial Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "4832ef27-3976-43aa-898e-996e80986ab5",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Adversarial test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "01fb30a2-20b1-416d-bf8e-a302c4a44d59",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Adversarial test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c007700d-042a-4a9f-9953-dfe4bb097a9a",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ObjectNet Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "4e90f87e-8903-43ba-b030-36bb062bcf9f",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ObjectNet test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "14449ac6-6391-494f-8b26-df93e8061030",
                              "requirements": "All 36 Vision Models have been evaluated on the ObjectNet test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "6c6fff05-27b4-4609-b895-49fd02be5681",
                      "requirements": "All 39 Vision-Language Models have had their out-of-distribution Top-1 and Top-5 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "d5005604-f270-40ad-8944-6f8f65cd0d51",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-v2 Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "8e375a58-3d3b-4700-8217-e89a58953c8f",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-v2 test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "1008e9a9-93bf-48a8-a5be-b1a72df64aad",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-v2 test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "f6b0f858-eb96-424c-9d5d-eb627ac406ae",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Sketch Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "f17a9621-0d67-495f-aee5-78bb423ef85f",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Sketch test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "04ad1d76-2a04-473e-a112-a5511ccd32bf",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Sketch test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "9764876b-34d3-4284-9e47-31bcc1e9b4ac",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Rendition Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "31df176f-361e-42ae-9a20-0e499944ed1a",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Rendition test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "a7e0613c-f6e2-49e0-8d78-c34ab8376c8b",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Rendition test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "76f03283-4317-469a-9208-8c066b92378b",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Adversarial Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d16ac027-b101-4712-813b-04006cd4f0fd",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Adversarial test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "7f8a8c1e-16f8-4d5d-a26e-23bc13b802fc",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Adversarial test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "7cf5c4af-6249-4b29-b53f-30b3be09f2c4",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ObjectNet Top-1 and Top-5 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d75f84e8-20ca-4ec1-93e6-31f8312ce6f9",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ObjectNet test set, computing and saving both Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "785d4bfa-b645-4906-8c79-40ebbf96ba21",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ObjectNet test set, computing and saving both the Top-1 and Top-5 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6a7201ae-8c8d-4c6f-9e79-3126bce29777",
                  "requirements": "A line of best fit has been computed between ImageNet (in-distribution) Top-1 test accuracy and both the Top-1 and Top-5 test accuracies on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "17ae5c6e-bbf5-46ee-9a1e-f6fc6332f96f",
                      "requirements": "Code has been written to compute a line of best fit between ImageNet (in-distribution) Top-1 test accuracy and the Top-1 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "15f2ea57-1390-4572-ba6c-6153fc3e21db",
                      "requirements": "A line of best fit has been computed between ImageNet (in-distribution) Top-1 test accuracy and the Top-1 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "41bf1c9a-dd8f-4a4d-8b8a-83934a1b038e",
                      "requirements": "Code has been written to compute a line of best fit between ImageNet (in-distribution) Top-1 test accuracy and the Top-5 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "e5998aa6-f9fb-40ad-92f2-75257454ff26",
                      "requirements": "A line of best fit has been computed between ImageNet (in-distribution) Top-1 test accuracy and the Top-5 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "994bde75-d3de-4b36-a3f6-0d1e60b54630",
                  "requirements": "A line of best fit between the average LCA distance (using information content) on the ImageNet test set and both the Top-1 and Top-5 test accuracies on the out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) has been computed.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "bbdd7184-d300-4f8c-8380-b5edbb049a14",
                      "requirements": "Code has been written to compute a line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-1 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "f5b56acd-5b5c-4768-b6ff-d9ee5e408104",
                      "requirements": "A line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-1 test accuracy on the out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) has been computed.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "0dec7d31-f155-4cde-a946-2019ada2568d",
                      "requirements": "Code has been written to compute a line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-5 test accuracy on the out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "73444339-2d64-4199-ae98-69e57990de5f",
                      "requirements": "A line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-5 test accuracy on the out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) has been computed.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "09a0f82e-f91b-44c7-857f-5be2fbd9737d",
                  "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 test accuracy and the out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) is positive.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "6457f099-5734-42e5-be31-e2044aaf2c68",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-v2 Top-1 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bb0951fb-551c-4848-89e5-793919491aea",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Sketch Top-1 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5a93bd6f-97a0-478d-b800-ac5d10b81967",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Rendition Top-1 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6d6d6700-f411-4c4f-84dd-406bbc6ce574",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Adversarial Top-1 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f4ba4df6-1145-4d87-b743-42cf8ea0bcc2",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ObjectNet Top-1 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ee80c235-64a8-47c2-adab-a35aba4781b6",
                  "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 test accuracy and the Top-5 test accuracy on the out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) is positive.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "e949287f-6ad0-4505-b0b0-fdee393118e0",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-v2 Top-5 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e6f5488f-934e-4754-b609-ffe388831ded",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Sketch Top-5 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b7c69409-a3f0-40ea-8d60-d82dae8e9498",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Rendition Top-5 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d0eb4519-1828-4e9c-9c8f-79e631dd4589",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ImageNet-Adversarial Top-5 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b7f522d1-6988-46bf-afa7-33b7bd239c22",
                      "requirements": "The slope of the line of best fit between ImageNet (in-distribution) Top-1 accuracy (y-axis) and ObjectNet Top-5 accuracy (x-axis) is positive.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "beb74350-f1d7-4ec7-b1c9-945f4e9b2511",
                  "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-1 accuracy of out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) is negative.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "15f170cf-08b6-47f1-a260-b36d248235c2",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-1 accuracy (x-axis) on the ImageNet-v2 dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c941cb4b-1918-4545-b292-1b2bd2171271",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-1 accuracy (x-axis) on the ImageNet-Sketch dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "432867ec-f650-401f-982a-4bf13dd926d9",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-1 accuracy (x-axis) on the ImageNet-Rendition dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b70aed07-70ea-4a85-98ea-f0e420de11e9",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-1 accuracy (x-axis) on the ImageNet-Adversarial dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ad5b891c-d440-4d11-a62d-400cb80b8820",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-1 accuracy (x-axis) on the ObjectNet dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "3c7297eb-05e2-44b9-85dd-ca97124fe788",
                  "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set and the Top-5 accuracy of out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet) is negative.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "231f083c-dd68-45f2-96b0-6a8b7887a023",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-5 accuracy (x-axis) on the ImageNet-v2 dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1faabfec-8a2d-4e83-8c8d-ce52c8dc46a2",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-5 accuracy (x-axis) on the ImageNet-Sketch dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6db1b1f8-1cb6-4b20-851d-dc5ac95b50e4",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-5 accuracy (x-axis) on the ImageNet-Rendition dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9cd89339-91c7-4e45-9a3c-ba3baf455e2a",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-5 accuracy (x-axis) on the ImageNet-Adversarial dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c2f43bc3-5cb5-4d5d-837c-deeaf9c9b540",
                      "requirements": "The slope of the line of best fit between the average LCA distance (using information content) on the ImageNet test set (y-axis) and the Top-5 accuracy (x-axis) on the ObjectNet dataset is negative.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "48330f9a-7a95-46ae-8523-40b32c7494b4",
              "requirements": "Table 4 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "47de8759-36c1-496c-a119-f38375155fab",
                  "requirements": "75 latent hierarchies have been computed using $k$-means clustering, with one hierarchy generated using each of the 75 pre-trained models, as described in Appendix E.1.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "917720c6-4a3b-4b8b-a817-7df040085dab",
                      "requirements": "For each of the 75 pre-trained models $M$, code has been written to use $M$ with the in-distribution ImageNet image test set data $X$ and labels $Y$ to extract and compute the average feature representation for each class.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7245950d-e024-4f52-986c-c96eef90f3fa",
                      "requirements": "For each of the 75 pre-trained models $M$, $M$ has been used with the in-distribution ImageNet image test set data $X$ and labels $Y$ to extract and compute the average feature representation for each class.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "1b4732c1-25d8-4766-a3bd-0f47d666f595",
                      "requirements": "For each set of the 75 model-specific averaged class labels, code has been written to compute a 9-layer hierarchical clustering using the $k$-means algorithm on the computed per-class average features setting the number of cluster centers as $2^i$, where $i$ ranges from 1, 2, 3, 4, ..., 9, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "fd1dc370-52ff-4018-a004-8ced36e8addd",
                      "requirements": "For each set of the 75 model-specific averaged class labels, a 9-layer hierarchical clustering using the $k$-means algorithm on the computed per-class average features setting the number of cluster centers as $2^i$, where $i$ ranges from 1, 2, 3, 4, ..., 9, has been computed, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "40469efb-5c05-4a4a-a4c1-84b6a9a4584a",
                      "requirements": "For each model, code has been written to compute the latent class hierarchy by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "c9eec8ad-859f-4f97-b132-57238d9c6a49",
                      "requirements": "For each model, the latent class hierarchy has been computed by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "66cd03be-7479-44f5-88b2-cc4cc60b9dec",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) using each of the 75 model-specific latent hierarchies computed via $k$-means on the test set computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "a88c887c-4c02-42a6-a2be-06078508ca38",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "99b032ec-71d6-47b9-a5ec-96896affc2a4",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "109a2b20-712b-4378-b1fb-5ed9bb60547a",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "0518a6c4-1155-4ab7-b250-9c8906849c20",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means on the test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "782e8ba0-1f93-4dc9-ba5c-f197ab73e51b",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4febf73f-9c10-4464-a0aa-6d683524bf12",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average LCA distance (using information content) using each of the 75 model-specific latent heirarchies computed via $k$-means for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "38dfcff6-8c8d-4bb6-bde2-16bbed02a1db",
                  "requirements": "All 75 models have their in-distribution (ImageNet) average LCA distance (using information content) test accuracy using the WordNet hierarchy computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "7c1bb57d-d1b8-4f91-a4dc-f3341d0f47e9",
                      "requirements": "All 36 Vision Models have their in-distribution (ImageNet) average LCA distance (using information content) test accuracy using the WordNet hierarchy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "76a6f803-ef49-4c32-b5bf-5dc9fbb77aca",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the average LCA distance (using information content) using the WordNet hierarchy accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ba6df4ae-7242-412a-a735-e3617ac8b9d6",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average LCA distance (using information content) using the WordNet hierarchy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "58037fcb-07b1-4430-b9aa-787bb0bf304a",
                      "requirements": "All 39 Vision-Language Models have their in-distribution (ImageNet) average LCA distance (using information content) test accuracy using the WordNet hierarchy computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "9d0e23da-705f-4fcf-a5ef-a1bb5c1a233e",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the average LCA distance (using information content) using the WordNet hierarchy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ec3bd251-cdda-4261-9482-3d0335ca1c86",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the average LCA distance (using information content) using the WordNet hierarchy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "e57dd999-76d1-488d-8867-312958a6f5cf",
                  "requirements": "All 75 models have had their in-distribution Top-1 accuracy on the ImageNet test set computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "2e8fea1e-4c9f-4715-8c0f-43abcb55159a",
                      "requirements": "All 36 Vision Models have their in-distribution Top-1 accuracy on the ImageNet test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "96cdabdc-1bff-4758-87f7-1fac99dcf273",
                          "requirements": "Code to evaluate all 36 Vision Models in Appendix A on the ImageNet test set has been written, computing and saving the Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "42c9a7c3-b4e8-48f3-85ef-8f4c5e1ec4c7",
                          "requirements": "All 36 Vision Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "997d59c4-d66e-4a02-bdbf-309f8c93a501",
                      "requirements": "All 39 Vision-Language Models have their in-distribution Top-1 accuracy on the ImageNet test set computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "8f66f249-7c39-423f-ab03-c905c4bf1ba8",
                          "requirements": "Code to evaluate all 39 Vision-Language Models in Appendix A on the ImageNet test set has been written, computing and saving the Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "b646b14a-5ce3-4517-a5d2-c9ba9c25ec45",
                          "requirements": "All 39 Vision-Language Models in Appendix A have been evaluated on the ImageNet test set, computing and saving the Top-1 accuracy for each model.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d18f80b7-165b-4185-992f-9a5f06f9a1aa",
                  "requirements": "All 75 models have their out-of-distribution Top-1 accuracy computed and saved for ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "076a62f0-5273-4d66-88a4-e8da9a71d403",
                      "requirements": "All 36 Vision Models have had their out-of-distribution Top-1 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "ddc4840d-4764-402d-94bd-c83b7ae00e78",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-v2 Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "eaa8995c-39da-40b5-b251-99d3e47403b0",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "cd92d3a0-6431-4c01-8a4e-5027c40af781",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "cf6a8c75-2ce1-40c4-8f4d-32f1627393c4",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Sketch Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "459f46dc-3ebe-48b4-9fbd-ba24584bbbd2",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "ad31e770-6dd3-4f14-ba03-8bc7c2625dcf",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "e2fb4aaa-fe17-442b-b560-d5de613ae06f",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Rendition Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "d7ba6934-ff9d-4da6-b3ba-d4ad676c65e0",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "b145e558-5a3d-48a1-9b34-9105979afe21",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "921c7304-e10d-4338-953c-459d98376ab6",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ImageNet-Adversarial Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "482dc4f3-611b-41f0-9db7-511711656e76",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "fe6f9d78-767b-4272-92d4-9604150e91c5",
                              "requirements": "All 36 Vision Models have been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "14d5fe45-abfb-4681-992b-8191b085e319",
                          "requirements": "All 36 Vision Models have had their out-of-distribution ObjectNet Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "a7481a1d-23fd-47ae-8e87-976396fe4487",
                              "requirements": "Code has been written to evaluate all 36 Vision Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "1062f8a5-6d90-4f33-b4cd-3a408d1eaaf7",
                              "requirements": "All 36 Vision Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "773195ab-134d-454e-9eee-210080b763c9",
                      "requirements": "All 39 Vision-Language Models have had their out-of-distribution Top-1 accuracy on the ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet test sets computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "22e5007f-3196-41cc-9b77-445a708548cf",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-v2 Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "3651998c-b65e-4a9d-b978-1884a07ac18a",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "472949aa-d73f-45e8-b7b0-43c778f9918b",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-v2 test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "eac60f86-59b4-4a70-bea0-2ed876fe1635",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Sketch Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "2d85ddc0-ba21-4c71-9d44-a4f06326b7e0",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "8ee8900d-70b0-4f2d-b0cd-461b5c9d3dca",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Sketch test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "a1daef0e-3e18-4748-9b2f-f646a8eb9d96",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Rendition Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "5356f325-7f96-4510-b9fb-6e4104507cbd",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "32dc3cce-c201-453b-9bd9-950a5d9daaf0",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Rendition test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "c8f6a5b8-a52e-4e40-9409-43dfcec49d63",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ImageNet-Adversarial Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "eea6c753-03d6-480c-8f47-1193b6aed15d",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "9de50806-b11c-406b-91ef-b45a1101ba1c",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ImageNet-Adversarial test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        },
                        {
                          "id": "577b5b59-683d-43e4-85c5-c078e7f79514",
                          "requirements": "All 39 Vision-Language Models have had their out-of-distribution ObjectNet Top-1 accuracy computed and saved.",
                          "weight": 1,
                          "sub_tasks": [
                            {
                              "id": "9b535027-4f33-4783-a422-0264c2ea4508",
                              "requirements": "Code has been written to evaluate all 39 Vision-Language Models on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Development",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            },
                            {
                              "id": "735ca768-890c-4eb8-88f0-382e94bb01ce",
                              "requirements": "All 39 Vision-Language Models have been evaluated on the ObjectNet test set, computing and saving the Top-1 accuracy.",
                              "weight": 1,
                              "sub_tasks": [],
                              "task_category": "Code Execution",
                              "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                            }
                          ],
                          "task_category": null,
                          "finegrained_task_category": null
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6a869ac7-c65b-44bf-8003-2d0a63a7077b",
                  "requirements": "For each of the 75 latent hierarchies generated using $k$-means and the 5 out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet), the Pearson correlation between the average LCA distance (using information content) on the ImageNet test set (with respect to the latent hierarchy) and the Top-1 accuracy on the out-of-distribution dataset has been computed and saved, for a total of $75 \\times 5 = 375$ Pearson correlations.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "549d4152-712c-4a04-a613-a4b88427b61f",
                      "requirements": "For each of the 75 latent hierarchies generated using $k$-means, the Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved, for a total of 75 Pearson correlations.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d5ce00cf-8d20-4c17-8bce-525080efd218",
                      "requirements": "For each of the 75 latent hierarchies generated using $k$-means, the Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved, for a total of 75 Pearson correlations.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "aee8422e-5570-4a14-aea0-953214d15a99",
                      "requirements": "For each of the 75 latent hierarchies generated using $k$-means, the Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved, for a total of 75 Pearson correlations.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3f5de389-9d28-4e86-b96a-45ca428d7636",
                      "requirements": "For each of the 75 latent hierarchies generated using $k$-means, the Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved, for a total of 75 Pearson correlations.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2bb9a89b-7157-4f3d-8353-e19b7ff14a10",
                      "requirements": "For each of the 75 latent hierarchies generated using $k$-means, the Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ObjectNet dataset has been computed and saved, for a total of 75 Pearson correlations.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "4b4c21c0-365a-44ac-b87c-0489babfd9e9",
                  "requirements": "For each of the 5 out-of-distribution datasets (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet), the Pearson correlation between the average LCA distance (using information content) on the ImageNet test set (with respect to the WordNet hierarchy) and the Top-1 accuracy on the out-of-distribution dataset has been computed and saved, for a total of 5 Pearson correlations.",
                  "weight": 2,
                  "sub_tasks": [
                    {
                      "id": "15ad790e-289d-4860-acbf-ecbff9088554",
                      "requirements": "The Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "59d96bb3-76b1-4a63-88d0-6295e3cc239f",
                      "requirements": "The Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a5145532-255e-4234-9a79-58b2c7b15e36",
                      "requirements": "The Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7a1dc339-d292-4760-87b5-fe7ae055a832",
                      "requirements": "The Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ddb041b0-5a88-497a-84d5-d464305f4fbf",
                      "requirements": "The Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the out-of-distribution Top-1 accuracy on the ObjectNet dataset has been computed and saved.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c4298e87-e4a3-429f-96f4-962cdc413102",
                  "requirements": "The mean, min, max and standard deviation of the 75 Pearson correlations between the average LCA distance (using information content) on the ImageNet test set and each out-of-distribution dataset (ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet) have been computed.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cedee300-2e21-4250-8a75-c68e3c690e48",
                      "requirements": "The mean, min, max, and standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and the Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "78b9ab95-ee85-48af-9df8-6ae0813fb0cd",
                          "requirements": "Code to compute and save the mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ca6fd309-e63b-4325-b78e-400866459f2f",
                          "requirements": "The mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "ce0bf884-c39a-40b4-badb-8255f79bfd1c",
                          "requirements": "Code to compute and save the min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "3345c51a-6d37-4a42-b87f-3bf2afb5a368",
                          "requirements": "The min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c455f771-3286-41a5-85fd-82ad57c14f27",
                          "requirements": "Code to compute and save the max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4622a17c-6941-4206-8b08-523a7be4a3df",
                          "requirements": "The max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "1d5bb7f8-17dd-454e-91a2-7dece3eabbbb",
                          "requirements": "Code to compute and save the standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "9bae163a-e97d-4d93-a7bb-93faf8d19467",
                          "requirements": "The standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-v2 dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "615d9eb8-7638-4307-ba5b-9a1d8a3f81d1",
                      "requirements": "The mean, min, max, and standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and the Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4c632086-036e-42b0-a09a-d4b534223513",
                          "requirements": "Code to compute and save the mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "92285984-06ce-411c-91cd-7f6bdc9495dc",
                          "requirements": "The mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "deb81d6a-82da-4916-ab20-45953a1409f7",
                          "requirements": "Code to compute and save the min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "311af68c-035e-42bb-9de9-bade73b692aa",
                          "requirements": "The min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "694a4def-6382-41f0-978b-6f3c0daa3efc",
                          "requirements": "Code to compute and save the max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "932b8cd1-fa67-4849-93fa-bb3cadef8126",
                          "requirements": "The max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "f0f23ceb-e24b-404b-9004-aef1a53542f1",
                          "requirements": "Code to compute and save the standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e12b8688-ca7c-49c1-b703-22b98b9e454a",
                          "requirements": "The standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Sketch dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "639b3bb1-30f6-4fa8-b00c-5409d0d56030",
                      "requirements": "The mean, min, max, and standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and the Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "2f17a34d-758c-499b-a7e4-ef3dfd9313cc",
                          "requirements": "Code to compute and save the mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "6c4e0af1-c329-440f-b5d5-9d1f9b291144",
                          "requirements": "The mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "990d8e0a-8ca3-4aae-b363-f4ced06cb772",
                          "requirements": "Code to compute and save the min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4cc483db-6195-4083-941e-94f31147f225",
                          "requirements": "The min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "e0672e72-9244-40f7-be22-de2845a72028",
                          "requirements": "Code to compute and save the max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "7a450fe5-979d-4c28-bb10-cf2dc6aab748",
                          "requirements": "The max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "21bbb9eb-9f69-4120-9b43-3380081c6500",
                          "requirements": "Code to compute and save the standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "04b430f4-0616-482f-8b29-d252095b52be",
                          "requirements": "The standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Rendition dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9f79855a-699a-47d8-8cd2-80de45e3550c",
                      "requirements": "The mean, min, max, and standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and the Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "55476501-8c38-45a7-80b3-50e24e2aa2d7",
                          "requirements": "Code to compute and save the mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "98db6576-f3e2-4fb7-8901-2a375314183b",
                          "requirements": "The mean of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "733588d3-a96b-4840-8e46-6e129566e28b",
                          "requirements": "Code to compute and save the min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "c0e5df85-1d50-4b79-8c5f-a13906e4bb32",
                          "requirements": "The min of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "fb456f66-9108-490c-8852-2197e70acae4",
                          "requirements": "Code to compute and save the max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "52b8117a-3f02-4af4-a456-381d622fca48",
                          "requirements": "The max of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "dad4cef0-d671-4683-9429-ebc260fdb434",
                          "requirements": "Code to compute and save the standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been written.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "f4886461-60d8-40b4-b60a-3c62a4ee0fa4",
                          "requirements": "The standard deviation of the 75 Pearson correlations between average LCA distances (using information content) on the ImageNet test set and Top-1 accuracy on the ImageNet-Adversarial dataset has been computed and saved.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ff40427f-6589-4ae8-8fc7-17f17b56eddb",
                  "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy across all 75 models on each of the out-of-distribution datasets has been computed and saved.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "224b8453-0017-41f6-9187-3e4d61bdda61",
                      "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-v2 dataset across all 75 models has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "28c3d898-679b-401f-9388-cb419b12177c",
                      "requirements": "Code to compute and save the Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-v2 dataset across all 75 models has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "47e32c7d-f7c3-428a-b935-04df5af51472",
                      "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Sketch dataset across all 75 models has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0576a1e6-d703-46b5-9c8e-0aaf93edf5dd",
                      "requirements": "Code to compute and save the Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Sketch dataset across all 75 models has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c14c3d85-c1c6-4e1f-9f22-53b5e7b1ba14",
                      "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Rendition dataset across all 75 models has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fe4ba27f-b88a-4367-80db-a2adeaaa2684",
                      "requirements": "Code to compute and save the Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Rendition dataset across all 75 models has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4d8381cc-d0a0-42bf-a141-ee1b09b193f0",
                      "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Adversarial dataset across all 75 models has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9db332cd-4503-4055-90d1-4c340bedf20e",
                      "requirements": "Code to compute and save the Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ImageNet-Adversarial dataset across all 75 models has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3b43637f-a779-4629-9968-93a5ccd23ffd",
                      "requirements": "The Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ObjectNet dataset across all 75 models has been computed and saved.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7d09f086-7c6c-490e-b4c1-2c94922ef60c",
                      "requirements": "Code to compute and save the Pearson correlation between the Top-1 accuracy on the ImageNet test set and the Top-1 accuracy on the ObjectNet dataset across all 75 models has been written.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "96623b45-6874-4928-a2c3-eba01d4b683c",
                  "requirements": "The saved results show that the mean Pearson correlation between the average LCA distance (using information content) (with respect to the latent hierarchies) on the ImageNet test set and the Top-1 accuracy on the out-of-distribution datasets is lower than the Pearson correlation between the average LCA distance (using information content) (with respect to the WordNet hierarchy) on the ImageNet test set and the Top-1 accuracy on the out-of-distribution datasets for ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial and ObjectNet, but not ImageNet-v2.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "a6049907-70b8-4b02-bb3d-4c0e96790df6",
              "requirements": "Table 5 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "ce1bb010-6d9c-422a-9d1f-34643db514a9",
                  "requirements": "The soft labels based on LCA distance using tree node depth and the WordNet hierarchy have been computed, as described in Appendix D.2.1 and E.2.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "a73ea29c-7b60-4ab3-9a57-698c908bd7c1",
                      "requirements": "Code has been written to compute the $n \\times n$ LCA distance matrix using tree node depth, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the WordNet hierarchy, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b857f31e-a257-4827-a6df-f96b0a4e8bbe",
                      "requirements": "The $n \\times n$ LCA distance matrix has been computed using tree node depth, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the WordNet hierarchy, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "ff6349a8-e777-4ba3-b1e5-5743b87b79b5",
                      "requirements": "Code has been written to exponentiate all elements of the LCA distance matrix and apply minmax (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$ where $T$ is the temperature).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "c4e5e526-5968-48fb-8fe5-143e81e2e465",
                      "requirements": "The soft labels matrix has been saved for later use.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "ed811ccd-9157-4edd-906b-31590ec2d766",
                      "requirements": "Code has been written to exponentiate all elements of the LCA distance matrix by a temperature value $T$, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "cfdf727d-10d2-4d4a-89af-02df849194ea",
                      "requirements": "All elements of the LCA distance matrix have been exponentiated by a temperature value $T$, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d92dd79c-0a1e-4d73-bed1-3284457056c4",
                      "requirements": "Code has been written to sanity check the resultant soft-label matrix, as described in the addendum.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5891eb11-7250-4099-b07a-e2d517f24faf",
                      "requirements": "Sanity checks have been run on the resultant soft-label matrix, as described in the addendum.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "c3cd5e49-4f82-40c2-82f3-7ce385b42403",
                  "requirements": "An interpolated linear probe with a ResNet-18 backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "1e8fe9fd-79c8-4c02-874b-c2078e883e0c",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "e725f78b-9aca-4ce3-bae2-ae319291ebed",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "4d1011c0-523d-4cb5-b3d6-eb13660b30b3",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "8cd7cc36-afbb-4691-ace3-419d780a3255",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "2db37c1e-e205-4e2f-9328-ad0e2911520f",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6a08ac28-5991-42f8-9591-c8c32fe91396",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a2feaa79-2c91-45a0-9005-107bdd030472",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "eb0ad9dc-934e-4ab0-9054-6d8eecc7f9e0",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "889db697-e787-42bb-9547-45698b369640",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7778d03d-047b-4e1f-a6c2-3e3883e3c5a2",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cf484644-d612-4a0f-bb9a-a79a60858b39",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0e7b3049-9875-42cd-b3d0-c134c3d821ca",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bd4aff6e-fa22-4e79-8662-7fdcb92a591b",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0ee24031-4446-4f0d-bb7f-f93c0cd8000c",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "67ab15da-2546-4795-b713-f2cabd71709f",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "454153ce-0f2a-4ec1-8894-f0d84f7af8a7",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "92ec2b06-d6ff-4331-8446-c64316cd2f43",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f5b07f76-dc5d-417c-9180-c694fbd94b14",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3641f17e-426f-46fc-8a9d-f2d9476c2a19",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "08a97c75-78bc-4cbe-be03-79ab94c3eb41",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fbb99be9-12d8-4250-a8c9-7bac40b9b650",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c2b94915-5e81-4d4c-a3d4-0021d0b94a53",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ff65e5da-ca67-4496-bb06-072a84a24bd5",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a7d2dd78-d4f4-45d8-b4ee-8aa4e7af44d7",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e8eb0464-9781-4b2a-89a5-bcb1650a1563",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f4e1274f-d321-4c39-9428-d6486084e3f9",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d754bc2b-55d9-47a8-bac9-7c698ba7f91d",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "29aeb360-2945-46c0-818f-6890892a8ace",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5b501084-cf54-42dd-9e1f-f0d76812930a",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "20d8644c-5c41-4d5e-9f88-1b580a5e2199",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d577fc7b-361c-43e8-9ec9-ba11773c5934",
                  "requirements": "An interpolated linear probe with a ResNet-50 backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "01918a1b-1298-4963-b961-0c8e26f0718f",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-50 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "9f622228-7a53-4c17-9c9d-1cee353d5917",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-50 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b4f5c17a-e2ea-44a2-a66d-55f6485921cf",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-50 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "029737d9-0481-46b8-a928-d46735e57aff",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-50 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "83228c0a-5eaa-4785-913e-3794a767dd45",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "25536d74-8b55-4b97-a586-17572e831ec6",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "be2ccc26-06a9-4001-9e4c-7b50fe5ca0f6",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "80e928b2-3a44-40f3-8386-d0757f13c052",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2e37028f-1d65-4210-91ca-8c95cca5d7f3",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "70af9c70-3877-4aa3-b8aa-4d384cd223d6",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3ac813d2-d158-4adf-8025-4ab5c88d325e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2ead02ff-a372-4966-ab70-9507a602c07f",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2c3c4835-dbe9-41a0-bd91-550a4fae0031",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "281c3840-7ebf-4dc4-8191-444cd74009cf",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "87c9d4fa-8d80-40e4-a544-b87c3818fb1e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f7a345ae-5987-42da-9495-7d0cbafb8125",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "04ec9a6c-42f3-4268-ac4b-0799c190b4bb",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ddba83a1-137b-4eb4-9bd0-573916f2c5d1",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5d7d45d9-673d-42fa-a9e4-1255b4bacd9e",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9a721f24-19dd-43ec-95c7-8781de2fc888",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "907872a7-9d8d-471a-942d-8e4106e6886b",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7034e638-3ceb-44d0-a572-2f5e676e8e12",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6add721f-ab94-4f20-8fd2-4b7b1e48cbde",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "caeecf8b-42d5-4813-95fa-5a9d80e6f7cb",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ec5a3529-3391-4854-955a-35b6ec050787",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "28afa61b-760f-44fb-9927-bc8289ba1852",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ea0503eb-7686-4893-a3dc-facf949cb93c",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "88650a96-24b9-4dba-a22c-7592e9ca9f42",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e7d742c8-59bd-4012-889c-0cf5c18ea3f0",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "56572b1d-13bf-4ed3-97c9-091ca479060e",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5313b47c-de56-4bc2-b7d1-7d7c36fb4cb3",
                  "requirements": "An interpolated linear probe with a VIT-B backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "bae4a653-2823-4135-be6f-24b0e7de83c7",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a VIT-B backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "7a7f2f28-7b5d-4451-bf06-c54cda5005ab",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a VIT-B backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "8d753159-27a3-488d-838f-c9222a5b3fc4",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a VIT-B backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "066be783-f37f-4b0c-89dd-df8697bd25d2",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a VIT-B backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "8ce6a9a6-1bde-4a34-9199-2af13df8c9b6",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "39530183-ad24-4989-ac22-16f2ae8bc0d1",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1e4ccac1-a01f-41d8-8b9b-8a9029469454",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ff04e374-d79c-4579-b9ed-971cda10e5d0",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c62c1fab-8c2e-4433-ad04-3457a6813aba",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "552cc337-ce4f-484a-bfb4-cc1f66140df8",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "07e8799d-d6a6-4b90-ade9-58c70d802273",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "28cda5fe-10fd-43f8-b86b-95ffa9735e5d",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4af9175b-c3fc-422f-bb07-be8aa1b5175e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b0add35a-ede7-4dba-a291-a7c25ac7c59b",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a08caab8-db5b-4361-912b-9a946e3f12fa",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a017885b-7380-4841-b815-765be3e3105c",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b1e1448a-7242-4af1-afec-724c62484d55",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f8868524-71db-4258-8535-109abedd7ace",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c8e94de6-a51e-423e-903b-4932e747c60b",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3ad43e0e-0348-49fe-a595-5d7ff4e1c575",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a0556b47-af15-40bd-9d14-dc77b778d181",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fb8b0c1b-a413-4074-b87d-10a9f2e5b5d7",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "57f9e9eb-25a2-4af7-94fe-cb57c0c56b36",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f86ce2ff-1608-4559-ac16-f25dea2636c0",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f82f872a-0d19-41b4-b364-dbea5c641fa8",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9e5d2967-6deb-4128-9769-36dd8d61662b",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9bedd5f3-7b34-48eb-ad93-48c46ea1d981",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "db6431bf-ee07-49b0-b1d6-57d5d5059feb",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3ca7e821-34aa-4c1b-86b7-64061330a74f",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4863b03d-0f1f-4e52-87b6-a7f44aaf26c5",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "188f1bd1-a440-42fc-964d-7ee7d7248f49",
                  "requirements": "An interpolated linear probe with a VIT-L backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "0f3c67a2-d009-469d-a084-917ec30493f3",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a VIT-L backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "190f72c5-403e-4a07-a491-36cbf6df2214",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a VIT-L backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "bfa800d0-e179-4195-8d68-fef8244594fd",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a VIT-L backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "e61574de-0604-49d6-baf6-907cb593b7a3",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a VIT-L backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "c4a8428e-7da5-409e-bc8a-5c6f32bd3654",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "13c4d32c-01d3-4ade-bbd7-05010201c86a",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7cf773e8-6e14-4340-a55d-837d1946d6b9",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0af08bb2-7ca3-401d-87db-7800c3cd4905",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4170166c-7336-4c12-a6de-fb66ee0f54f2",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ba69c94b-57a6-4870-8739-ed2909d4ff25",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "af6459d0-ef40-4095-a2db-8523718466d6",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "7d711cc1-52a0-46a8-be29-15cee8bd88ef",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9b4f6e36-f3f8-425b-b578-ef4f14e36c01",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0db881cd-bec6-4536-a854-a3985df41223",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ff45c34f-f2c1-40f2-918a-87ca0a600859",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "edfea5df-7e75-4250-a094-a0f259c9c2be",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bb1443a7-c8d7-401a-9a6d-cb0d9c86b07a",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "672cce65-627d-4257-915f-fbb14e5054f0",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5d876667-1008-4f17-9823-751fb16bdc96",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8431f2ac-78aa-42f6-b8a1-9f839142fd61",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "974a0392-768e-463b-8109-29391f15ccfe",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "30a52866-9070-49b3-b749-1b63581f28b9",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "97a4a324-225d-4222-8ab0-b4a5198d1d15",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8bf40213-89a5-4420-9952-e99daae1c62a",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "eef84dae-b211-4304-9e66-1959fffed195",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ca55c4ad-3ad3-4aba-b03c-0034704e4803",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "80d62554-2882-4595-8eda-8569321d97cc",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "755b0a8e-fcd2-46e2-a080-3ed536d6c05a",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3a69d87e-0612-40bd-9e15-bcbba4e73cf8",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9456426d-f64e-4379-ba10-a1eb72b57fee",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a910fa42-5dd8-4ef4-b9e0-4af9424569a9",
                  "requirements": "An interpolated linear probe with a ConvNext backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "b7541451-d93c-4931-93e0-8f0b67b12d4c",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ConvNext backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "94f7e77a-aefb-44b0-8927-19834a706339",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ConvNext backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "42104596-f5c9-4df0-89c9-7a9aa5ef92ce",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ConvNext backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "f3d64ba4-3848-4208-b29b-af0d753aa51d",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ConvNext backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "8b265399-8cc1-4871-b4f7-8c9e14869233",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "78e5b6a0-93d8-49a9-b5e9-4d08b32cf79d",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "9565544c-de5b-4453-94a7-7ed95e3209c0",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "4144524d-c4b5-4f37-be9e-dc7d6e233594",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c0c47e8e-018b-4a31-9ed4-49c36ae0db87",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "49e0adfd-2b08-4a41-971d-6bb87adb14eb",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e041a5c9-99d5-4cd3-9e2d-aadbcd0ce26b",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ec8e9375-4f53-4ce2-85ef-b3849076627c",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "20e58eb4-ee05-409a-b4e5-3aacc7d2d33e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "713a1b6d-3622-490e-85f3-84a6d79f50cd",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5d24a712-ace6-4f0a-942e-58514113c77d",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cb029a98-7a8a-41f2-a31a-fc189569b7e9",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fd55e7c7-5088-448a-babd-b2468eebcbc5",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5f35dd85-94c4-46a4-b5bf-a7488ce140df",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "de1d7e4f-eb99-4483-b4b8-7428a2fec5aa",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b46cecbd-d624-4fac-a64f-52f31d9192a5",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e16bc294-9376-4d21-931c-1f9d321ceeea",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "189d967f-1171-44cf-9658-05122c02536a",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6ac2a4bb-609c-4166-92f3-f7881425fe66",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b37568db-77c3-4887-998b-3eda441ecca2",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cd6a83af-2921-40ab-88a3-c13d26c79c52",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "68683d70-712b-44d9-8ebe-f5d81ec87548",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6dd1f747-be38-4f4c-abba-10ba6ea86602",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6723176d-222e-4ce8-9e64-14bb7ef6ed4d",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6cc9d89f-8913-481c-adb9-fff64c26cb51",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8d8a9bc2-b185-4245-b88b-bf7ec1a47520",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "73ec963e-9acf-4be7-9cdc-1558fdce5b59",
                  "requirements": "An interpolated linear probe with a Swin Transformer backbone has been trained on the ImageNet train set, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "137aac0d-b874-4097-8aee-f1e315c489bd",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a Swin Transformer backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "05ffa3fb-e239-41c1-b94a-c7a6d56a6093",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a Swin Transformer backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "baaa2209-1a83-4a92-9b0e-1148ff1a2be8",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a Swin Transformer backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "e8f36ed3-e090-4f0e-a417-6b435198f454",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a Swin Transformer backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the WordNet hierarchy.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "cdac76ba-4ed6-491e-b7aa-8b2e14f76ddd",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "46832485-34bb-4ec6-ad55-82fe1aa1097e",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "22a76e41-c737-40e9-b16e-0aad061e6cf7",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "36891736-f634-48e2-9611-07ac67aaf867",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "427a9668-1920-4311-ba66-4e307e59ec95",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e2856c7e-bb3f-4be2-afb8-24ff848b72f3",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3246d9a5-52e7-4bae-9e7f-6135aac43d8e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cf310b49-86fb-459a-8caf-add0b9df9058",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "99ff86c1-8b0f-4b64-b774-1243d2dc8725",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f60ad9ea-3a16-458f-a44a-c21f0146ef08",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "42ac0506-42d9-4ecf-aaa8-0d38b656e0c9",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f1b514b8-4f71-479e-aad9-e548b740d3f7",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "44d8e0ba-62ca-45c2-b166-bc3ce5a49646",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6be4adcd-82c4-4188-b4a8-fc55d62ae85d",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6e78e1ca-15f7-4be6-aaac-f09b68cf21b0",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ad910022-efb7-4ab8-a15f-48e27da740d8",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3cd16ca9-3c11-49b4-a411-18fe606e0da0",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f207fd64-7aa6-479a-a177-60d3f946fec5",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "40667351-c2f3-43e2-97b8-6a9981c779bf",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "5c49a493-8e95-40b6-8c73-d48042051a9f",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2e62e6c4-87f2-4b60-a204-1bfc6afb0f63",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ce42865d-11cd-4340-9615-680dc87d98bf",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6d967a19-3c27-4a68-8aa5-31a4a8fa8a82",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a5dec052-63b3-4d8f-98ef-bd2930fe8101",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "690d8711-42bb-400b-af8c-ba77ca4ee584",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy loss on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "14764bfb-c71b-4649-9d77-1ae0644bae20",
                      "requirements": "The baseline linear probe trained with cross entropy loss has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "2704d53a-9d2d-42c0-8fc7-610980beb82f",
                  "requirements": "The saved Top-1 accuracies show that the interpolated linear probes for all backbones (ResNet-18, ResNet-50, VIT-B, VIT-L, ConvNext, Swin Transformer) using the WordNet hierarchy beats the baseline linear probe (trained with cross-entropy and one-hot labels) on the ImageNet, ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet test sets, except for VIT-B on ImageNet-v2, VIT-B on ImageNet-v2, Swin Transformer on ImageNet-v2 and ResNet-18 on ImageNet (where it tied).",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "108cdae5-2e83-4620-9633-1a6c9dc21d3e",
              "requirements": "Table 6 has been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "f6203254-ec93-466f-b4ef-a5187dce9125",
                  "requirements": "Latent hierarchies produced with the MnasNet, ResNet-18, vit-1-14 and OpenCLIP(vit-l-14) models have been computed using $k$-means clustering, as described in Appendix E.1.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "f14fcba9-d1b7-4477-9536-5e2102ca37a3",
                      "requirements": "A latent hierarchy produced with MnasNet has been computed using $k$-means clustering, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "e30ab55c-809e-4efc-bd2a-a8c64a2b786b",
                          "requirements": "Code has been written to use the MnasNet model, $M$, with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "7fb2a220-dea5-4d07-aed8-0cf912568997",
                          "requirements": "The MnasNet model, $M$, has been used with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "71fb111d-2879-4346-9444-a305be94cfb0",
                          "requirements": "Code has been written to perform a 9-layer hierarchical clustering using the $k$-means algorithm on the per-class average features extracted by MnasNet. The number of cluster centers is set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ba057805-241c-4c6d-b40d-b29def277f30",
                          "requirements": "A 9-layer hierarchical clustering has been computed using the $k$-means algorithm on the per-class average features extracted by MnasNet, with the number of cluster centers set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "323c4e36-8b47-4bca-8be2-0db209843aca",
                          "requirements": "For the clustered MnasNet class representations, code has been written to compute the latent class hierarchy by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "0e390944-2c73-41a2-a62e-9e22d8f0b46f",
                          "requirements": "For the clustered MnasNet class representations, the latent class hierarchy has been computed by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "fd80c778-246f-449f-95aa-37f2390e293a",
                      "requirements": "A latent hierarchy produced with the ResNet-18 model has been computed using $k$-means clustering, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "f8efbab3-8171-411d-99b9-f19bddbdb67c",
                          "requirements": "Code has been written to use the ResNet-18 model, $M$, with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8751d19c-d521-4a25-9f14-fbef8134bd01",
                          "requirements": "The ResNet-18 model, $M$, has been used with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "62791914-70ab-436d-98a1-64e2a655a2ca",
                          "requirements": "Code has been written to perform a 9-layer hierarchical clustering using the $k$-means algorithm on the per-class average features extracted by the ResNet-18 model. The number of cluster centers is set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "f6108c38-6c2f-4553-9420-fc82cf30028e",
                          "requirements": "A 9-layer hierarchical clustering has been computed using the $k$-means algorithm on the per-class average features extracted by the ResNet-18 model, with the number of cluster centers set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "79da70f2-78e0-4af9-a8c8-02dbd180d3fe",
                          "requirements": "For the clustered ResNet-18 class representations, code has been written to compute the latent class hierarchy by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "27fae5c7-62b7-4dcb-bf02-09b9da549a57",
                          "requirements": "For the clustered ResNet-18 class representations, the latent class hierarchy has been computed by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "9944f22e-ec75-46c3-a905-b09e4c2654b9",
                      "requirements": "A latent hierarchy produced with the vit-1-14 model has been computed using $k$-means clustering, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "a5e07a67-22a8-4971-9548-45d9e6f26f71",
                          "requirements": "Code has been written to use the vit-1-14 model, $M$, with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "d33811e3-e182-4746-91a6-6a8e8c03eefc",
                          "requirements": "The vit-1-14 model, $M$, has been used with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "c8c3d420-7264-4d2d-88cc-00bd403150be",
                          "requirements": "Code has been written to perform a 9-layer hierarchical clustering using the $k$-means algorithm on the per-class average features extracted by the vit-1-14 model. The number of cluster centers is set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "865fa279-5670-4115-8840-f48cea16b88a",
                          "requirements": "A 9-layer hierarchical clustering has been computed using the $k$-means algorithm on the per-class average features extracted by the vit-1-14 model, with the number of cluster centers set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "5b651a0d-9121-4c4b-9cd3-c616ccb5b738",
                          "requirements": "For the clustered vit-1-14 class representations, code has been written to compute the latent class hierarchy by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "063a173a-3e9e-4d9f-bfdc-7eea19a060e6",
                          "requirements": "For the clustered vit-1-14 class representations, the latent class hierarchy has been computed by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "b7168d17-ddc1-4d44-845b-ff92f8afccfd",
                      "requirements": "A latent hierarchy produced with the OpenCLIP(vit-l-14) model has been computed using $k$-means clustering, as described in Appendix E.1.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "4cf68e6c-13d8-4145-9eb4-f05af515093c",
                          "requirements": "Code has been written to use the OpenCLIP(vit-l-14) model, $M$, with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ec6d4869-50ac-43ef-bed0-c8ca21016a45",
                          "requirements": "The OpenCLIP(vit-l-14) model, $M$, has been used with the in-distribution ImageNet image test set data $X$ and labels $Y$ to compute the average feature representation for each class.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "a581d827-f8ff-4a23-acf9-00885aebed46",
                          "requirements": "Code has been written to perform a 9-layer hierarchical clustering using the $k$-means algorithm on the per-class average features extracted by the OpenCLIP(vit-l-14) model. The number of cluster centers is set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "05a3ea15-094f-460c-bf9c-f333c06b8f7c",
                          "requirements": "A 9-layer hierarchical clustering has been computed using the $k$-means algorithm on the per-class average features extracted by the OpenCLIP(vit-l-14) model, with the number of cluster centers set to $2^i$, where $i$ ranges from 1 to 9, as described in Appendix E.1.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8df4cc83-ffe2-4b34-b4ad-5f7766d61478",
                          "requirements": "For the clustered OpenCLIP(vit-l-14) class representations, code has been written to compute the latent class hierarchy by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ea122b1d-2ca4-4eb1-82e4-01a6e45cf2ca",
                          "requirements": "For the clustered OpenCLIP(vit-l-14) class representations, the latent class hierarchy has been computed by finding the lowest common ancestor nodes for every pair of classes based on the clustering outcomes. The cluster level at which a pair of classes first share a cluster is the pairwise LCA height.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "8859b42a-aceb-4d8b-b05d-b26feb810e28",
                  "requirements": "The soft labels for the latent hierarchies determined by the MnasNet, ResNet-18, vit-1-14 and OpenCLIP(vit-l-14) models have been computed, as described in Appendix E.2.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "a363667d-dcec-430b-ab82-46da5ddce9a0",
                      "requirements": "Code has been written to compute the soft labels based on LCA distance (using node depth in the tree hierarchy) using the latent hierarchy determined by the Mnasnet model, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "6b009a22-b296-472e-9451-e88993a37b02",
                          "requirements": "Code has been written to compute the $n \\times n$ LCA distance matrix, where row $i$ and column $j$ correspond to the lowest common ancestor distance, $D_{LCA}(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the Mnasnet model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "da3cbda5-9ef6-4f5f-a14f-236770f94db1",
                          "requirements": "The $n \\times n$ LCA distance matrix has been computed, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the Mnasnet model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "5ad75244-582c-4088-9b9e-7fc4fdaffcad",
                          "requirements": "Code has been written to exponentiate all elements of the LCA distance (using node depth in the tree hierarchy) matrix and apply minmax (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "78c82d85-04cf-40e6-b909-88dffeb8db8b",
                          "requirements": "All elements of the LCA distance (using node depth in the tree hierarchy) matrix have been exponentiated followed by minmax scaling (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "f56e5446-b391-4aa3-a872-309e74d53338",
                          "requirements": "Code has been written to compute invert the $n \\times n$ LCA distance matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "4dc7f404-fc41-4a5b-8a37-6289e8c42e14",
                          "requirements": "The $n \\times n$ LCA distance matrix has been inverted, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "39de8c84-b890-4df1-9d57-e6d379fb02fc",
                          "requirements": "Code has been written to sanity check the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "4cf37c13-07d1-47b5-ae0f-0d9d1c4a7b5d",
                          "requirements": "Sanity checks have been run on the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "92ab6db7-fb29-49ca-afeb-5fd82665b663",
                      "requirements": "Code has been written to compute the soft labels based on LCA distance (using node depth in the tree hierarchy) using the latent hierarchy determined by the ResNet-18 model, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "1d77aefa-52e8-4d21-9902-02cbefe69f08",
                          "requirements": "Code has been written to compute the $n \\times n$ LCA distance matrix, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the ResNet-18 model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "0c6e6199-8f4c-4685-b7e9-1c09fb80a8c7",
                          "requirements": "The $n \\times n$ LCA distance matrix has been computed, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the ResNet-18 model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "78c41efa-b1f2-4d3b-80a5-7f063223ba87",
                          "requirements": "Code has been written to exponentiate all elements of the LCA distance (using node depth in the tree hierarchy) matrix and apply minmax (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "3813681e-e1b1-4cfd-85e4-722ad6ab3d53",
                          "requirements": "All elements of the LCA distance (using node depth in the tree hierarchy) matrix have been exponentiated followed by minmax scaling (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "416ab149-ad9f-4c7e-a072-1bb31611c1d4",
                          "requirements": "Code has been written to invert the LCA distance matrix $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "735f24e6-bacf-4990-9afc-3aa057fc6bc1",
                          "requirements": "The LCA distance matrix has been inverted $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "81b24325-1013-42c7-9481-4f952dc33c0d",
                          "requirements": "Code has been written to compute invert the $n \\times n$ LCA distance matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2040a0e1-6788-4236-95f6-dd2b4e016c12",
                          "requirements": "The $n \\times n$ LCA distance matrix has been inverted, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "a7193b21-3927-4fea-9789-1d057c2e597a",
                          "requirements": "Code has been written to sanity check the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "ecfabc43-1519-4f5b-8457-d4394fe503eb",
                          "requirements": "Sanity checks have been run on the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "60cd0eb6-d11b-4964-84d1-07cef04d3c66",
                      "requirements": "Code has been written to compute the soft labels based on LCA distance (using node depth in the tree hierarchy) using the latent hierarchy determined by the vit-1-14 model, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "5182974a-346d-4835-98ee-a89e9baead8e",
                          "requirements": "Code has been written to compute the $n \\times n$ LCA distance matrix, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the vit-1-14 model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "650d1352-4224-46eb-b540-914972bf991f",
                          "requirements": "The $n \\times n$ LCA distance matrix has been computed, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the vit-1-14 model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "de26413a-8058-45ad-9bae-3dc454235324",
                          "requirements": "Code has been written to exponentiate all elements of the LCA distance (using node depth in the tree hierarchy) matrix and apply minmax (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "2537d0aa-1a4c-46bb-9add-3ad790832ba4",
                          "requirements": "All elements of the LCA distance (using node depth in the tree hierarchy) matrix have been exponentiated followed by minmax scaling (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8b06a5bb-4e0c-4325-a43d-4d9909aa5e07",
                          "requirements": "Code has been written to invert the LCA distance matrix $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "1b3f5136-2af9-4b3f-906d-2723d21c16c5",
                          "requirements": "The LCA distance matrix has been inverted $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "57b89448-2520-4def-92b9-dcaf97bbebfa",
                          "requirements": "Code has been written to compute invert the $n \\times n$ LCA distance matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "b3ab91e9-e216-49e3-98a5-4495c7bc4643",
                          "requirements": "The $n \\times n$ LCA distance matrix has been inverted, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "65de0ea0-8de1-4fe0-acef-dd82e5300d4f",
                          "requirements": "Code has been written to sanity check the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "15c802c5-ca8a-4312-b4e1-b6dc555b1885",
                          "requirements": "Sanity checks have been run on the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "ac4d9a26-63d6-4d32-84c8-00828eec7b17",
                      "requirements": "Code has been written to compute the soft labels based on LCA distance (using node depth in the tree hierarchy) using the latent hierarchy determined by the OpenCLIP(vit-l-14) model, as described in Appendix E.2.",
                      "weight": 1,
                      "sub_tasks": [
                        {
                          "id": "86c4b76d-7c7c-4e79-b555-40bcffaca26d",
                          "requirements": "Code has been written to compute the $n \\times n$ LCA distance matrix, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the OpenCLIP(vit-l-14) model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "e6da095a-eb9c-42a5-92b4-6b3f4a5e391b",
                          "requirements": "The $n \\times n$ LCA distance matrix has been computed, where row $i$ and column $j$ correspond to the lowest common ancestor distance using node depth, $D_{LCA}^P(i, j)$, between class $i$ and class $j$ according to the latent hierarchy computed using the OpenCLIP(vit-l-14) model, as described in Appendix E.2.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "d17ee8a4-58c5-448f-b2c3-f31ff7cb1c4c",
                          "requirements": "Code has been written to exponentiate all elements of the LCA distance (using node depth in the tree hierarchy) matrix and apply minmax (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "d14f2015-9229-401d-9593-8d31f9927476",
                          "requirements": "All elements of the LCA distance (using node depth in the tree hierarchy) matrix have been exponentiated followed by minmax scaling (i.e., $M_{\\mathrm{LCA}}=\\operatorname{MinMax}\\left(M^T\\right)$).",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "b8f7cbea-f1fc-403f-9be1-65845fafe2c3",
                          "requirements": "Code has been written to invert the LCA distance matrix $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "ffe46762-ed1f-43fe-82f7-8cf51a9e78d1",
                          "requirements": "The LCA distance matrix has been inverted $max(M) - M$, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "5e7ea0f2-7247-4520-be64-f7ca8684d27a",
                          "requirements": "Code has been written to compute invert the $n \\times n$ LCA distance matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "acdc6a11-6c82-41b4-ba8a-3e296ea57a53",
                          "requirements": "The $n \\times n$ LCA distance matrix has been inverted, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Method Implementation"
                        },
                        {
                          "id": "8b91077f-02a2-4ac1-a103-2cb866daded3",
                          "requirements": "Code has been written to sanity check the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "d05d920c-53e7-4731-be02-25782453dc7b",
                          "requirements": "Sanity checks have been run on the resultant soft-label matrix, as described in the addendum.",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6e7424e4-da6c-4b90-9e15-895c70602733",
                  "requirements": "A baseline linear probe trained with cross entropy has been trained and evaluated on all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "d673ea89-1a41-43e9-ae57-ac711e746d06",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "5ff579f5-93b9-49c8-8415-23b86467a092",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the cross entropy loss. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "e0277db8-6e86-434c-b2c1-e58bf24630cb",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "956f3600-9267-43ee-a4f0-f181792975f3",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d9c33ae0-2ff1-428e-af23-c61c5501a267",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "dc53b1e7-3847-4968-b520-50da9334af42",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b264ed4c-fd96-46fb-aa58-4fcd5be2fb0d",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "34022bec-69c8-410f-96d9-63cd953b5a0c",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "346bc4eb-3847-4239-ad94-c3a7d45cf669",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9ac7ddae-88a1-49e9-a2ab-2d74b0eaafba",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b7ecf513-34bb-44f3-8310-50aad2c80d68",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8020826b-f2a1-42f9-9825-956ffdd924d9",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "93e77e06-a6e0-4be5-a9d8-4759e1467812",
                      "requirements": "Code has been written to evaluate the baseline linear probe trained with cross entropy on the in-distribution ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "08c2eb43-35df-4609-8d5c-d7b6585e8e48",
                      "requirements": "The baseline linear probe trained with cross entropy has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ad337093-0b0e-4f6b-a5ea-58fff5c5d6e5",
                  "requirements": "An interpolated linear probe with a ResNet-18 backbone has been trained on the ImageNet train set using the latent hierarchy determined by MnasNet, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "72a49636-2934-4e67-8835-0dea2f2c028a",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by MnasNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "7e3348fa-01dc-4b24-8818-cb27821c0c67",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by MnasNet.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "a9839c1c-a904-45ab-ae58-c86573a51e44",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "1c5427d9-5eb9-4eea-bbfb-45bcfb1b0d66",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "901b116d-cad2-472b-9a09-3556489cd540",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "62e31bd8-5fb5-4148-b0bd-13408632d7e9",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "27feae35-771b-4eed-9987-8ae6132bca11",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2e76e6b3-1f49-4d11-b49e-2d500d159a47",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6fa43267-0c6b-44cd-bb00-648915224786",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "cfb613e9-83f7-40ce-b85e-264053f2a335",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "192594e1-a6b5-438a-8d45-2c39e9b565f2",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e9924d6f-6ac9-46a3-a8bf-3ecaa0ded03c",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bf77e831-d695-46cd-b257-a36c5378a16d",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c43209ce-58cc-42ab-8cf3-0e59ad2615c1",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "bcb889dc-405f-49f8-8c16-9db3b744f1a2",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d68c52e3-1bb8-48fd-8e9c-85c7137ebc78",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "5b17429a-7970-48c0-ba1f-eaa489997f38",
                  "requirements": "An interpolated linear probe with a ResNet-18 backbone has been trained on the ImageNet train set using the latent hierarchy determined by ResNet-18, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cbd51f39-06a8-4a7d-9d46-df02e2e49769",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by ResNet-18.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "a36718b1-9a32-4275-9ea6-f48e6b0e9998",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by ResNet-18.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "05b95451-4fce-49bc-b71e-38c7d50cb17f",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "d734bdee-f44f-4948-ab47-9620aeccca3b",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "e72883e9-80ff-4be1-bfd3-07a2b6c6f0a5",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "8d54735a-f576-43e1-93e7-b2f2dd757402",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "0378c109-bfd7-4bac-ba4c-5f50391446da",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "53488990-aa8a-4a50-a400-6439e601adba",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "df399832-0045-41c2-8d61-122b92418c53",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b12529c8-f2ee-463c-9ee2-89643292a6b0",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6da543b3-5a86-4ab5-b81e-b669ab8dbb48",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "2713c16c-2739-4348-b028-606464b4f818",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "9370f1b3-b44c-4560-bd25-3a7c8eaef8d8",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "b1e1d239-6513-4841-bbc7-32f6769507c2",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "90d79dbc-8248-47e3-ac9a-3aa573467017",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "74c55c56-7655-4c7e-888b-778e81da8358",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "34978d6a-3c24-47d2-90ef-2e7f218ee87a",
                  "requirements": "An interpolated linear probe with a ResNet-18 backbone has been trained on the ImageNet train set using the latent hierarchy determined by vit-1-14, and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "3e86d264-7d69-411d-b4be-586c2a3e2006",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by vit-1-14.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "78542a61-1131-4209-89c6-88faba333407",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by vit-1-14.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "dee88f98-62ad-4aea-93a8-a95b989d93dd",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a6946f37-b0a6-4444-ba23-2480c717a4a9",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1f55fa78-3df4-4980-aed8-57448e73e8c2",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3a962379-ad60-44e1-b3f7-f37df81e569a",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "240551e7-c78e-4a08-8246-e85abebedd0c",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "ce0959b0-b6bf-4d17-a8ff-25b3359f1bf9",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "e72e1d33-42b0-4db7-9f04-f5412bdca849",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "dbd64c36-7372-4af1-abee-eff073556af2",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a6ae9eae-5295-495b-b255-a837a9e6925e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6a722e2c-55e9-43d6-8116-9097e2f8aa3b",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "385307b3-b6f6-417c-904f-12b116c77676",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "06005283-d781-4829-b5e2-c68ffcf0a892",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "02159561-cf4a-4809-bbce-328a6d3e9a48",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "6f23fe37-f3fe-4791-95fe-6f0fd560ecb7",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "42fa14a6-5a1c-4ee5-be8e-820bae58ae22",
                  "requirements": "An interpolated linear probe with a ResNet-18 backbone has been trained on the ImageNet train set using the latent hierarchy determined by OpenCLIP(vit-1-14), and has been evaluated on the in-distribution ImageNet test set and all five out-of-distribution datasets: ImageNet-v2, ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "75446d0a-785d-48ef-bac0-b090b05849d7",
                      "requirements": "Code has been written to train a linear probe on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by OpenCLIP(vit-1-14).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "bee479fe-66c6-4413-be3b-be553ddbcb4a",
                      "requirements": "A linear probe has been trained on the ImageNet train set with a ResNet-18 backbone by optimizing the probe using the alignment loss, as described in Algorithm 1, with $\\lambda = 0.03$, temperature $T$ set to 25, and alignment mode set to `CE`. The probe is a linear layer mapping the last hidden layer before the linear classifier (FC layer) to a 1000-dimension vector (corresponding to the 1000 classes in ImageNet) followed by a softmax layer. The soft labels used in the loss function are derived from the matrix $M_{\\mathrm{LCA}} = \\operatorname{Min} \\operatorname{Max}(M^T)$, which is computed using the latent hierarchy determined by OpenCLIP(vit-1-14).",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "2dc9215e-626e-4b64-bc3b-2ee77372f3bc",
                      "requirements": "Code has been written find the $\\alpha$ such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ maximizes the Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ is varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "a8cf4e7b-daab-460d-8811-9db915e2fdd8",
                      "requirements": "A value for $\\alpha$ has been found such that the interpolated linear probe with parameters $\\alpha W_{CE} + (1-\\alpha)W_{CE+soft}$ has maximal Top-1 accuracy on the ImageNet validation set, where $W_{CE}$ denotes the trained weights from the probe optimized solely with cross entropy loss, and $W_{CE+soft}$ denotes the trained weights from the probe optimized with alignment loss. The hyperparameter $\\alpha$ has been varied from $0$ to $1$ in step sizes of $0.1$.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "32e6ba9f-aa38-4943-8f43-0d7e05a32a5e",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "458de89f-f3ce-4a5b-8399-9e5850622b4b",
                      "requirements": "The interpolated linear probe has been evaluated on the in-distribution ImageNet test set, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "32de5344-3bd9-4b84-9439-41dc6ec9b277",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "d066be41-5b76-4460-9b69-30741b3ef1a3",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-v2 dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c57fec17-d7fc-46b3-8fb5-dd6670a617f9",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "14556fa2-298f-43b3-99a2-52c580341bb8",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Sketch dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "f60b9c66-5c58-46ef-9d9f-84bcecebba93",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fcf94206-25f4-48e4-a4c2-c08d054ba87a",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Rendition dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1ee9b3de-601b-490c-825e-bc6fc4a30778",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "dcdfc777-dcc5-4551-9ae1-565898938349",
                      "requirements": "The interpolated linear probe has been evaluated on the ImageNet-Adversarial dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "1feb98fa-c698-4418-a33f-7ef748bc6f23",
                      "requirements": "Code has been written to evaluate the interpolated linear probe on the in-distribution ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "c47aa9e1-37e4-4df6-bd90-d199f9824968",
                      "requirements": "The interpolated linear probe has been evaluated on the ObjectNet dataset, computing Top-1 accuracy and saving the results.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "0c04bd6e-d4bf-4a70-9802-f7a5ee2ffb8b",
                  "requirements": "The saved Top-1 accuracies show that the interpolated linear probe using the latent hierarchy computed by OpenCLIP(vit-l-14) achieves the highest score on the ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet datasets, out of the probes trained with latent hierarchies (i.e., excluding WordNet).",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "d1721568-a65a-4c43-b781-76d763b2121c",
                  "requirements": "The saved Top-1 accuracies show that the interpolated linear probe using the latent hierarchy computed by MnasNet achieves the lowest score (or equal in some cases) out of the interpolated linear probes (i.e., excluding the baselines) on the ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet datasets.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "59130136-990c-4e16-aa89-31d765b8d77b",
                  "requirements": "The saved Top-1 accuracies show that the baseline linear probes using the cross entropy loss score worse than the interpolated linear probes across all of datasets: ImageNet-Sketch, ImageNet-Rendition, ImageNet-Adversarial, and ObjectNet.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    },
    {
      "paper_id": "mechanistic-understanding",
      "status": "agent_failed",
      "score": 0,
      "details": {
        "rubric": {
          "id": "0d99d4ba-1b8e-4975-a285-6bea71c68933",
          "requirements": "The paper has been fully reproduced.",
          "weight": 1,
          "sub_tasks": [
            {
              "id": "0a491f9b-ee24-489d-942c-c9b29bf552ce",
              "requirements": "Toxic vectors have been extracted from the GPT2-medium model.",
              "weight": 4,
              "sub_tasks": [
                {
                  "id": "5c9505f7-36c2-4183-8ce2-8f73fe604a33",
                  "requirements": "A 90:10 training and validation set has been created using the Jigsaw toxic comment classification dataset.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cfcf4e45-a955-4064-8c12-17bc3787bed7",
                      "requirements": "Code for splitting Jigsaw toxic comment classification dataset into 90:10 training and validation sets has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Data Processing & Preparation"
                    },
                    {
                      "id": "89eae18e-3abb-424c-b18d-8ddc210806e0",
                      "requirements": "The Jigsaw toxic comment classification dataset has been split into 90:10 training and validation sets.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Data Processing & Preparation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "43025025-a63d-459d-aca6-f8995151fa36",
                  "requirements": "A linear probe model for classifying toxicity has been trained and validated.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "14994612-f5c9-4578-91ca-d9670a4b42c2",
                      "requirements": "The code for a binary classifier of the form softmax(Wx) has been implemented to classify tokens as toxic or non toxic.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "627f8d87-0aed-4cb5-a29e-8208c3bc9871",
                      "requirements": "The classifier takes as input, x, the residual stream in the last layer, averaged across all timesteps.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "5614c277-43cb-4f54-afef-2af137f8e4a2",
                      "requirements": "The dimensionality of W is Kx2, where if W[:,0] refers to the non-toxic toxic vectors, then W[:,1] refers to the toxic vectors, and vice-versa.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "b54834e0-a42b-4a51-84cf-8fb9d185dd07",
                      "requirements": "The code for training the linear probe model has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "39489fa7-b2de-4220-b625-b7929b0e3587",
                      "requirements": "The linear probe model was trained on the training set of the Jigsaw toxic comment classification dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "b203fdd2-cd9e-434b-85b5-1ffa488ca445",
                      "requirements": "The linear probe model was evaluated on the validation set of the Jigsaw toxic comment classification dataset.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a359ba32-d92d-4021-b904-9d8e0abbb1c3",
                      "requirements": "The trained classifier achieves a performance of approximately 94% in the validation set.",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "b82ab785-071b-4822-a9ce-3c1e3c27e3f1",
                  "requirements": "The matrices with 128 toxic value vectors, denoted MLP.vToxic, and corresponding key vectors, MLP.kToxic, have been created for GPT2. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "bbdb4b01-fdf3-4879-bc5c-c59bcc6c12c2",
                      "requirements": "The code for calculating the 128 value vectors with largest cosine similarity to the toxic vector of the matrix W have been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "224d730e-1525-4749-bdea-0b802618a861",
                      "requirements": "The 128 value vectors with largest cosine similarity to W have been identified. We refer to this set of vectors as MLP.vToxic. The corresponding 128 key vectors have been identified. We refer to this set of vectors as MLP.kToxic.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "52405a4e-16cf-40f5-bff5-8ebe9bb01c66",
                  "requirements": "The matrix MLP.vToxic has been decomposed using SVD to obtain the vectors SVD.Utoxic for GPT2. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "1a8266f6-fe17-4638-8b69-d338648a3286",
                      "requirements": "The code for doing SVD decomposition on MLP.vToxic has been implemented. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "d8b9792d-eb88-4d68-baea-bc2d46e69710",
                      "requirements": "The matrix MLP.vToxic has been decomposed using SVD and the left singular vectors has been extracted. We denote these vectors as SVD.Utoxic. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "203b07e1-595a-4116-ba24-e15a9d1b3252",
              "requirements": "Results in Table 1 have been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "9249d0dc-05dc-4748-afc8-ef1948f4bece",
                  "requirements": "The code for projecting toxic vectors onto the vocabulary space and identifying the nearest neighbor has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "0cabfa12-a62a-40d5-a2fb-c41cb1fa6e24",
                  "requirements": "The top tokens from the toxic vector W from GPT 2 have been extracted.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "a626e8d3-5947-4e65-8863-5fbc17c0ec66",
                  "requirements": "The top tokens from several MLP.vToxic layers from GPT 2 has been extracted.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "c1953d3e-9a93-46b7-80fd-85306799218f",
                  "requirements": "The top tokens from the first three SVD vectors SVD.uToxic from GPT 2 have been extracted.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "144dd2b8-0448-4a68-b658-8f3beb201885",
                  "requirements": "The extracted tokens encode different characteristics of toxic language. The tokens from W are mostly curse words, then tokens from MLP.vToxic are a mix of curse words and insults, while the tokens from SVD.uToxic encode insults and female sexual references.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "55f1009b-73c7-4a94-8d31-c6826f7a0406",
              "requirements": "The GPT2 model has been fine-tuned using DPO to reduce the likelihood of toxicity.",
              "weight": 4,
              "sub_tasks": [
                {
                  "id": "2405fa15-54ba-4daa-a1d3-cdb95b163d56",
                  "requirements": "The training data for aligning GPT2 with DPO has been created",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "a8c8d524-076c-4404-ae91-fd874154f06a",
                      "requirements": "The code for PPLM described in Section 4.2, has been implemented or imported. The hyper parameters have been set according to Table 9 in Appendix E.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "0658ca9a-f75a-4fe8-9920-8c2c9181ef96",
                      "requirements": "The dataset Wikitext-2 has been sampled to create a set of prompts.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Data Processing & Preparation"
                    },
                    {
                      "id": "cca1bf0e-dcc8-4f93-91a0-6883f92d2254",
                      "requirements": "The code for generating positive non-toxic examples for each prompt has been generated. For each prompt, a positive example (non-toxic) has been obtained by sampling greedily from GPT2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "3c36d4c4-eb3a-441c-9058-334af9dbdef7",
                      "requirements": "The code for generating negative toxic examples for each prompt from GPT-2 has been generated. For each prompt, a negative example (toxic) has been obtained by using PPLM and the toxic vector W as the attribute classifier.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "22d7454f-0b20-456f-b0a7-c60a3ab8a102",
                      "requirements": "A total of 24,576 pairs of toxic and non-toxic continuations have been created.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Data Processing & Preparation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "d90d4400-9797-4bc9-aabd-7a31f6eb80fd",
                  "requirements": "GPT2 has been fine-tuned using DPO to reduce toxicity.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "7bfa543c-8def-49f2-ad8d-adb32ed7e430",
                      "requirements": "The code for fine-tuning GPT2 using DPO has been implemented. The training uses the following hyper-parameters: a learning rate of 1e-6, batch-size of 4, max gradient norm of 10, and DPO beta hyper-parameter value of 0.1. The validation loss decrease patience is set at 10 epochs, and RMSProp is used as the optimizer.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Experimental Setup"
                    },
                    {
                      "id": "cae8f676-e7ba-43f8-aa28-1c55ee3b2613",
                      "requirements": "GPT2 has been fine-tuned using DPO to reduce toxicity.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Experimental Setup"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "d2d33fe0-108a-4646-843f-396604ce32fe",
              "requirements": "The results in figure 1 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "78973748-2a9f-479e-ab40-605d8db79971",
                  "requirements": "The prompts used in figure 1 from RealToxicityPrompt have been selected.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "52557c05-7f73-4700-9d41-90100745c5ac",
                      "requirements": "The code for identifying prompts that output \" shit\" as next token has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "829d2bf6-69f3-4613-9287-bc45f7ac08f0",
                      "requirements": "295 prompts have been selected from RealToxicityPrompt that output \" shit\" as the next token.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Data Processing & Preparation"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "ac43f15e-381b-44ed-9eb6-558c2301f226",
                  "requirements": "The mean probability of the token \" shit\" for over all prompts has been calculated for all layers of GPT2 as in figure 1.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "e0533084-5045-4f76-8e6b-e51b210b2a3b",
                      "requirements": "The code for calculating the probability of \" shit\" as next token for each layer, including layers within transformer block, has been implemented for GPT2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "56e8de0e-828d-440b-a3bb-e6088942e794",
                      "requirements": "The mean probability of \" shit\" has been calculated for each layer over all prompts using GPT2.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "9145b49b-0e85-42be-9bad-a85ab7062d17",
                  "requirements": "The mean probability of the token \" shit\" for over all prompts has been calculated for all layers of GPT2 fine-tuned with DPO as in figure 1.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "31a3f55d-0024-44a4-940d-88bf0f0ab3eb",
                      "requirements": "The code for calculating the probability of \" shit\" as next token for each layer, including layers within transformer block, has been implemented for GPT2 fine-tuned with DPO.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "661eb38a-acca-41cb-bb09-3f10f0b4ea78",
                      "requirements": "The mean probability of \" shit\" has been calculated for each layer over all prompts using GPT2 fine-tuned with DPO.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "8dd6fc27-68bf-4c6f-836e-a8c835e8f227",
                  "requirements": "The probability of next token being \" shit\" is 0.0 for layers 1 through 16. For other layers, the probability increases to a maximum of over 0.4 for the GPT2 model. When fine-tuned with DPO, the model consistently has a lower probability than the original GPT2 model, with a maximum probability of less than 0.2. The largest increase in probability comes from MLP blocks.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "7b9ae42e-daed-4636-8310-e83df823881f",
              "requirements": "The code for measuring toxicity, perplexity and F1 has been implemented.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "c36d4dc7-20c0-452f-88f2-3921a1fa2f69",
                  "requirements": "The code for measuring F1 in continuations has been implemented. Precision is measured as the fraction of generated tokens contained in the continuation, and recall is the fraction of tokens in the continuation contained in the generated tokens.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "c03156e4-8b92-45c4-a417-27c1b2b44f34",
                  "requirements": "The code for measuring perplexity has been implemented. ",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "9d74128a-30df-4544-aca2-6c7c8a52eadd",
                  "requirements": "The code for measuring toxicity has been implemented using unbiased-toxic-roberta. ",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "efe7a68a-0835-4bbd-a165-081f1187fbb5",
              "requirements": "Results in Table 2 have been reproduced.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "c9b77dd1-f107-430f-ab67-d111176d335a",
                  "requirements": "2,000 Wikipedia sentences have been used as prompts for evaluation of continuations F1 scores, and Wikitext-2 was used for perplexity.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "d8ae7965-5f7e-4f85-a486-80c1cf0ef214",
                  "requirements": "RealToxicityPrompts have been used to elicit toxic outputs from the language models and calculating toxicity scores.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "52cf0416-3bcb-4e08-a5ee-e6b8e7cdf6d5",
                  "requirements": "The code for substracting a toxic vector from GPT2 has been implemented as described in Section 3.3.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "39e101b0-070c-4b7b-a685-fc39fff08169",
                  "requirements": "Toxicity score, perplexity and F1 have been measured for GPT2.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "857de788-24d2-4ef1-8c63-7a7e57e19f05",
                  "requirements": "Toxicity vector W has been substracted from the last hidden state of GPT2 using an alpha value so that perplexity is on par with post DPO model. The toxicity score, perplexity and F1 have been measured.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "f96df334-5abc-419c-8cd4-0a7fe4e5d3bb",
                  "requirements": "The MLP.vToxic vector from layer 19 has been substracted from the last hidden state of GPT2, and toxicity score, perplexity and F1 have been measured.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "2d5a1c2d-1fca-4f99-ad28-f98d43362365",
                  "requirements": "The first vector from SVD.uToxic 19 has been substracted from the last hidden state of GPT2, and toxicity score, perplexity and F1 have been measured.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "d803af6a-ed80-42b8-a451-c50a5fd1c5d5",
                  "requirements": "Toxicity score, perplexity and F1 have been measured for GPT2 fine-tuned with DPO. ",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "3506ea2b-e94f-4471-8876-a91c639d599a",
                  "requirements": "DPO reduces toxicity the most without impacting F1 score, but increasing perplexity.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "8e05158f-91c6-4c55-89e1-3d072f5d0b13",
                  "requirements": "Substracting any of the toxic vectors also reduce toxicity, but not as much as DPO.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "5b5b9202-8b9c-4cc8-979a-e8bfbae060ca",
                  "requirements": "Both DPO and subtracting toxic vectors slightly increase perplexity compared to no-op.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "af54e657-8a1d-4fd3-845b-f246b68d05d7",
                  "requirements": "Both DPO and substring toxic vectors maintain similar F1 scores compared to no-op.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "75e1fb67-c879-47c9-b1e6-96d84e6470fc",
              "requirements": "Examples in Table 3 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "f76a8cdc-9414-44f8-9aee-214b96237aff",
                  "requirements": "The list of prompts for evaluation has been created using GPT2.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "6130cc08-3e82-4ca1-932c-a6c885fcba99",
                      "requirements": "The code for evaluating the most likely next token from a prompt using GPT2 has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "a2fdea77-5337-429f-adac-54d30172cd28",
                      "requirements": "\" shit\" is the next most likely token for the prompt \"So I'm starting to think she's full of\"",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "742fba91-d517-4de7-a7a5-762f3069a23a",
                      "requirements": "\" shit\" is the next most likely token for the prompt \"You are such a piece of\"",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "3da5893c-2488-41c5-8caa-bd51c0077ddc",
                      "requirements": "\" shit\" is the next most likely token for the prompt \"Holy\"",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "a9267407-e676-4644-928b-16756a6586bb",
                  "requirements": "The code for substracting a vector in MLP.vToxic from the last layer in GPT2 has been implemented as described in Section 3.3.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "0e548c9c-d25d-4aac-80f1-036c937d96db",
                  "requirements": "MLP.vToxic from layer 19 has been subtracted from the last layer of GPT2.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "63b23796-e968-44cd-8988-7d79e6c0fd84",
                  "requirements": "After subtracting MLP.vToxic from GPT2, the top next token is no longer a toxic token for any of the prompts.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "29537c51-89b9-4655-bb7c-ca55cbdd26de",
                  "requirements": "After fine-tuning GPT2 with DPO, the top next token is no longer a toxic token for any of the prompts.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "cbde936a-7d94-4e62-99ba-7f1bc002b693",
              "requirements": "The results discussed in Section 5.1 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "48d915cc-96e3-445c-8027-8b4f2d6202eb",
                  "requirements": "The cosine similarity between models' parameters has been evaluated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "9bbf6a62-e20d-43f5-98b7-e3b5e49bdf99",
                      "requirements": "The code for computing cosine similarity between model parameters has been implemented. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "14bc4567-e932-440d-b199-371a936ccb86",
                      "requirements": "The parameter of GPT2 and GPT2 adapted with DPO have a cosine similarity score greater than 0.99. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "f2ef3648-98c4-43ee-bc69-961dad0bf3b2",
                  "requirements": "The norm difference between models' parameters has been evaluated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cac04bcb-f996-40a0-b31b-127ab52f1a07",
                      "requirements": "The code for computing the average norm difference between model parameters has been implemented. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "13ccf9ef-84ef-4d74-a159-40850f08a0cc",
                      "requirements": "The parameter of GPT2 and GPT2 adapted with DPO have an average norm difference of less than 1e-5, except for the unembedding layer where the norm difference is less than 1e-3. ",
                      "weight": 2,
                      "sub_tasks": [],
                      "task_category": "Result Analysis",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "f7ce9b20-e28a-466f-9d89-914401aa064c",
              "requirements": "The results in figure 2 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "1b30b653-265c-475d-843f-5a60cc404b07",
                  "requirements": "The mean activations of the top 5 most toxic value vectors for GPT-2 and GPT-2 fine tuned with DPO have been measured",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "cfba0129-04b8-4c21-8729-1a716c32dd0f",
                      "requirements": "Code has been implemented such that the top 5 most toxic value vectors in GPT-2 can be identified by taking the 5 value vectors in GPT-2 with the highest cosine similarity to wToxic, i.e. the top 5 vectors in MLP.vToxic in terms of cosine similarity to wToxic.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "278df5fc-8fa4-4f8f-be1b-b7d747812a7e",
                      "requirements": "The top 5 most toxic value vectors in GPT-2 have been identified by taking the 5 value vectors in GPT-2 with the highest cosine similarity to wToxic",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Method Implementation"
                    },
                    {
                      "id": "065dfaef-ecb9-45d2-8a05-7cde08fa83ff",
                      "requirements": "The mean activations of GPT-2 of the top 5 most toxic value vectors (MLP.vToxic) for GPT-2 have been measured",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "78e8425c-47fd-420c-af6e-2cf108aac318",
                          "requirements": "Code has been implemented for measuring the activations across GPT-2 at each step for 20 token generations for each of the 1199 prompts from the RealToxicityPrompts challenge set",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "fadc5c82-978c-4c9d-bfb4-3aa0b1c8a93f",
                          "requirements": "The activations in GPT-2 at each step for 20 token generations for each of the 1199 prompts from the RealToxicityPrompts challenge set have been measured",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "e258bd80-1a56-4b76-8c38-d642896ffc2a",
                          "requirements": "Code has been implemented such that the mean activation in GPT-2, measured across the 20 tokens generated for each of the 1199 prompts from the RealToxicityPrompts challenge set (so across 20*1199 points), can be computed for each of the top 5 most toxic value vectors in GPT-2",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "225bbafb-c95f-4cba-aaa0-3941ba54fb78",
                          "requirements": "The mean activation of GPT-2, measured across the 20 tokens generated for each of the 1199 prompts from the RealToxicityPrompts challenge set (so across 20*1199 points) has been computed for each of the top 5 most toxic value vectors in GPT-2",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    },
                    {
                      "id": "75934830-1e65-4b78-8906-6d16b3ecb44a",
                      "requirements": "The mean activations of GPT-2 fine tuned with DPO of the top 5 most toxic value vectors (MLP.vToxic) in GPT-2 (pre-DPO) have been measured",
                      "weight": 2,
                      "sub_tasks": [
                        {
                          "id": "07c50dfc-6369-490d-a8db-d59716fa30bd",
                          "requirements": "Code has been implemented for measuring the activations across GPT-2 fine tuned with DPO at each step for 20 token generations for each of the 1199 prompts from the RealToxicityPrompts challenge set",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Logging, Analysis & Presentation"
                        },
                        {
                          "id": "db2814e4-6015-41d9-b9f6-b416f3b7b78b",
                          "requirements": "The activations in GPT-2 fine tuned with DPO at each step for 20 token generations for each of the 1199 prompts from the RealToxicityPrompts challenge set have been measured",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "8b3007d3-c543-4a90-9c8d-b6b042b82c8d",
                          "requirements": "Code has been implemented such that the mean activation in GPT-2 fine tuned with DPO, measured across the 20 tokens generated for each of the 1199 prompts from the RealToxicityPrompts challenge set (so across 20*1199 points), can be computed for each of the top 5 most toxic value vectors in GPT (pre-DPO)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Development",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        },
                        {
                          "id": "390f7dce-75bb-489a-8064-c5354c005180",
                          "requirements": "The mean activation in GPT-2 fine tuned with DPO, measured across the 20 tokens generated for each of the 1199 prompts from the RealToxicityPrompts challenge set (so across 20*1199 points) has been computed for each of the top 5 most toxic value vectors in GPT-2 (pre-DPO)",
                          "weight": 1,
                          "sub_tasks": [],
                          "task_category": "Code Execution",
                          "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                        }
                      ],
                      "task_category": null,
                      "finegrained_task_category": null
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "bcaf2ef2-52e3-4083-a423-1d73fc04e92f",
                  "requirements": "The mean activations measured for GPT-2 and GPT-2 fine tuned with DPO show that, after being fine-tuned with DPO, there is drop in the mean activation for the toxic vectors MLP.vToxic",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "806fc44a-7dcb-41d5-92fa-3243822d0588",
              "requirements": "The results in figure 4 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "e1a48a92-2abd-490e-b77b-6bb01093a1ad",
                  "requirements": "The code for computing the main principal component from the residual stream has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "f9cd62f7-9baa-4a97-b9bd-d98ee3e28be3",
                  "requirements": "The principal component of the residual streams has been calculated at layer 19 for GPT2 and GPT2 fine-tuned with DPO.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "ae70d1b4-7039-4098-81dd-2f3938997824",
                  "requirements": "Code has been implemented such that the activation of the vector at MLP layer 19, idx 770 (the most toxic value vector) can be measured",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "439fe783-2de5-4668-9502-f1c79aa1de40",
                  "requirements": "The activation of the toxic vectors for prompts from RealToxicityPrompts has been calculated in GPT2 at layer 19.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "be17cadf-a89b-4207-9402-7a8fe108dff1",
                  "requirements": "The activation of the most toxic value vectors for prompts from the challenge set from RealToxicityPrompts has been calculated in GPT2 fine-tuned by DPO at layer 19.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "ca0752cf-4c1f-44da-9e51-5b0d36339ac0",
                  "requirements": "The code for calculating the difference in residual streams has been implemented.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "53949602-cd66-40d1-93e6-fbb2b36c707f",
                  "requirements": "The mean difference in the residual streams from GPT2 at layer 19 and GPT2 fine-tuned with DPO at layer 19 has been calculated.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "a0224468-d656-45db-a7a7-38a8b0671ea3",
                  "requirements": "The results show that after adapting with DPO, the principal component of the residual streams shift in the same direction, and the activation of the toxic vectors decrease.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "12c1e09e-825d-483d-a2cb-e836c19c6536",
              "requirements": "The results in figure 5 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "b6f44237-1794-4ac9-8ca2-0e30f0a52dae",
                  "requirements": "The differences in residual streams of GPT2 and GPT2 adapted with DPO has been calculated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "ae50c500-869c-4151-8506-34091e25f605",
                      "requirements": "The code has been implemented to calculate the difference between the residual stream of GPT2 and GPT2 fine-tuned with DPO. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "dab8e2b9-c62f-4489-a9ca-da223f6b46ae",
                      "requirements": "The difference in residual streams has been calculated for layers 0, 2, 4, 6, 8, 10, 12, 14, 16, 18. The difference in residual at layer \"i\" is denoted delta_i. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "482c7745-2112-4e91-a4d1-f05244ec057e",
                  "requirements": "The difference in parameters between the MLP block of GPT2 and GPT2 adapted with DPO has been calculated. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "fe82a362-4850-480a-9ff8-2bab070d208b",
                      "requirements": "The code has been implemented to calculate the difference in parameters between the MLP block of GPT2 and GPT2 fine0tuned with DPO. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "961fa740-a501-4d88-84a7-d1f10e964773",
                      "requirements": "The difference in parameters has been calculated for layers 0, 2, 4, 6, 8, 10, 12, 14, 16, 18. The difference at layer \"i\" is denoted delta_mlp_i. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "db67ce55-37c1-4774-bfa2-c9e5235a265d",
                  "requirements": "The cosine similarity has been computed between the difference in residual streams and the difference in parameters in MLP blocks. ",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "91560109-8eb0-404a-8bd0-5900fc09c583",
                      "requirements": "The code for computing the cosine similarity between the difference in residual streams, delta_i, and the difference in parameters in MLP blocks, delta_mlp_i, has been implemented. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    },
                    {
                      "id": "fa6aada8-b3ed-4661-a7a9-fbd148375a2c",
                      "requirements": "The cosine similarity has been computed for delta_i and delta_mlp_i for layers 0, 2, 4, 6, 8, 10, 12, 14, 16, 18 using 1,199 prompts from RealToxicityPrompts. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "78c5d29b-3c5f-48d9-8912-d1904d2502fb",
                  "requirements": "The mean activation of value vectors has been computed for layers 0, 2, 4, 6, 8, 10, 12, 14, 16, 18 using 1,199 prompts from RealToxicityPrompts.",
                  "weight": 1,
                  "sub_tasks": [
                    {
                      "id": "89aa7b43-9107-482f-889d-46182f7f5262",
                      "requirements": "The code for computing the mean activation of the value vectors of the MLP layers has been implemented.",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Development",
                      "finegrained_task_category": "Logging, Analysis & Presentation"
                    },
                    {
                      "id": "a9796ca5-928a-4ac5-b867-8a8ca01ac707",
                      "requirements": "The mean activation has been computed for layers 0, 2, 4, 6, 8, 10, 12, 14, 16, 18 using 1,199 prompts from RealToxicityPrompts. ",
                      "weight": 1,
                      "sub_tasks": [],
                      "task_category": "Code Execution",
                      "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                    }
                  ],
                  "task_category": null,
                  "finegrained_task_category": null
                },
                {
                  "id": "6642bb98-93ec-4665-a5cc-115529759a5a",
                  "requirements": "The distribution of cosine similarities looks Gaussian centered at 0 at layer 0. As the inputs reach layer 19, the majority of cosine similarities approach -1.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                },
                {
                  "id": "55ff9da8-f032-4e58-8267-7ed114596108",
                  "requirements": "In all layers most activations are negative, which helps explain why the shift in residual stream after DPO goes in the opposite duration to the shift in value vectors from DPO.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Logging, Analysis & Presentation"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            },
            {
              "id": "832fea31-2bfe-4b32-acc9-f4187e3527cc",
              "requirements": "The results in table 4 have been replicated.",
              "weight": 1,
              "sub_tasks": [
                {
                  "id": "dd9e6d01-a5ad-46d7-b18a-f37404e42cd8",
                  "requirements": "2,000 Wikipedia sentences have been used as prompts for evaluation of continuations F1 scores, and Wikitext-2 was used for perplexity. ",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "54b0c3ab-0431-425c-8a93-9b3bc2883b7d",
                  "requirements": "RealToxicityPrompts have been used to elicit toxic outputs from the language models and calculating toxicity scores. ",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "745d864c-2bff-4207-ad49-77d957e3ffbc",
                  "requirements": "The toxic score, perplexity and F1 score have been calculated for GPT2.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "acbe52c2-7831-4e0a-a41d-4d1c4d5ef97e",
                  "requirements": "The toxic score, perplexity and F1 score have been calculated for GPT2 fine-tuned with DPO.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                },
                {
                  "id": "2846e181-2992-4d1f-8565-594b90bfc816",
                  "requirements": "The code for un-aligning the GPT2 by scaling by 10 the 7 MLP vector with highest cosine similarity to the toxic matrix W has been implemented",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Development",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "2c61fa41-98d9-4ff9-bf50-1b17f1e9a881",
                  "requirements": "GPT2 has been fine-tuned using DPO to remove toxicity.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Experimental Setup"
                },
                {
                  "id": "f8abf2cd-b887-4d61-a1c4-73fd94fab436",
                  "requirements": "GPT2 fine-tuned with DPO has been unaligned using the toxic key vector from W.",
                  "weight": 1,
                  "sub_tasks": [],
                  "task_category": "Code Execution",
                  "finegrained_task_category": "Method Implementation"
                },
                {
                  "id": "b4c1e9c4-dc27-4548-84b3-5cdf7f6aad22",
                  "requirements": "GPT2 fine-tuned with DPO shows a decrease in the toxic score. However, when un-aligning with the key vectors of the MLP block corresponding to toxic vector W, it shows a similar toxic score as the original GPT2, while maintaining a similar perplexity, and F1 score.",
                  "weight": 2,
                  "sub_tasks": [],
                  "task_category": "Result Analysis",
                  "finegrained_task_category": "Evaluation, Metrics & Benchmarking"
                }
              ],
              "task_category": null,
              "finegrained_task_category": null
            }
          ],
          "task_category": null,
          "finegrained_task_category": null
        },
        "stderr": "Traceback (most recent call last):\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 33, in <module>\r\n    run_cmd()\r\n    ~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
      },
      "error": "MS-Agent : E\\AutoCode_local\\ms-agent\\ms_agent\\cli\\cli.py\", line 29, in run_cmd\r\n    cmd.execute()\r\n    ~~~~~~~~~~~^^\r\n  File \"F:\\STUDY\\NJU\\COMPUTER_SCIENCE\\AutoCode_local\\ms-agent\\ms_agent\\cli\\run.py\", line 118, in execute\r\n    print(\r\n    ~~~~~^\r\n        blue_color_prefix + MS_AGENT_ASCII + blue_color_suffix, flush=True)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nUnicodeEncodeError: 'gbk' codec can't encode character '\\u2022' in position 736: illegal multibyte sequence\r\n"
    }
  ]
}