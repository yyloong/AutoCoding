llm:
  service: openai
  #model: a6000mnt/Qwen-235B-A35B-thinking
  #model: a6000mnt/Qwen_30B_code
  #model: a6000mnt/Qwen_30B_thinking
  #model: Qwen_30B_code
  model: qwen3-max
  openai_api_key:  
  #openai_base_url: http://210.28.134.171:8000/v1
  #openai_base_url: http://210.28.135.93:8000/v1
  openai_base_url: https://dashscope.aliyuncs.com/compatible-mode/v1

agent: structure_evaluate
type: state_llmagent

generation_config:
  temperature: 0.2
  top_k: 20
  stream: true
  max_tokens: 32000
  extra_body:
    dashscope_extend_params:
      provider: b
    enable_thinking: false


prompt:
  system: |
    You are responsible for code structure evaluation. Given the current project structure, you need to evaluate whether the structure is reasonable and meets the project requirements.
    Your goal is try to make the project structure more organized and easier to understand.
    If you find the structure is not reasonable, you should use state_transition tool to transfer to coding agent to refine the structure.
    A good structure should be minimalist and flat, strictly adhering to the DRY (Don't Repeat Yourself) principle. It must avoid deep nesting, over-engineering, and duplicated files, ensuring that every directory and module has a distinct, single responsibility without unnecessary complexity.
    If you think the structure is already good enough, you can make a state_transition with positive feedback.
    Now, begin:

handler: config_handler

callbacks:
  - callbacks/tool_use_callback

tools:
  state_transition:
    mcp: false
  document_inspector:
    mcp: false
  file_system:
    mcp: false
    exclude:
      - write_file
      - create_directory
      - delete_file_or_dir
    ignore_files:
      - paper.pdf
      - paper.md
    limit_len_files_end_with:
      - .csv
      - .npz
      - .tsv
      - .fasta
      - .obo
    limit_len: 1000

memory:
  - name: statememory
    user_id: "code_scratch"
#memory:
#  - name: mem0
#    user_id: "code_scratch"
#    agent_id: "subtask"
#    conversation_search_limit: 10
#    procedural_search_limit: 3
#    embedding_model: "text-embedding-v4"
#    summary_model: "qwen3-max"
#    max_tokens: 4096

max_chat_round: 100

tool_call_timeout: 30000

output_dir: new_output

help: |
