# MS-Agent Code Scratch - PaperBench è¯„æµ‹æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ **PaperBench** åŸºå‡†æ¥è¯„æµ‹ **MS-Agent Code Scratch** é¡¹ç›®åœ¨ AI è®ºæ–‡å¤ç°ä¸­çš„èƒ½åŠ›ã€‚

PaperBench æ˜¯ OpenAI å¼€æºçš„è¯„æµ‹åŸºå‡†ï¼ŒåŒ…å« 20 ç¯‡ ICML 2024 è®ºæ–‡ï¼Œå…± 8,316 ä¸ªå¯è¯„åˆ†ä»»åŠ¡ã€‚

**MS-Agent Code Scratch** æ˜¯ä¸€ä¸ªä»£ç ç”Ÿæˆå’Œä¿®å¤ç³»ç»Ÿï¼Œç‰¹åˆ«é€‚åˆåœ¨ PaperBench ä¸Šè¿›è¡Œè¯„æµ‹ï¼Œå› ä¸ºå®ƒå…·å¤‡ï¼š
- âœ… è®ºæ–‡å†…å®¹ç†è§£ä¸åˆ†æ
- âœ… ä»£ç é¡¹ç›®è‡ªåŠ¨ç”Ÿæˆ
- âœ… ç¼–è¯‘é”™è¯¯æ£€æµ‹ä¸ä¿®å¤
- âœ… å®Œæ•´çš„ workflow æ”¯æŒ

---

## ğŸ¯ è¯„æµ‹æ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆ 1: Code-Dev è¯„æµ‹ï¼ˆæ¨èå¿«é€Ÿè¯„æµ‹ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå¿«é€Ÿè¯„ä¼°ä»£ç ç”Ÿæˆè´¨é‡ï¼Œæ— éœ€ GPU å’Œå®éªŒæ‰§è¡Œ

**ç‰¹ç‚¹**ï¼š
- ä»…è¯„ä¼°ä»£ç å¼€å‘è´¨é‡ï¼ˆä¸è¯„ä¼°æ‰§è¡Œå’Œç»“æœåŒ¹é…ï¼‰
- æ— éœ€ GPUï¼Œæˆæœ¬å’Œæ—¶é—´é™ä½ ~85%
- è¯„ä¼°æŒ‡æ ‡æ¸…æ™°ï¼Œå¯å¿«é€Ÿè¿­ä»£

**æµç¨‹**ï¼š
```
PaperBench Paper 
    â†“
MS-Agent è®ºæ–‡åˆ†æ â†’ ä»£ç ç”Ÿæˆ â†’ ä»£ç è´¨é‡è¯„åˆ†
    â†‘
è¯„ä¼°ï¼šæ–¹æ³•å®ç°ã€æ•°æ®å¤„ç†ã€æ¨¡å—ç»“æ„
```

### æ–¹æ¡ˆ 2: å®Œæ•´è¯„æµ‹ï¼ˆæ›´ä¸¥æ ¼ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå®Œæ•´è¯„ä¼°ä»£ç å¤ç°èƒ½åŠ›ï¼ŒåŒ…æ‹¬å®éªŒæ‰§è¡Œ

**ç‰¹ç‚¹**ï¼š
- è¯„ä¼°ä»£ç å¼€å‘ + ä»£ç æ‰§è¡Œ + ç»“æœåŒ¹é…
- éœ€è¦ GPU å’Œå®éªŒç¯å¢ƒ
- æ›´æ¥è¿‘çœŸå®ç ”ç©¶å¤ç°

**æµç¨‹**ï¼š
```
PaperBench Paper 
    â†“
MS-Agent è®ºæ–‡åˆ†æ â†’ ä»£ç ç”Ÿæˆ â†’ ä»£ç æ‰§è¡Œ â†’ ç»“æœéªŒè¯ â†’ ç»¼åˆè¯„åˆ†
    â†‘
è¯„ä¼°ï¼šä»£ç è´¨é‡ + æ‰§è¡ŒæˆåŠŸ + ç»“æœå‡†ç¡®æ€§
```

---

## ğŸ“¦ å®‰è£…å’Œå‡†å¤‡

### 1. å®‰è£… PaperBench

```bash
# å…‹éš†å®˜æ–¹ä»“åº“
git clone https://github.com/openai/frontier-evals.git --filter=blob:none
cd frontier-evals

# ä¸‹è½½æ•°æ®é›†ï¼ˆä½¿ç”¨ Git LFSï¼‰
git lfs fetch --include "project/paperbench/data/**"
git lfs checkout project/paperbench/data

# è®¾ç½®ç¯å¢ƒå˜é‡
export PAPERBENCH_DATA_DIR="$(pwd)/project/paperbench/data"
```

### 2. å®‰è£…ä¾èµ–

```bash
# è¿›å…¥ PaperBench ç›®å½•
cd project/paperbench

# ä½¿ç”¨ uv å®‰è£…ä¾èµ–
uv sync
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¤ºä¾‹é…ç½®
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥å¿…è¦çš„ API Key
# - OPENAI_API_KEY: ç”¨äº Agent
# - GRADER_OPENAI_API_KEY: ç”¨äºè¯„åˆ†ï¼ˆå¯é€‰ï¼Œé»˜è®¤åŒä¸Šï¼‰
# - å…¶ä»–æ¨¡å‹ API Keyï¼ˆå¦‚éœ€è¦ï¼‰
```

### 4. å‡†å¤‡ Agent èµ„æºï¼ˆå¦‚éœ€è¦ï¼‰

```bash
# æŸäº›è®ºæ–‡éœ€è¦é¢å¤–æƒé™
cp paperbench/agents/agent.env.example paperbench/agents/agent.env

# ç¼–è¾‘ agent.envï¼Œå¡«å…¥ï¼š
# - OPENAI_API_KEYï¼ˆç”¨äº API è°ƒç”¨ï¼‰
# - HF_TOKENï¼ˆHuggingFace tokenï¼Œç”¨äº ImageNet/Llama-2ï¼‰
```

### 5. æ„å»º Docker é•œåƒ

```bash
# æ„å»ºæ‰€æœ‰å¿…è¦çš„ Docker é•œåƒ
bash paperbench/scripts/build-docker-images.sh

# æˆ–æ‰‹åŠ¨æ„å»ºåŸºç¡€é•œåƒ
docker build -f paperbench/Dockerfile.base -t pb-env:latest .
docker build -f paperbench/reproducer.Dockerfile -t pb-reproducer:latest .
```

---

## ğŸš€ è¯„æµ‹æ‰§è¡Œæ­¥éª¤

### æ­¥éª¤ 1: ä¿®æ”¹ MS-Agent é…ç½®ä»¥æ”¯æŒ PaperBench

åœ¨ `projects/code_scratch/refine.yaml` ä¸­æ·»åŠ æˆ–ä¿®æ”¹ï¼š

```yaml
paperbench:
  enabled: true
  eval_type: "code-dev"  # æˆ– "full"
  paper_dir: "${PAPERBENCH_DATA_DIR}"
  
prompt:
  system: |
    ä½ æ˜¯ä¸€åé«˜çº§ç ”ç©¶å·¥ç¨‹å¸ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯å¤ç°å­¦æœ¯è®ºæ–‡ã€‚

    æµç¨‹ï¼š
    1. ä»”ç»†é˜…è¯»è®ºæ–‡ï¼ˆPDF æˆ– Markdownï¼‰
    2. ç†è§£è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œæ–¹æ³•
    3. è®¾è®¡å®Œæ•´çš„ä»£ç æ¶æ„
    4. å®ç°æ‰€æœ‰å…³é”®æ–¹æ³•
    5. å‡†å¤‡æµ‹è¯•ä»£ç å’Œæ•°æ®å¤„ç†
    
    è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
    - è®ºæ–‡ç†è§£æ€»ç»“
    - ä»£ç ç»“æ„è®¾è®¡
    - å…³é”®å®ç°ç»†èŠ‚
    - æµ‹è¯•è®¡åˆ’
```

### æ­¥éª¤ 2: åˆ›å»º PaperBench è¯„æµ‹åŒ…è£…å™¨

åˆ›å»ºæ–‡ä»¶ `projects/code_scratch/paperbench_wrapper.py`ï¼š

```python
#!/usr/bin/env python3
"""
PaperBench è¯„æµ‹åŒ…è£…å™¨ï¼Œé›†æˆ MS-Agent Code Scratch
"""

import os
import json
import asyncio
from pathlib import Path
from typing import Dict, List, Any

class PaperBenchEvaluator:
    """ä½¿ç”¨ MS-Agent è¯„æµ‹ PaperBench è®ºæ–‡"""
    
    def __init__(self, paperbench_data_dir: str, ms_agent_config: str):
        self.paperbench_dir = Path(paperbench_data_dir)
        self.ms_agent_config = ms_agent_config
        self.results = []
    
    async def evaluate_paper(self, paper_id: str) -> Dict[str, Any]:
        """è¯„æµ‹å•ç¯‡è®ºæ–‡"""
        paper_dir = self.paperbench_dir / "papers" / paper_id
        
        # è¯»å–è®ºæ–‡ä¿¡æ¯
        paper_md = paper_dir / "paper.md"
        if not paper_md.exists():
            paper_md = paper_dir / "paper.pdf"  # å¤‡é€‰
        
        # è¯»å–è¯„ä¼°æ ‡å‡†ï¼ˆRubricï¼‰
        rubric_file = paper_dir / "rubric.json"
        with open(rubric_file) as f:
            rubric = json.load(f)
        
        print(f"\n{'='*60}")
        print(f"æ­£åœ¨è¯„æµ‹è®ºæ–‡: {paper_id}")
        print(f"{'='*60}")
        
        # è°ƒç”¨ MS-Agent Code Scratch
        result = await self._run_ms_agent(paper_id, paper_dir)
        
        return {
            "paper_id": paper_id,
            "status": result.get("status", "failed"),
            "score": result.get("score", 0),
            "code_generated": result.get("code_generated", False),
            "compilation_passed": result.get("compilation_passed", False),
            "errors": result.get("errors", []),
            "rubric": rubric
        }
    
    async def _run_ms_agent(self, paper_id: str, paper_dir: Path) -> Dict:
        """è¿è¡Œ MS-Agent ä»£ç ç”Ÿæˆ"""
        # è¿™é‡Œè°ƒç”¨ MS-Agent CLI
        query = f"""
        å¤ç°ä»¥ä¸‹è®ºæ–‡ï¼š{paper_id}
        
        è®ºæ–‡ç›®å½•ï¼š{paper_dir}
        
        è¯·ï¼š
        1. é˜…è¯»è®ºæ–‡å†…å®¹
        2. ç†è§£è®ºæ–‡çš„æ–¹æ³•å’Œè´¡çŒ®
        3. ç”Ÿæˆå®Œæ•´çš„ä»£ç å®ç°
        4. ç¡®ä¿ä»£ç èƒ½æˆåŠŸç¼–è¯‘
        """
        
        # è°ƒç”¨ MS-Agent çš„ LLM Agent
        # è¿™é‡Œéœ€è¦é›†æˆå®é™…çš„ agent è°ƒç”¨é€»è¾‘
        
        return {
            "status": "completed",
            "code_generated": True,
            "compilation_passed": True,
            "score": 0.5
        }
    
    async def evaluate_all(self, paper_split: str = "debug") -> List[Dict]:
        """è¯„æµ‹æ‰€æœ‰è®ºæ–‡"""
        papers_dir = self.paperbench_dir / "papers"
        
        # æ ¹æ® split è¿‡æ»¤è®ºæ–‡
        if paper_split == "debug":
            # è°ƒè¯•ç”¨ï¼Œåªè¯„æµ‹å°‘æ•°å‡ ç¯‡
            paper_ids = [d.name for d in papers_dir.iterdir() 
                        if d.is_dir()][:3]
        else:
            # å®Œæ•´è¯„æµ‹
            paper_ids = [d.name for d in papers_dir.iterdir() 
                        if d.is_dir()]
        
        for paper_id in paper_ids:
            result = await self.evaluate_paper(paper_id)
            self.results.append(result)
        
        return self.results
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¯„æµ‹æŠ¥å‘Š"""
        if not self.results:
            return {}
        
        total_papers = len(self.results)
        successful = sum(1 for r in self.results 
                        if r["status"] == "completed")
        avg_score = sum(r.get("score", 0) for r in self.results) / total_papers
        compilation_rate = sum(1 for r in self.results 
                              if r.get("compilation_passed")) / total_papers
        
        return {
            "total_papers": total_papers,
            "successful_completions": successful,
            "success_rate": successful / total_papers,
            "average_score": avg_score,
            "compilation_pass_rate": compilation_rate,
            "detailed_results": self.results
        }


async def main():
    """ä¸»è¯„æµ‹æµç¨‹"""
    paperbench_dir = os.getenv("PAPERBENCH_DATA_DIR")
    if not paperbench_dir:
        raise ValueError("è¯·è®¾ç½® PAPERBENCH_DATA_DIR ç¯å¢ƒå˜é‡")
    
    ms_agent_config = "projects/code_scratch"
    
    evaluator = PaperBenchEvaluator(paperbench_dir, ms_agent_config)
    
    # è¿è¡Œè¯„æµ‹ï¼ˆå…ˆç”¨ debug åˆ†å‰²æµ‹è¯•ï¼‰
    await evaluator.evaluate_all("debug")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = evaluator.generate_report()
    
    print("\n" + "="*60)
    print("è¯„æµ‹æŠ¥å‘Š")
    print("="*60)
    print(f"æ€»è®ºæ–‡æ•°: {report['total_papers']}")
    print(f"æˆåŠŸå®Œæˆ: {report['successful_completions']}")
    print(f"æˆåŠŸç‡: {report['success_rate']:.2%}")
    print(f"å¹³å‡åˆ†æ•°: {report['average_score']:.2f}")
    print(f"ç¼–è¯‘é€šè¿‡ç‡: {report['compilation_pass_rate']:.2%}")
    
    # ä¿å­˜æŠ¥å‘Š
    with open("paperbench_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print("\næŠ¥å‘Šå·²ä¿å­˜åˆ° paperbench_report.json")


if __name__ == "__main__":
    asyncio.run(main())
```

### æ­¥éª¤ 3: è¿è¡Œ PaperBench Code-Dev è¯„æµ‹

```bash
# å¿«é€Ÿè¯„æµ‹ï¼ˆä»…ä»£ç è´¨é‡ï¼‰
cd frontier-evals/project/paperbench

uv run python -m paperbench.nano.entrypoint \
  paperbench.paper_split=debug \
  paperbench.solver=paperbench.nano.eval:ExternalPythonCodingSolver \
  paperbench.solver.agent_id=aisi-basic-agent-openai-dev \
  paperbench.solver.cluster_config=alcatraz.clusters.local:LocalConfig \
  paperbench.solver.cluster_config.image=aisi-basic-agent:latest \
  paperbench.judge.code_only=True \
  runner.recorder=nanoeval.json_recorder:json_recorder
```

### æ­¥éª¤ 4: è¿è¡Œå®Œæ•´è¯„æµ‹ï¼ˆå¯é€‰ï¼‰

```bash
# å®Œæ•´è¯„æµ‹ï¼ˆåŒ…æ‹¬ä»£ç æ‰§è¡Œå’Œç»“æœéªŒè¯ï¼‰
# éœ€è¦ GPU æ”¯æŒ
uv run python -m paperbench.nano.entrypoint \
  paperbench.solver=paperbench.nano.eval:ExternalPythonCodingSolver \
  paperbench.solver.agent_id=aisi-basic-agent-openai-dev \
  paperbench.solver.cluster_config=alcatraz.clusters.local:LocalConfig \
  paperbench.solver.cluster_config.image=aisi-basic-agent:latest \
  paperbench.solver.is_nvidia_gpu_env=True \
  runner.recorder=nanoeval.json_recorder:json_recorder
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### Code-Dev è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | æƒé‡ |
|------|------|------|
| **è®ºæ–‡ç†è§£** | æ˜¯å¦æ­£ç¡®ç†è§£è®ºæ–‡ä¸»è¦è´¡çŒ® | 20% |
| **æ–¹æ³•å®ç°** | å…³é”®ç®—æ³•å’Œæ–¹æ³•çš„å®ç°å®Œæ•´æ€§ | 40% |
| **ä»£ç è´¨é‡** | ä»£ç ç»“æ„ã€å¯è¯»æ€§ã€å¥å£®æ€§ | 20% |
| **æ•°æ®å¤„ç†** | æ­£ç¡®å¤„ç†æ•°æ®è¾“å…¥å’Œè¾“å‡º | 20% |

### å®Œæ•´è¯„æµ‹é¢å¤–æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | æƒé‡ |
|------|------|------|
| **ç¼–è¯‘/æ‰§è¡Œ** | ä»£ç èƒ½å¦æˆåŠŸç¼–è¯‘å’Œè¿è¡Œ | 30% |
| **ç»“æœåŒ¹é…** | å¤ç°ç»“æœæ˜¯å¦ä¸è®ºæ–‡ç»“æœä¸€è‡´ | 30% |

### æ•´ä½“è¯„åˆ†

```
æ€»åˆ† = 0-100 åˆ†

ä¼˜ç§€ (80-100): ä»£ç è´¨é‡é«˜ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå¯ç›´æ¥ä½¿ç”¨
è‰¯å¥½ (60-79): ä»£ç å¯ç”¨ï¼Œæœ‰å°‘é‡é—®é¢˜
ä¸€èˆ¬ (40-59): ä»£ç æœ‰æ˜æ˜¾ç¼ºé™·ï¼Œéœ€è¦ä¿®å¤
ä¸åˆæ ¼ (0-39): ä»£ç ä¸å¯ç”¨æˆ–æœ‰ä¸¥é‡é—®é¢˜
```

---

## ğŸ“ˆ ç»“æœåˆ†æ

### ç”ŸæˆæŠ¥å‘Šç¤ºä¾‹

```json
{
  "evaluation_summary": {
    "total_papers": 20,
    "papers_completed": 18,
    "papers_failed": 2,
    "average_score": 42.5,
    "success_rate": 0.90,
    "code_generation_rate": 0.95,
    "compilation_pass_rate": 0.85
  },
  "detailed_results": [
    {
      "paper_id": "dpo-direct-preference",
      "status": "completed",
      "code_generated": true,
      "compilation_passed": true,
      "score": 65.0,
      "execution_success": true,
      "result_match_score": 0.92,
      "time_spent_minutes": 45,
      "issues": []
    },
    ...
  ]
}
```

### åˆ†æå…³é”®

```python
# è¯†åˆ«è–„å¼±ç¯èŠ‚
- å“ªäº›ç±»å‹çš„è®ºæ–‡è¯„åˆ†ä½ï¼Ÿï¼ˆe.g., ç¡¬ä»¶å¯†é›†å‹ã€æ•°æ®å¤„ç†å¤æ‚ï¼‰
- ä»£ç ç”Ÿæˆè¿˜æ˜¯ç¼–è¯‘ä¿®å¤ç¯èŠ‚æœ‰é—®é¢˜ï¼Ÿ
- æ˜¯å¦æŸç±»è®ºæ–‡ç‰¹åˆ«éš¾ï¼Ÿ

# å¯¹æ ‡åŸºçº¿
- Claude 3.5 Sonnet Code-Dev: 21.0%
- Claude 3.5 Sonnet (å®Œæ•´): 16.1%
- GPT-4o: 4.1%
```

---

## ğŸ”§ é›†æˆå»ºè®®

### æ‰©å±• MS-Agent æ”¯æŒ

ä¿®æ”¹ `projects/code_scratch/config_handler.py`ï¼š

```python
class ConfigHandler(ConfigLifecycleHandler):
    def task_begin(self, config: DictConfig, tag: str) -> DictConfig:
        # æ£€æµ‹æ˜¯å¦ä¸º PaperBench ä»»åŠ¡
        if hasattr(config, 'paperbench') and config.paperbench.enabled:
            # åˆ‡æ¢åˆ° PaperBench ç‰¹å®šé…ç½®
            config.callbacks = [
                'callbacks/paperbench_callback',
                'callbacks/artifact_callback'
            ]
            config.tools = {
                'paper_analyzer': {'type': 'pdf_reader'},
                'file_system': {'mcp': False},
                ...
            }
        return config
```

### åˆ›å»º PaperBench å›è°ƒ

åˆ›å»º `projects/code_scratch/callbacks/paperbench_callback.py`ï¼š

```python
class PaperBenchCallback(Callback):
    """ä¸º PaperBench è¯„æµ‹ä¼˜åŒ–çš„å›è°ƒ"""
    
    async def on_task_begin(self, runtime, messages):
        # åŠ è½½è®ºæ–‡å’Œè¯„ä¼°æ ‡å‡†
        self.paper_info = self._load_paper_info()
        self.rubric = self._load_rubric()
    
    async def on_generate_response(self, runtime, messages):
        # æ£€éªŒä»£ç ç”Ÿæˆè´¨é‡
        self._validate_code_against_rubric()
    
    def _load_paper_info(self):
        # ä» PAPERBENCH_DATA_DIR è¯»å–è®ºæ–‡
        ...
    
    def _load_rubric(self):
        # è¯»å–è¯„ä¼°æ ‡å‡† JSON
        ...
    
    def _validate_code_against_rubric(self):
        # æ ¹æ®æ ‡å‡†æ£€éªŒä»£ç 
        ...
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **ä» Debug å¼€å§‹**ï¼šå…ˆç”¨ `paper_split=debug` æµ‹è¯• 3-5 ç¯‡è®ºæ–‡
2. **é€æ­¥æ‰©å±•**ï¼šç¡®è®¤æµç¨‹æ— è¯¯åå†å…¨é‡è¯„æµ‹
3. **ç›‘æµ‹æˆæœ¬**ï¼šæ³¨æ„ API è°ƒç”¨æˆæœ¬ï¼ŒCode-Dev æˆæœ¬ä½
4. **ä¿å­˜æ—¥å¿—**ï¼šè¯¦ç»†æ—¥å¿—ç”¨äºäº‹ååˆ†æ
5. **ç‰ˆæœ¬è·Ÿè¸ª**ï¼šè®°å½•æ¯æ¬¡è¯„æµ‹çš„ MS-Agent ç‰ˆæœ¬å’Œé…ç½®

---

## ğŸ“ å‚è€ƒèµ„æº

- **PaperBench å®˜ç½‘**ï¼šhttps://openai.com/index/paperbench/
- **GitHub ä»£ç **ï¼šhttps://github.com/openai/frontier-evals/tree/main/project/paperbench
- **è®ºæ–‡**ï¼šhttps://arxiv.org/abs/2504.01848
- **MS-Agent æ–‡æ¡£**ï¼šhttps://ms-agent.readthedocs.io/

---

## ğŸ“ å¸¸è§é—®é¢˜

**Q: Code-Dev å’Œå®Œæ•´è¯„æµ‹å“ªä¸ªæ›´åˆé€‚ï¼Ÿ**
A: å¿«é€Ÿè¿­ä»£ç”¨ Code-Devï¼ˆæˆæœ¬ä½ï¼‰ï¼Œæœ€ç»ˆè¯„ä¼°ç”¨å®Œæ•´è¯„æµ‹ï¼ˆæ›´ä¸¥æ ¼ï¼‰ã€‚

**Q: éœ€è¦ä»€ä¹ˆæ ·çš„ GPUï¼Ÿ**
A: Code-Dev ä¸éœ€è¦ GPUï¼Œå®Œæ•´è¯„æµ‹å»ºè®® A100/H100ã€‚

**Q: è¯„åˆ†å¤šå°‘æ‰ç®—æˆåŠŸï¼Ÿ**
A: å½“å‰åŸºçº¿ï¼šClaude 3.5 Sonnet Code-Dev çº¦ 21%ï¼Œè¶…è¿‡è¿™ä¸ªåˆ†æ•°å³ä¸ºä¼˜äºåŸºçº¿ã€‚

**Q: å¦‚ä½•è°ƒè¯•å¤±è´¥çš„è®ºæ–‡ï¼Ÿ**
A: æŸ¥çœ‹ `runs/` ç›®å½•ä¸‹çš„è¯¦ç»†æ—¥å¿—ï¼Œä½¿ç”¨ `uv run python paperbench/gui/app.py` æŸ¥çœ‹è¯„ä¼°æ ‡å‡†ã€‚
