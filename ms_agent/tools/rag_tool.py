# Copyright (c) Alibaba, Inc. and its affiliates.
import os
import shutil
from typing import Optional

from ms_agent.llm.utils import Tool
from ms_agent.tools.base import ToolBase
from ms_agent.utils import get_logger
from ms_agent.utils.constants import DEFAULT_OUTPUT_DIR
from ms_agent.rag.ensemble_rag import MultiLlamaIndexRAG

logger = get_logger()

rag_model_cache = None

class RAGTool(ToolBase):
    """RAG Tool"""

    name = "rag_tool"
    description = (
        "A tool for retrieval augmented generation (RAG) tasks. "
        "Useful for answering questions based on a large corpus of documents."
    )

    def __init__(self, config,**kwargs):
        super().__init__(config)
        global rag_model_cache
        if rag_model_cache is not None:
            self.rag_model = rag_model_cache
        else:
            self.rag_model = MultiLlamaIndexRAG(config)
            rag_model_cache = self.rag_model
    
    async def connect(self):
        """Connect to RAG model"""
        await self.rag_model.initialize_all_components()
        logger.info("RAG model connected.")
    
    async def get_tools(self):
        """Get RAG tool"""
        rag_tool = Tool(
            tool_name="search_with_rag",
            server_name="rag_tool",
            description="Use this tool to answer questions based on a large corpus of documents.",
            parameters={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The question to be answered using RAG.",
                    },
                },
                "required": ["query"],
            }
        )
        return {
            "rag_tool": [rag_tool]
        }
    
    async def call_tool(self, server_name, *, tool_name, tool_args):
        return await getattr(self, tool_name)(**tool_args)
    
    async def search_with_rag(self, query: str) -> str:
        """Search with RAG model

        Args:
            query (str): The question to be answered using RAG.
            top_k (Optional[int], optional): The number of top relevant documents to retrieve. Defaults to 3.

        Returns:
            str: The answer generated by the RAG model.
        """
        answer = await self.rag_model.query(query)
        return answer
        