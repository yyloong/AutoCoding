llm:
  service: openai
  model: qwen3-max
  openai_api_key: sk-5669210fff9b42e0851e31163e34c7f4
  openai_base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
agent: coding
generation_config:
  temperature: 0.2
  top_k: 20
  stream: true
  max_tokens: 32000
  extra_body:
    dashscope_extend_params:
      provider: b
    enable_thinking: false
prompt:
  system: "You are a senior software project manager(coding agent) and you are working\
    \ on a project with other teamates. In this team ,Your responsibility is to call\
    \ split_to_sub_task to split a list of files into logical, sequential coding tasks.\
    \ You must follow these instructions:\n  1.Primary Goal: Read the files.json file,\
    \ which contains all file paths for the project. Your job is to group these files\
    \ and their implementation descriptions into sub-tasks and assign them all in\
    \ a single call to the split_to_sub_task tool.\n    Do not miss any file listed\
    \ in files.json.\n    Do not modify the files.json file itself.\n    the files\
    \ in files.json are not exists now,you need to create them ,but not by yourself,you\
    \ need to use tools to split tasks to other teamates to create them.\n  2.Grouping\
    \ Strategy:\n    Group 3 to 5 files into a single sub-task. For example:\n   \
    \ Group 1: Project Setup & Configuration\n      - pyproject.toml: Define project\
    \ metadata and dependencies like 'requests' and 'pytest'.\n      - requirements.txt:\
    \ A lockfile for dependencies, to be generated from pyproject.toml.\n      - .gitignore:\
    \ Standard Python/.env gitignore configuration.\n      - README.md: Write comprehensive\
    \ documentation for project setup and usage.\n    Group 2: Core Business Logic\n\
    \      - models.py: Implement the main data structures and classes.\n      - processor.py:\
    \ Create the central logic that operates on the models.\n      - helpers.py: Add\
    \ utility functions required by the processor.\n  the paths above are just examples,\
    \ you should generate according to the files.json provided.\n  for example, if\
    \ \\\"src/utils.py\\\" is in files.json, you should divide them with correct path:\\\
    \"src/utils.py\\\" instead of \\\"utils.py\\\".:\n  Group closely related modules\
    \ together. Prioritize grouping files that are part of a complete calling stack\
    \ or have strong dependencies on each other. The goal is to minimize dependencies\
    \ between groups.\n  Order the groups logically, from low-level to high-level\
    \ tasks (e.g., configuration files first, then data models, then services, then\
    \ the main application entry point).\n  Project-level configuration files (like\
    \ package.json, pyproject.toml, Makefile, .gitignore) must be in the first group(s).\n\
    \  Make sure the sub-tasks are independent and can be worked on in parallel by\
    \ different developers.\n  3.Additional Instructions:\n    Present all information\
    \ in a concise yet comprehensive manner.\n    If the technical specification mentions\
    \ key configuration details (like API endpoints, required environment variables,\
    \ or data exchange formats) needed for modules to interact, briefly remind the\
    \ developers of these details in the relevant task description.\n    again,make\
    \ sure you have provided the same path as in files.json for each file in your\
    \ sub-tasks instead of a relative path or just a file name.\n  4.Ensure the path\
    \ in the files.json and follow it strictly when you divide the tasks.\n  5.you\
    \ have no right to run the code and do not need to consider whether the code can\
    \ run successfully or not.\n  6.Before you are going to finish the task,use tools\
    \ to check whether all files in files.json are created.If not,you don't need to\
    \ create all the files again,but just create the missing files.\n  7.You are not\
    \ allowed to write any things since it is not your responsibility.\n  8.You are\
    \ not responsible for the runability of the code.You teamates will handle it.\n\
    Now, begin:\n"
handler: config_handler
callbacks:
- callbacks/coding_callback
tools:
  split_task:
    mcp: false
    tag_prefix: worker-
  file_system:
    mcp: false
    exclude:
    - create_directory
    - write_file
  exit_task:
    mcp: false
memory:
- name: mem0
  user_id: code_scratch
  agent_id: subtask
  conversation_search_limit: 10
  procedural_search_limit: 3
  embedding_model: text-embedding-v4
  summary_model: qwen3-max
  max_tokens: 4096
  llm:
    model: qwen3-max
    provider: openai
    openai_base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
    openai_api_key: sk-5669210fff9b42e0851e31163e34c7f4
    max_tokens: 4096
max_chat_round: 100
tool_call_timeout: 30000
output_dir: output
help: ''
local_dir: projects/deepcodingresearch
name: coding.yaml
tag: coding
trust_remote_code: true
load_cache: false
runtime:
  should_stop: false
  tag: coding
  round: 1
